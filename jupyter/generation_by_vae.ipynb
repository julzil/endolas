{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder for Augmentation of Laser-Based Laryngeal Imaging\n",
    "\n",
    "For the deep-learning-based algorithm to match features via a registration task, it is essential to apply intense data augmentation to the training data set. The training data consists of moving images $m(x)$ that represent the spatial configuration of laser points projected onto the vocal fold surface.\n",
    "The foundation for the images $m(x)$ are the x-y-coordinates of each single laser point within the image, as $m(x)$ is generated by plotting the single laser points and then smoothing the image. To create intense augmentation we want to train a variational autoencoder (VAE) to then generate images that are variations of the images of the training set and represent feasible configurations of laser points projected onto a vocal fold.\n",
    "\n",
    "In a VAE a decoder-encoder architecture is utilized. The coding is split up into a vector representing the mean $\\mu$ and one representing the logarithmic variance $\\log{(\\mathbf{\\sigma^2})}$. The distribution is assumed to be gaussian. Behind the coding a sampling layer exists that randomly samples a value from the distribution. Like that it is possible to create a smooth latent space. The network can be trained in a unsupervised manner, as the the decoder should learn to reconstruct the input of the encoder as good as possible. After training, only the decoder part will be used. Inputing random points in the latent space will then generate x- and y-coordinates that are part of the underlying trained distribution based on the ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements\n",
    "The notebook was developed on Keras using the Tensorflow 2.2.0 backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Configuration\n",
    "Check for GPU and allow memory growth such that limitations for training are reduced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if len(tf.config.experimental.get_visible_devices('GPU')):\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality\n",
    "The following functionality helps to create the images for training the registration task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_smoothing(image, sigma=1.0, sigma_back=10.0):\n",
    "    image_orig = image\n",
    "    image = gaussian_filter(image, sigma=sigma)\n",
    "    image_back = gaussian_filter(image, sigma=sigma_back)\n",
    "\n",
    "    image = (image / image.max()) * 255\n",
    "    image_back = (image_back / image_back.max()) * 255\n",
    "    image = 0.3 * image_orig + 0.3 * image + 0.3 * image_back\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_image(x_position, y_position):\n",
    "    image = np.zeros((image_height, image_width))\n",
    "    index_2_xy = dict()\n",
    "    point_index = 0\n",
    "    for x, y in zip(x_position.flatten(), y_position.flatten()):\n",
    "        x = int(x*image_width)\n",
    "        y = int(y*image_height)\n",
    "        \n",
    "        if x >= 5 and y>= 5:\n",
    "            image[y][x] = 1\n",
    "            index_2_xy[str(point_index)] = [x, y]\n",
    "            \n",
    "        point_index += 1\n",
    "        \n",
    "    image = apply_smoothing(image, sigma=2, sigma_back=15)\n",
    "    return image, index_2_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters\n",
    "The grid dimensions have to be know, as well as the image dimensions for scaling. The depth of the input and output layer is 2 here, as we will have one channel representing x-coordinates and a second channel representing y-coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_width = 18\n",
    "grid_height = 18\n",
    "\n",
    "image_width = 728\n",
    "image_height = 728\n",
    "\n",
    "inout_layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "The dimension of the latent space can be adapted to optimize the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 8\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "coding_loss_factor =0.2\n",
    "epsilon_factor = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Layer\n",
    "In the sampling layer the coding $\\mathbf{\\mu}$ and $\\log{(\\mathbf{\\sigma^2})}$ are used to randomly sample a point from the underlying distribution. Due to this randomness that occurs within each batch and along all epochs the decoder is trained on smooth distributions. Each coding $\\mathbf{z}$ used to train the decoder is computed as\n",
    "\n",
    "$$\\mathbf{z} = \\mathbf{\\mu} + e^{0.5\\mathbf{\\log{(\\mathbf{\\sigma^2})}}}\\mathbf{\\epsilon}f$$\n",
    "\n",
    "where $\\epsilon$ is a random vector from a normal distribution and $f$ is a hyperparameter to control the amount of randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon * epsilon_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Model\n",
    "In the encoder strided convolutional layers are applied to reduce the dimensionality of the input. For a grid with dimension 18x18 the input shape is increased to 20x20 and the input images are padded. Like that it is easier to ensure symmetry between encoder an decoder. The encoder is a keras model having the mean, variance and a sampled value as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(shape=(grid_width+2, grid_height+2, inout_layers))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Model\n",
    "The decoder takes only a sampeled value or a randomly selected value with the size of the latent space as input. \n",
    "The dimnesion of the input of the encoder is then reconstructed. The decoder is constructed as a keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "y_val = (grid_height+2)//4\n",
    "x_val = (grid_width+2)//4\n",
    "\n",
    "x = layers.Dense(y_val*x_val*64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((y_val, x_val, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(inout_layers, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Model\n",
    "The VAE is composed by the encoder and decoder. The decoder only takes the random coding $\\mathbf{z}$ from the encoder. However, the codings $\\mathbf{\\mu}$ and $\\log{(\\mathbf{\\sigma^2})}$ are used to compute a loss $\\epsilon_{coding}$ for regularizing and ensuring a smooth distribution. A binary crossentropy is used to define a reconstruction loss $\\epsilon_{reconstruction}$. \n",
    "We are doing a regression here, based on probabilities. The overall loss is then:\n",
    "\n",
    "$$\\epsilon = \\epsilon_{reconstruction} + \\epsilon_{coding}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VariationalAutoEncoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "            \n",
    "        # Gradient tape allows to \"record\" a function that will be derived\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            \n",
    "            # Reconstuction Loss\n",
    "            reconstruction = decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= grid_height+2 * grid_height+2\n",
    "            \n",
    "            # Regularization Loss for well formed latent space and no overfitting\n",
    "            coding_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            coding_loss = tf.reduce_mean(coding_loss)\n",
    "            coding_loss *= -(0.5 * coding_loss_factor)\n",
    "            \n",
    "            # Total Loss\n",
    "            total_loss = reconstruction_loss + coding_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"coding_loss\": coding_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "Load the data and scale them to be between 0.0 an 1.0. Further use zero-padding to get a 20x20 shape for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a path from where to load the data\n",
    "base_path = 'Data/LASTEN/train'\n",
    "\n",
    "# Load data into numpy arrays\n",
    "def sort_key(path):\n",
    "    return int(path.split(os.sep)[-1].split(\".\")[0].split(\"_\")[0]) \n",
    "    \n",
    "globs = glob.glob(base_path+'/*.json')\n",
    "files = sorted(globs, key=sort_key)\n",
    "file_length =len(files)\n",
    "x_position = np.full((file_length, grid_height, grid_width), 0)\n",
    "y_position = np.full((file_length, grid_height, grid_width), 0)\n",
    "for file_id, file in enumerate(files):\n",
    "    with open(file) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        for key, value in data.items():\n",
    "            key = int(key)\n",
    "        \n",
    "            \n",
    "            y = key // grid_height \n",
    "            x = key % grid_width\n",
    "\n",
    "            x_position[file_id][y][x] = value[0]\n",
    "            y_position[file_id][y][x] = value[1]\n",
    "\n",
    "\n",
    "# Define an offset\n",
    "offset = 0.0\n",
    "\n",
    "# Non existing points mapping\n",
    "x_position = np.where(x_position<=0, -offset, x_position) + offset\n",
    "y_position = np.where(x_position<=0, -offset, y_position) + offset\n",
    "\n",
    "x_position = x_position / (image_width + offset)\n",
    "y_position = y_position / (image_height + offset)\n",
    "\n",
    "# Zero padding\n",
    "x_position = np.pad(x_position,[(0,0),(1,1),(1,1)],constant_values=0)\n",
    "y_position = np.pad(y_position,[(0,0),(1,1),(1,1)],constant_values=0)\n",
    "\n",
    "x_position = x_position[:,:,:,np.newaxis]\n",
    "y_position = y_position[:,:,:,np.newaxis]\n",
    "\n",
    "xy_data = np.concatenate((x_position, y_position), axis=3)\n",
    "print(\"Shape of 'xy_data': {}\".format(xy_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Initialize the VAE, compile it and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vae = VariationalAutoEncoder(encoder, decoder)\n",
    "\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "logger = CSVLogger(\"VAE_log\")\n",
    "history = vae.fit(xy_data, epochs=epochs, batch_size=batch_size)\n",
    "#vae.save_weights('weights/vae/vae_100_epochs_gt')\n",
    "#vae.load_weights('weights/vae/vae_100_epochs_gt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if history:\n",
    "    print('Mean reconstruction loss over last 20 epochs: {}'.format(np.array(history.history['reconstruction_loss'][-20:]).mean()))\n",
    "    print('Mean coding loss over last 20 epochs: {}'.format(np.array(history.history['coding_loss'][-20:]).mean()))\n",
    "    plt.semilogy(history.history['reconstruction_loss'], label='Reconstruction Loss')\n",
    "    plt.title('Crossentropy Loss for Reconstruction of Input images')\n",
    "    plt.ylabel('Crossentropy')\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict images and compare with ground truth\n",
    "Get the mean value for ground truth images and decode the value to reconstruct the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_encoder = encoder.predict(xy_data)\n",
    "res_decoder = decoder.predict(res_encoder[0])\n",
    "plt.rcParams[\"figure.figsize\"] = (7,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicition of x-coordinates by autoencoder\n",
    "Out of all 8 recordings from the dataset one frame is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    val = 441 + i\n",
    "    plt.subplot(val)\n",
    "    x = res_decoder[i*20,:,:,1][1:-1,1:-1]\n",
    "    plt.imshow(x)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground-truth of x-coordinates\n",
    "Out of all 8 recordings from the dataset one frame is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    val = 441 + i\n",
    "    plt.subplot(val)\n",
    "    x = xy_data[i*20,:,:,1][1:-1,1:-1]\n",
    "    plt.imshow(x)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicition of x-y-coordinates and display in image space \n",
    "Out of all 8 recordings from the dataset one frame is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    val = 441 + i\n",
    "    plt.subplot(val)\n",
    "    x = res_decoder[i*20,:,:,0]\n",
    "    y = res_decoder[i*20,:,:,1]\n",
    "    plt.imshow(reconstruct_image(x, y)[0],cmap='gist_gray')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth of x-y-coordinates and display in image space \n",
    "Out of all 8 recordings from the dataset one frame is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    val = 441 + i\n",
    "    plt.subplot(val)\n",
    "    x = xy_data[i*20,:,:,0]\n",
    "    y = xy_data[i*20,:,:,1]\n",
    "    plt.imshow(reconstruct_image(x, y)[0],cmap='gist_gray')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing\n",
    "Apply a bilateral filter to denoise the coordinate images. Further irregularities in x- and y-direction are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_bilateral\n",
    "plt.rcParams[\"figure.figsize\"] = (7,7)\n",
    "\n",
    "def postprocess_coordinate_images(results, index):\n",
    "    x = results[index,:,:,0]\n",
    "    y = results[index,:,:,1]\n",
    "    \n",
    "    # Unpad\n",
    "    x = x[1:-1,1:-1]\n",
    "    y = y[1:-1,1:-1]\n",
    "    \n",
    "    x_max_orig = x.max()\n",
    "    y_max_orig = y.max()\n",
    "    \n",
    "    # Smooth and equalize possible offset due to smoothing\n",
    "    x = denoise_bilateral(x, mode='edge',sigma_spatial=100, win_size=3)\n",
    "    y = denoise_bilateral(y, mode='edge',sigma_spatial=100, win_size=3)\n",
    "    x = x - x.min()\n",
    "    y = y - y.min()\n",
    "    x = x * (x_max_orig / x.max())\n",
    "    y = y * (y_max_orig / y.max())\n",
    "    \n",
    "    # Sort out irregularities in x\n",
    "    for i in range(len(x)):        \n",
    "        max_value=0.0\n",
    "        for j in range(len(x[i])):\n",
    "            if x[i][j] <= max_value:\n",
    "                x[i][j] = 0.0\n",
    "                y[i][j] = 0.0\n",
    "            else: \n",
    "                max_value = x[i][j]\n",
    "            \n",
    "    # Sort out irregularities in y\n",
    "    for i in range(len(y[0])):        \n",
    "        max_value=0.0\n",
    "        for j in reversed(range(len(y))):\n",
    "            if y[j][i] <= max_value:\n",
    "                x[j][i] = 0.0\n",
    "                y[j][i] = 0.0\n",
    "            else:\n",
    "                max_value = y[j][i]\n",
    "    \n",
    "    return x, y        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an image based on a vector from the latent space\n",
    "Use this functionality to explore the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def f(**sliders):\n",
    "    image_id = 0\n",
    "    \n",
    "    sliders_float = [float(slider[1]) for slider in sliders.items()]\n",
    "    \n",
    "    res_encoder_offset = np.array([sliders_float])\n",
    "    res_decoder = decoder.predict(res_encoder[0][image_id] + res_encoder_offset)\n",
    "    \n",
    "    x, y = postprocess_coordinate_images(res_decoder, image_id)\n",
    "\n",
    "    img = reconstruct_image(x, y)[0]\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    display(fig)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_axes(plt.axes())\n",
    "fig.canvas.draw()\n",
    "ax.axis('off')\n",
    "\n",
    "\n",
    "sliders = {str(i): widgets.FloatSlider(min=-2.0,max=2.0,step=0.5,value=0.0, continuous_update=False) for i in range(latent_dim)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = interact(f, **sliders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw samples from the distribution for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several possibilties to draw samples from the latent space.\n",
    "1. Predict the latent vector of one sample image and pertubate it.\n",
    "2. Linearly Interpolate between neighbors.\n",
    "3. Linearly Extrapolate with neighbors.\n",
    "\n",
    "We will show possbility 2 here to visualize the manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linearly Interpolate between neighbors\n",
    "First we define a function to linearly interpolate a coding between two existing codings with a factor $\\alpha$ in $[0,1]$. Therefore, we define:\n",
    "$$ \\hat{\\mathbf{z}} = (\\mathbf{\\mu}_2 - \\mathbf{\\mu}_1)\\alpha + \\mathbf{\\mu}_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_codings(first_coding, second_coding, alpha):\n",
    "    return (second_coding - first_coding) * alpha + first_coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we select four ground truth images for which we first compute the coding through the encoder. Then we sample with a factor of $\\alpha$, values between the first and the second image and the third and the fourth image. After, we sample again between the previously sampled points to cover approximatley the space between all ground truth images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image_id = 0\n",
    "second_image_id = 108\n",
    "third_image_id = 54\n",
    "fourth_image_id = 18\n",
    "\n",
    "first_coding = res_encoder[0][first_image_id]\n",
    "second_coding = res_encoder[0][second_image_id]\n",
    "third_coding = res_encoder[0][third_image_id]\n",
    "fourth_coding = res_encoder[0][fourth_image_id]\n",
    "\n",
    "alphas = list(np.arange(0.0,1.1,0.2))\n",
    "size = len(alphas)\n",
    "\n",
    "first_2_second_codings = np.array([interpolate_codings(first_coding, second_coding, alpha) for alpha in alphas])\n",
    "third_2_fourth_codings = np.array([interpolate_codings(third_coding, fourth_coding, alpha) for alpha in alphas])\n",
    "\n",
    "codings = np.zeros((size, size, latent_dim))\n",
    "\n",
    "for i in range(size):\n",
    "    first_2_second_coding = first_2_second_codings[i]\n",
    "    third_2_fourth_coding = third_2_fourth_codings[i]\n",
    "    \n",
    "    vertical_codings = np.array([interpolate_codings(first_2_second_coding, third_2_fourth_coding, alpha) for alpha in alphas])\n",
    "    \n",
    "    codings[:, i, :] = vertical_codings\n",
    "\n",
    "codings = codings.reshape((size * size, latent_dim))\n",
    "res_decoder = decoder.predict(codings)\n",
    "\n",
    "x_coords = list()\n",
    "y_coords = list()\n",
    "\n",
    "for i in range(size * size):\n",
    "    x, y = postprocess_coordinate_images(res_decoder, i)\n",
    "    x_coords.append(x)\n",
    "    y_coords.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now display the learned manifold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (40,40)\n",
    "\n",
    "for i in range(size * size):\n",
    "    x = x_coords[i]\n",
    "    y = y_coords[i]\n",
    "    \n",
    "    plt.subplot(size, size, i+1)\n",
    "    plt.imshow(reconstruct_image(x, y)[0],cmap='gist_gray')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "#plt.savefig('learned_manifold.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw samples from the distribution for generating a data set\n",
    "Use either sampling by interpolation or by noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide to sample by interpolation or by noise\n",
    "is_interpolation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample by interpolation\n",
    "if is_interpolation:\n",
    "    # Amount of between how many sample points from recordings an interpolation is carried out\n",
    "    sub_samples = 10\n",
    "    # Amount of how many interpolations are made between two points (alpha value).\n",
    "    inter_samples = 3\n",
    "    # Get the codings\n",
    "    codings = res_encoder[0]\n",
    "    # Split the recordings\n",
    "    recordings = [codings[0:20],\n",
    "                  codings[20:40],\n",
    "                  codings[40:60],\n",
    "                  codings[60:80],\n",
    "                  codings[80:100],\n",
    "                  codings[100:120],\n",
    "                  codings[120:140],\n",
    "                  codings[140:160]]\n",
    "\n",
    "    def interpolate_codings(first_coding, second_coding, alpha):\n",
    "        return (second_coding - first_coding) * alpha + first_coding\n",
    "\n",
    "    def extrapolate_codings(first_coding, second_coding, alpha):\n",
    "        return (first_coding - second_coding) * alpha + first_coding\n",
    "\n",
    "    def get_random_list(samples, sub_samples):\n",
    "        random_list = list(range(samples))\n",
    "        random.shuffle(random_list)\n",
    "        random_list = random_list[0:sub_samples]\n",
    "        return random_list\n",
    "\n",
    "    interpolated_codings = np.zeros((28*sub_samples*inter_samples, 8))#*2\n",
    "    alphas = np.linspace(0,1,inter_samples+2)[1:-1]\n",
    "\n",
    "    counter = 0\n",
    "    while recordings:\n",
    "        first_recording = recordings.pop(0)\n",
    "\n",
    "        for second_recording in recordings:\n",
    "            first_random_points = get_random_list(20, sub_samples)\n",
    "            second_random_points = get_random_list(20, sub_samples)\n",
    "\n",
    "            while first_random_points:\n",
    "                first_point = first_random_points.pop(0)\n",
    "                second_point = second_random_points.pop(0)\n",
    "                first_coding = first_recording[first_point]\n",
    "                second_coding = second_recording[second_point]\n",
    "                inter_codings = np.array([interpolate_codings(first_coding, second_coding, alpha) for alpha in alphas])\n",
    "                start_index_inter = counter*inter_samples #*2\n",
    "                end_index_inter = counter*inter_samples + inter_samples          \n",
    "                interpolated_codings[start_index_inter:end_index_inter] = inter_codings\n",
    "\n",
    "                counter +=1\n",
    "\n",
    "    res_decoder = decoder.predict(interpolated_codings)\n",
    "    variation_index = 40000\n",
    "    for i in range(len(interpolated_codings)):\n",
    "        new_x, new_y = postprocess_coordinate_images(res_decoder, i)\n",
    "        image, index_2_xy = reconstruct_image(new_x, new_y)\n",
    "\n",
    "        # Store JSON\n",
    "        json_file = json.dumps(index_2_xy)\n",
    "        f = open(base_path + os.sep + \"{}.json\".format(variation_index), \"w\")\n",
    "        f.write(json_file)\n",
    "        f.close()\n",
    "\n",
    "        # Store .png image\n",
    "        plt.imsave(base_path + os.sep + \"{}_mov.png\".format(variation_index), image, cmap=\"gray\")\n",
    "        variation_index += 1\n",
    "        \n",
    "# Sample Noise\n",
    "else:\n",
    "    # Sample size per observation\n",
    "    amount = 4\n",
    "    \n",
    "    variation_index = 40000\n",
    "    for i in range(amount):\n",
    "        epsilon = np.random.normal(size=res_encoder[0].shape)\n",
    "        variation = res_encoder[0] + np.exp(0.5 * res_encoder[1]) * epsilon\n",
    "        res_decoder = decoder.predict(variation)\n",
    "\n",
    "        for i in range(160):\n",
    "            new_x, new_y = postprocess_coordinate_images(res_decoder, i)\n",
    "            image, index_2_xy = reconstruct_image(new_x, new_y)\n",
    "            # Store JSON\n",
    "            json_file = json.dumps(index_2_xy)\n",
    "            f = open(base_path + os.sep + \"{}.json\".format(variation_index), \"w\")\n",
    "            f.write(json_file)\n",
    "            f.close()\n",
    "            # Store .png image\n",
    "            plt.imsave(base_path + os.sep + \"{}_mov.png\".format(variation_index), image, cmap=\"gray\")\n",
    "            variation_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
