{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements\n",
    "Following packages are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "from simplegen import SIMPLESequence\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "from unet import UNet\n",
    "from unet import preprocess_input as pre_une\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Checks\n",
    "The version of tensorflow as well as the GPU support are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality\n",
    "Necessary funcionality is added here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cube(img, x, y, val):\n",
    "    \n",
    "    img[y][x] = val\n",
    "    img[y][x-1] = val\n",
    "    img[y][x+1] = val\n",
    "    img[y-1][x] = val\n",
    "    img[y-1][x-1] = val\n",
    "    img[y-1][x+1] = val\n",
    "    img[y+1][x] = val\n",
    "    img[y+1][x-1] = val\n",
    "    img[y+1][x+1] = val  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.10) Supervised Euclidean for SIMPLED with difference image and gradient\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_10_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLED\\train\\0'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLED\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLED\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLED\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True,\n",
    "                           multi_channel='grad')\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une,\n",
    "                                multi_channel='grad')\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\skimage\\filters\\rank\\generic.py:119: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  out_dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\skimage\\filters\\rank\\generic.py:119: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  out_dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 163s 194ms/step - loss: 755.9079 - val_loss: 477.8638\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 150s 179ms/step - loss: 191.5001 - val_loss: 89.3899\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 132s 158ms/step - loss: 62.2317 - val_loss: 94.0575\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 152s 180ms/step - loss: 42.2581 - val_loss: 62.2709\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 157s 187ms/step - loss: 38.0869 - val_loss: 70.9921\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 147s 174ms/step - loss: 32.0374 - val_loss: 64.8964\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 140s 166ms/step - loss: 28.9761 - val_loss: 37.6842\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 131s 156ms/step - loss: 22.2836 - val_loss: 25.6810\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 140s 167ms/step - loss: 24.0317 - val_loss: 28.4430\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 140s 166ms/step - loss: 19.9800 - val_loss: 26.5658\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 150s 179ms/step - loss: 15.2160 - val_loss: 15.0252\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 141s 167ms/step - loss: 16.3054 - val_loss: 28.4163\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 134s 160ms/step - loss: 14.4909 - val_loss: 20.5944\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 136s 162ms/step - loss: 14.5400 - val_loss: 12.6655\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 129s 154ms/step - loss: 12.2906 - val_loss: 18.7746\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 127s 151ms/step - loss: 10.5495 - val_loss: 18.8014\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 152s 180ms/step - loss: 11.6138 - val_loss: 13.8459\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 125s 149ms/step - loss: 9.2141 - val_loss: 11.7202\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 126s 151ms/step - loss: 8.4267 - val_loss: 13.3946\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 128s 153ms/step - loss: 7.7630 - val_loss: 13.5084\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 145s 173ms/step - loss: 7.7728 - val_loss: 8.9320\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 137s 163ms/step - loss: 6.8644 - val_loss: 15.3345\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 127s 151ms/step - loss: 7.3325 - val_loss: 9.9027\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 128s 152ms/step - loss: 6.1160 - val_loss: 19.8272\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 127s 151ms/step - loss: 6.3218 - val_loss: 12.1505\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 135s 161ms/step - loss: 4.9450 - val_loss: 9.0565\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 134s 160ms/step - loss: 5.9575 - val_loss: 8.2894\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 137s 163ms/step - loss: 4.5797 - val_loss: 18.3474\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 140s 166ms/step - loss: 4.3361 - val_loss: 11.4932\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 127s 151ms/step - loss: 5.6888 - val_loss: 6.2936\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 148s 176ms/step - loss: 3.5230 - val_loss: 14.4619\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 138s 165ms/step - loss: 4.2788 - val_loss: 11.7166\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 141s 168ms/step - loss: 3.5918 - val_loss: 11.5796\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 142s 169ms/step - loss: 3.4081 - val_loss: 7.4184\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 139s 166ms/step - loss: 3.5886 - val_loss: 6.3605\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 126s 150ms/step - loss: 3.4425 - val_loss: 11.1874\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 130s 155ms/step - loss: 3.4961 - val_loss: 204.3825\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 130s 155ms/step - loss: 3.0280 - val_loss: 7.0755\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 136s 162ms/step - loss: 3.2185 - val_loss: 6.4176\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 143s 170ms/step - loss: 3.3425 - val_loss: 13.9607\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 134s 159ms/step - loss: 2.7597 - val_loss: 6.4912\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 131s 156ms/step - loss: 2.1184 - val_loss: 8.2499\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 125s 149ms/step - loss: 3.3047 - val_loss: 7.1673\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 127s 151ms/step - loss: 2.0690 - val_loss: 6.4903\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 135s 161ms/step - loss: 3.6091 - val_loss: 10.4335\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 126s 150ms/step - loss: 1.8622 - val_loss: 8.0626\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 138s 164ms/step - loss: 2.4696 - val_loss: 7.1891\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 127s 151ms/step - loss: 1.9547 - val_loss: 7.1713\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 136s 161ms/step - loss: 1.9663 - val_loss: 4.6851\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 126s 150ms/step - loss: 1.7370 - val_loss: 5.3526\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 127s 151ms/step - loss: 2.3102 - val_loss: 16.8666\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 137s 163ms/step - loss: 1.6725 - val_loss: 6.5728\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 139s 166ms/step - loss: 2.0743 - val_loss: 7.3086\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 139s 165ms/step - loss: 1.7898 - val_loss: 5.4888\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 137s 163ms/step - loss: 1.8051 - val_loss: 13.8551\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 137s 163ms/step - loss: 1.7124 - val_loss: 5.8405\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 126s 150ms/step - loss: 1.9805 - val_loss: 7.7760\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 136s 162ms/step - loss: 1.5004 - val_loss: 5.4756\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 137s 163ms/step - loss: 1.5598 - val_loss: 7.2391\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 129s 154ms/step - loss: 1.8266 - val_loss: 6.7063\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 139s 166ms/step - loss: 1.5039 - val_loss: 10.5830\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 128s 152ms/step - loss: 1.3757 - val_loss: 5.8406\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 142s 169ms/step - loss: 1.5691 - val_loss: 4.9989\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 129s 154ms/step - loss: 1.6732 - val_loss: 4.0294\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 129s 154ms/step - loss: 1.1436 - val_loss: 4.2239\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 138s 165ms/step - loss: 1.3478 - val_loss: 7.0064\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 139s 166ms/step - loss: 1.3157 - val_loss: 5.7923\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 133s 159ms/step - loss: 1.4889 - val_loss: 6.9800\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 126s 150ms/step - loss: 1.5863 - val_loss: 9.9792\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 127s 151ms/step - loss: 0.9904 - val_loss: 4.7521\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 135s 161ms/step - loss: 1.2120 - val_loss: 4.3093\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 141s 168ms/step - loss: 1.3814 - val_loss: 6.4456\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 134s 159ms/step - loss: 1.1885 - val_loss: 5.8104\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 133s 158ms/step - loss: 0.8718 - val_loss: 4.8095\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 128s 152ms/step - loss: 1.1201 - val_loss: 9.3164\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 139s 166ms/step - loss: 1.1514 - val_loss: 5.3950\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 128s 153ms/step - loss: 1.9972 - val_loss: 48.4677\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 140s 167ms/step - loss: 1.0165 - val_loss: 4.2636\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 129s 153ms/step - loss: 0.7735 - val_loss: 5.5512\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 140s 167ms/step - loss: 0.8318 - val_loss: 5.3623\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 134s 160ms/step - loss: 0.9436 - val_loss: 7.0772\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 136s 162ms/step - loss: 1.0078 - val_loss: 4.5592\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 127s 151ms/step - loss: 1.0349 - val_loss: 3.9165\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 141s 168ms/step - loss: 0.9599 - val_loss: 5.7883\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 128s 153ms/step - loss: 0.8202 - val_loss: 6.1340\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 145s 172ms/step - loss: 0.9531 - val_loss: 8.3335\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 140s 166ms/step - loss: 0.9522 - val_loss: 7.2673\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 145s 172ms/step - loss: 1.0422 - val_loss: 5.5056\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 135s 161ms/step - loss: 0.9009 - val_loss: 4.8208\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 140s 166ms/step - loss: 0.7804 - val_loss: 4.5771\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 136s 162ms/step - loss: 0.8069 - val_loss: 6.2654\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 142s 170ms/step - loss: 1.2145 - val_loss: 4.5973\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 135s 161ms/step - loss: 0.6215 - val_loss: 6.8762\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 136s 162ms/step - loss: 0.7177 - val_loss: 9.4117\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 138s 165ms/step - loss: 0.7839 - val_loss: 5.1828\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 134s 159ms/step - loss: 0.8903 - val_loss: 6.1243\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 151s 179ms/step - loss: 0.5537 - val_loss: 6.2106\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 142s 170ms/step - loss: 0.9377 - val_loss: 5.2120\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 145s 172ms/step - loss: 0.5909 - val_loss: 7.2101\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 128s 152ms/step - loss: 0.7475 - val_loss: 4.5780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22246951688>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.11) Supervised Euclidean for SIMPLED with L1 regularization\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_11_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLED\\train\\0'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLED\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLED\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLED\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kernel_regularizer=tf.keras.regularizers.l1(0.01)\n",
    "\n",
    "model = UNet(filters=32,\n",
    "             layers=4,\n",
    "             activation='linear',\n",
    "             classes=2,\n",
    "             input_shape=(224, 224, 1),\n",
    "             kernel_regularizer=kernel_regularizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True)\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une)\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 74s 88ms/step - loss: 1459.2959 - val_loss: 1198.8641\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 912.2209 - val_loss: 1253.3102\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 837.3503 - val_loss: 855.2464\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 673.2001 - val_loss: 818.4893\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 307.1844 - val_loss: 588.2663\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 242.7819 - val_loss: 614.4343\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 200.8430 - val_loss: 260.6504\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 68s 80ms/step - loss: 160.5816 - val_loss: 163.9658\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 160.3267 - val_loss: 575.6897\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: 138.6758 - val_loss: 946.4526\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 129.5667 - val_loss: 853.7915\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 124.2662 - val_loss: 1290.1762\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 126.0485 - val_loss: 128.0860\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 110.6288 - val_loss: 108.7451\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 104.0548 - val_loss: 122.0145\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 101.7584 - val_loss: 106.0084\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 103.7177 - val_loss: 104.1568\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 93.9052 - val_loss: 101.4033\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 90.9671 - val_loss: 141.4946\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 89.6719 - val_loss: 97.6015\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 86.1490 - val_loss: 499.7096\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 85.7348 - val_loss: 97.8400\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 82.8587 - val_loss: 102.8018\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 79.8124 - val_loss: 89.2472\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 78.6075 - val_loss: 92.5551\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 79.1300 - val_loss: 306.5794\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 76.6068 - val_loss: 111.1828\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 75.3902 - val_loss: 87.7052\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 73.0874 - val_loss: 229.3829\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 72.5852 - val_loss: 81.9146\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 71.9597 - val_loss: 84.4408\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 70.8420 - val_loss: 104.9127\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 69.9083 - val_loss: 81.1725\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 68.6851 - val_loss: 411.9900\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 71.3128 - val_loss: 83.2253\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 68s 82ms/step - loss: 67.1658 - val_loss: 82.8452\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 66.3880 - val_loss: 77.3221\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 66.9790 - val_loss: 588.5844\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 66.3431 - val_loss: 225.9041\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 65.3974 - val_loss: 77.4023\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 66.1508 - val_loss: 79.4038\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 63.4201 - val_loss: 80.1918\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 64.3722 - val_loss: 105.1497\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 63.3572 - val_loss: 206.5269\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: 62.7828 - val_loss: 73.5055\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 62.8888 - val_loss: 79.4764\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 61.6075 - val_loss: 95.3806\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 62.4665 - val_loss: 80.0446\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 61.3791 - val_loss: 86.3837\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 60.5089 - val_loss: 508.6042\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 61.1157 - val_loss: 328.3134\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 62.8270 - val_loss: 85.7253\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 60.6167 - val_loss: 122.1736\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 59.6165 - val_loss: 489.1594\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 58.7163 - val_loss: 305.6628\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 58.3358 - val_loss: 413.3106\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 59.3646 - val_loss: 77.5586\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 58.4668 - val_loss: 72.7652\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 59.2917 - val_loss: 72.8344\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 58.8654 - val_loss: 73.5782\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 58.3801 - val_loss: 114.0461\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: 57.4638 - val_loss: 75.5494\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 57.2410 - val_loss: 72.7478\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 56.7078 - val_loss: 352.4250\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 56.5356 - val_loss: 81.7624\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 56.0912 - val_loss: 73.3715\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 56.4261 - val_loss: 159.7390\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 56.7795 - val_loss: 79.4957\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 56.8190 - val_loss: 74.6631\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 56.3311 - val_loss: 160.2479\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 55.5999 - val_loss: 75.7238\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 56.3907 - val_loss: 72.5679\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: 55.0760 - val_loss: 96.6807\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 56.5304 - val_loss: 705.7407\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 53.7211 - val_loss: 74.2574\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 56.8934 - val_loss: 783.6347\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 61s 73ms/step - loss: 54.0435 - val_loss: 71.3104\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 54.4008 - val_loss: 292.4286\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 54.3077 - val_loss: 75.3710\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 54.3749 - val_loss: 124.5252\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 53.6937 - val_loss: 72.0714\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 53.7113 - val_loss: 89.7157\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 55.3547 - val_loss: 69.5665\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 53.2227 - val_loss: 72.5728\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 53.4152 - val_loss: 347.5642\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 53.2853 - val_loss: 81.1810\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 52.5780 - val_loss: 814.4984\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 54.5007 - val_loss: 73.2067\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 53.6023 - val_loss: 562.5496\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 52.8676 - val_loss: 75.2985\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 54.2400 - val_loss: 72.4396\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 53.4432 - val_loss: 76.9594\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 53.6794 - val_loss: 234.9357\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 52.5201 - val_loss: 73.0121\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 52.1813 - val_loss: 578.0989\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 53.1709 - val_loss: 73.5156\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 52.0901 - val_loss: 492.6950\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 53.9765 - val_loss: 72.2076\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 52.0056 - val_loss: 147.8358\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 68s 82ms/step - loss: 52.6356 - val_loss: 76.3972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2225508ac88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.12) Supervised Euclidean for SIMPLED with L2 regularization\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_12_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLED\\train\\0'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLED\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLED\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLED\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kernel_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "\n",
    "model = UNet(filters=32,\n",
    "             layers=4,\n",
    "             activation='linear',\n",
    "             classes=2,\n",
    "             input_shape=(224, 224, 1),\n",
    "             kernel_regularizer=kernel_regularizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True)\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une)\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 75s 89ms/step - loss: 883.9207 - val_loss: 667.9858\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 662.1973 - val_loss: 645.9089\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 639.1671 - val_loss: 640.7653\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 285.1208 - val_loss: 154.2659\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 133.4066 - val_loss: 1384.4052\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 116.9462 - val_loss: 108.2280\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: 116.8532 - val_loss: 101.6094\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 93.1858 - val_loss: 98.2143\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 106.8768 - val_loss: 94.1457\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 83.1229 - val_loss: 100.9462\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 78.8244 - val_loss: 103.8087\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 78.6089 - val_loss: 139.5507\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 77.2140 - val_loss: 1388.0631\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 85.6248 - val_loss: 75.0354\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 65.2041 - val_loss: 74.5823\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 60.0103 - val_loss: 71.6608\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 59.7288 - val_loss: 81.1939\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 61.2721 - val_loss: 68.4257\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 52.6489 - val_loss: 61.1350\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 54.7059 - val_loss: 345.9701\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 53.5090 - val_loss: 57.6719\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 46.6253 - val_loss: 69.2104\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 50.2849 - val_loss: 58.9406\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 68s 80ms/step - loss: 50.8269 - val_loss: 68.2116\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 44.8152 - val_loss: 56.3885\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 40.0741 - val_loss: 67.2251\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 39.1899 - val_loss: 56.2342\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 51.2717 - val_loss: 58.9196\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 39.1553 - val_loss: 56.7581\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 35.9106 - val_loss: 50.5672\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 34.7089 - val_loss: 58.8964\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 35.6516 - val_loss: 60.4665\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 46.2125 - val_loss: 67.1341\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 33.1251 - val_loss: 49.2977\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 31.2442 - val_loss: 52.6911\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: 32.4234 - val_loss: 314.4110\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 34.9145 - val_loss: 51.1450\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 29.7332 - val_loss: 52.6903\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 31.5126 - val_loss: 52.4277\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 36.5296 - val_loss: 117.4768\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 29.6169 - val_loss: 51.1616\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 28.1908 - val_loss: 52.3232\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 29.1563 - val_loss: 48.8353\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 35.0051 - val_loss: 48.1734\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 25.9899 - val_loss: 49.6697\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 26.6964 - val_loss: 163.6355\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 27.5307 - val_loss: 59.1890\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 28.5687 - val_loss: 51.3015\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 31.6671 - val_loss: 48.3851\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 24.5696 - val_loss: 48.2068\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 25.6331 - val_loss: 53.2049\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 25.0215 - val_loss: 50.6542\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 26.0575 - val_loss: 51.3302\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 24.5733 - val_loss: 54.5711\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 26.0762 - val_loss: 63.3542\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 24.7337 - val_loss: 70.5117\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 63s 76ms/step - loss: 25.1254 - val_loss: 51.7826\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 24.6090 - val_loss: 48.2256\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 23.2505 - val_loss: 51.2082\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 23.3969 - val_loss: 46.6395\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 68s 82ms/step - loss: 24.8791 - val_loss: 45.7272\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 23.8998 - val_loss: 46.5675\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 22.2370 - val_loss: 48.8445\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 23.1940 - val_loss: 51.3043\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 24.2175 - val_loss: 52.8135\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 22.3810 - val_loss: 51.8969\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 23.1571 - val_loss: 47.5963\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 22.5855 - val_loss: 46.0625\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 21.3186 - val_loss: 50.3302\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 22.3941 - val_loss: 49.2116\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 21.5623 - val_loss: 61.4033\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 24.4478 - val_loss: 258.9855\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 22.1089 - val_loss: 56.1076\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 23.3878 - val_loss: 74.4090\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 19.5579 - val_loss: 64.1731\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 68s 80ms/step - loss: 21.7556 - val_loss: 57.5933\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: 22.4098 - val_loss: 52.2479\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 66s 78ms/step - loss: 20.7696 - val_loss: 49.6132\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 26.3274 - val_loss: 672.9237\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: 20.2486 - val_loss: 53.3559\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 19.8564 - val_loss: 64.9852\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 23.3937 - val_loss: 65.0900\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 21.1907 - val_loss: 47.4962\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 20.3315 - val_loss: 47.3728\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 21.3728 - val_loss: 45.1840\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 81s 96ms/step - loss: 22.7118 - val_loss: 50.2110\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 144s 171ms/step - loss: 19.5414 - val_loss: 43.5072\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 19.6691 - val_loss: 57.3298\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 27.9872 - val_loss: 87.4056\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: 19.5821 - val_loss: 196.1175\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 18.0100 - val_loss: 47.6437\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 21.5575 - val_loss: 52.2462\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 19.7569 - val_loss: 51.7125\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 20.7640 - val_loss: 63.5242\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 21.3787 - val_loss: 47.1529\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 20.5232 - val_loss: 50.6262\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 19.7938 - val_loss: 920.0153\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 20.1371 - val_loss: 52.1939\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 20.4539 - val_loss: 51.5769\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 19.2770 - val_loss: 48.9559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2227be5c608>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.13) Supervised Euclidean for SIMPLED with SGD\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_13_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLED\\train\\0'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLED\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLED\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLED\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32,\n",
    "             layers=4,\n",
    "             activation='linear',\n",
    "             classes=2,\n",
    "             input_shape=(224, 224, 1),\n",
    "             kernel_regularizer=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True)\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une)\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "optimizer= tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.99)\n",
    "model.compile(optimizer=optimizer, loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 72s 85ms/step - loss: inf - val_loss: inf\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 63s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: inf - val_loss: inf\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: inf - val_loss: inf\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: inf - val_loss: inf\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: inf - val_loss: inf\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: inf - val_loss: inf\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: inf - val_loss: inf\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: inf - val_loss: inf\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: inf - val_loss: inf\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: inf - val_loss: inf\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: inf - val_loss: inf\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: inf - val_loss: inf\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: inf - val_loss: inf\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: inf - val_loss: inf\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 56s 67ms/step - loss: inf - val_loss: inf\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 58s 69ms/step - loss: inf - val_loss: inf\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 57s 68ms/step - loss: inf - val_loss: inf\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 56s 66ms/step - loss: inf - val_loss: inf\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 57s 68ms/step - loss: inf - val_loss: inf\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 57s 68ms/step - loss: inf - val_loss: inf\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 56s 67ms/step - loss: inf - val_loss: inf\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 59s 71ms/step - loss: inf - val_loss: inf\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: inf - val_loss: inf\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 63s 74ms/step - loss: inf - val_loss: inf\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 63s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: inf - val_loss: inf\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: inf - val_loss: inf\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 63s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: inf - val_loss: inf\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 62s 73ms/step - loss: inf - val_loss: inf\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: inf - val_loss: inf\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: inf - val_loss: inf\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: inf - val_loss: inf\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 63s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: inf - val_loss: inf\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: inf - val_loss: inf\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: inf - val_loss: inf\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: inf - val_loss: inf\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: inf - val_loss: inf\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: inf - val_loss: inf\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: inf - val_loss: inf\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 66s 79ms/step - loss: inf - val_loss: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2226aec2d88>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-d933a63c9cea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0muy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muy_field\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_pos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_pos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mx_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_pos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mux\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0my_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0muy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\matplotlib\\image.py:397: UserWarning: Warning: converting a masked element to nan.\n",
      "  dv = (np.float64(self.norm.vmax) -\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\matplotlib\\image.py:398: UserWarning: Warning: converting a masked element to nan.\n",
      "  np.float64(self.norm.vmin))\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\matplotlib\\image.py:405: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_min = np.float64(newmin)\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\matplotlib\\image.py:410: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_max = np.float64(newmax)\n",
      "<string>:6: UserWarning: Warning: converting a masked element to nan.\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\numpy\\ma\\core.py:711: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
