{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The GAN as explained by \"Deep Learning with Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 18\n",
    "height = 18\n",
    "width = 18\n",
    "channels = 2\n",
    "\n",
    "image_width = 728\n",
    "image_height = 728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 18)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10368)             196992    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 9, 9, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 18, 18, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 18, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 18, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 2)         25090     \n",
      "=================================================================\n",
      "Total params: 5,367,682\n",
      "Trainable params: 5,367,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "x = layers.Dense(128 * 9 * 9)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((9, 9, 128))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 18, 18, 2)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       2432      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 527,489\n",
      "Trainable params: 527,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "height=18\n",
    "width=18\n",
    "channels=2\n",
    "\n",
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "#x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "#x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.00008,\n",
    "                                                  clipvalue=1.0,\n",
    "                                                  decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer,\n",
    "                      loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "x = generator(gan_input)\n",
    "x = discriminator(x)\n",
    "gan = keras.models.Model(gan_input, x)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0008,\n",
    "                                         clipvalue=1.0,\n",
    "                                         decay=1e-8)\n",
    "\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN2/train'\n",
    "\n",
    "files = glob.glob(base_path+'/*.json')\n",
    "\n",
    "file_length =len(files)\n",
    "\n",
    "x_position = np.full((file_length, height, width), 0)\n",
    "y_position = np.full((file_length, height, width), 0)\n",
    "\n",
    "for file_id, file in enumerate(files):\n",
    "    with open(file) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        for key, value in data.items():\n",
    "            key = int(key)\n",
    "        \n",
    "            y = key // height \n",
    "            x = key % width\n",
    "\n",
    "            x_position[file_id][y][x] = value[0]\n",
    "            y_position[file_id][y][x] = value[1]\n",
    "            \n",
    "np.save('x_pos', x_position)\n",
    "np.save('y_pos', y_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_position = np.load('x_pos.npy')\n",
    "y_position = np.load('y_pos.npy')\n",
    "\n",
    "x_position = x_position / image_width\n",
    "y_position = y_position / image_height\n",
    "\n",
    "a = x_position\n",
    "\n",
    "# Zero padding\n",
    "#x_position = np.pad(x_position,[(0,0),(1,1),(1,1)],constant_values=0)\n",
    "#y_position = np.pad(y_position,[(0,0),(1,1),(1,1)],constant_values=0)\n",
    "\n",
    "x_position = x_position[:,:,:,np.newaxis]\n",
    "y_position = y_position[:,:,:,np.newaxis]\n",
    "\n",
    "x_train = np.concatenate((x_position, y_position), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 18, 18, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.7112607359886169\n",
      "adversarial loss: 0.6937574148178101\n",
      "discriminator loss: 0.687309980392456\n",
      "adversarial loss: 0.7942737340927124\n",
      "discriminator loss: 0.6342492699623108\n",
      "adversarial loss: 0.9576197862625122\n",
      "discriminator loss: 0.6975255012512207\n",
      "adversarial loss: 0.707342267036438\n",
      "discriminator loss: 0.6470522880554199\n",
      "adversarial loss: 0.8273881673812866\n",
      "discriminator loss: 0.6123018264770508\n",
      "adversarial loss: 0.9334529638290405\n",
      "discriminator loss: 0.5875279307365417\n",
      "adversarial loss: 1.1727354526519775\n",
      "discriminator loss: 0.5589766502380371\n",
      "adversarial loss: 1.3346006870269775\n",
      "discriminator loss: 0.5289129018783569\n",
      "adversarial loss: 1.3716436624526978\n",
      "discriminator loss: 0.5209511518478394\n",
      "adversarial loss: 1.3833038806915283\n",
      "discriminator loss: 0.5011485815048218\n",
      "adversarial loss: 1.4920706748962402\n",
      "discriminator loss: 0.4682406783103943\n",
      "adversarial loss: 1.6508150100708008\n",
      "discriminator loss: 0.4559561312198639\n",
      "adversarial loss: 1.557044267654419\n",
      "discriminator loss: 0.42414379119873047\n",
      "adversarial loss: 1.7166435718536377\n",
      "discriminator loss: 0.40151748061180115\n",
      "adversarial loss: 1.6990629434585571\n"
     ]
    }
   ],
   "source": [
    "iterations = 30\n",
    "batch_size = 20\n",
    "save_dir = 'gan_lasten2'\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    # Get random 'fake' images\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim)) # sample with mean=0 and std=1.0\n",
    "    \n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    \n",
    "    # Get 'real' images, merge them with 'fake' and create labels\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start:stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    \n",
    "    labels += 0.05 * np.random.random(labels.shape) # important to introduce some randomness\n",
    "    \n",
    "    # Train the discriminator on 'real' and 'fake' images\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "\n",
    "    # Get random images from generator but treat them as 'real' now\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "    \n",
    "    # Train the generator's weights\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    # Finalize loop\n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "        \n",
    "    if step % 2 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        print('discriminator loss:', d_loss)\n",
    "        print('adversarial loss:', a_loss)\n",
    "        \n",
    "        gen = generated_images[0,:,:,0][:,:,np.newaxis]\n",
    "        real = real_images[0,:,:,0][:,:,np.newaxis]\n",
    "        \n",
    "        img = image.array_to_img(gen * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'generated' + str(step) + '.png'))\n",
    "        \n",
    "        img = image.array_to_img(real * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'real' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_latent_vectors = np.random.normal(size=(batch_size, latent_dim)) # sample with mean=0 and std=1.0\n",
    "    \n",
    "generated_images = generator.predict(random_latent_vectors)\n",
    "generated_images *= 255\n",
    "\n",
    "for i in range(1):\n",
    "    img = generated_images[i,:,:,0]\n",
    "    img = img[:,:,np.newaxis]\n",
    "    img = keras.preprocessing.image.array_to_img(img)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
