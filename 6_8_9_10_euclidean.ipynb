{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements\n",
    "Following packages are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "from simplegen import SIMPLESequence\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "from unet import UNet\n",
    "from unet import preprocess_input as pre_une\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Checks\n",
    "The version of tensorflow as well as the GPU support are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality\n",
    "Necessary funcionality is added here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cube(img, x, y, val):\n",
    "    \n",
    "    img[y][x] = val\n",
    "    img[y][x-1] = val\n",
    "    img[y][x+1] = val\n",
    "    img[y-1][x] = val\n",
    "    img[y-1][x-1] = val\n",
    "    img[y-1][x+1] = val\n",
    "    img[y+1][x] = val\n",
    "    img[y+1][x-1] = val\n",
    "    img[y+1][x+1] = val  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.8) Supervised Euclidean for SIMPLED with fixed image\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_8_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLED\\train\\0'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLED\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLED\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLED\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True,\n",
    "                           multi_channel='fixed')\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une,\n",
    "                                multi_channel='fixed')\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 82s 98ms/step - loss: 722.3557 - val_loss: 609.9671\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 73s 86ms/step - loss: 295.2440 - val_loss: 69.2219\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 63.9594 - val_loss: 40.3651\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 43.8902 - val_loss: 134.2030\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 34.9258 - val_loss: 44.4679\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 29.1634 - val_loss: 24.8344\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 26.7894 - val_loss: 35.6561\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 24.6091 - val_loss: 23.7568\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 21.0550 - val_loss: 21.3612\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 20.4461 - val_loss: 25.2225\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 15.3134 - val_loss: 18.1396\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 16.7065 - val_loss: 35.5319\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 14.9690 - val_loss: 18.6292\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 14.2445 - val_loss: 10.4626\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 11.7442 - val_loss: 13.6364\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 10.3303 - val_loss: 14.6317\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 9.4774 - val_loss: 12.4873\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 8.8505 - val_loss: 8.6820\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 8.4456 - val_loss: 10.3180\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 7.0369 - val_loss: 10.1059\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 7.7543 - val_loss: 7.7725\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 6.5877 - val_loss: 6.6305\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 6.4059 - val_loss: 11.5036\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 5.6017 - val_loss: 6.6035\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 7.3943 - val_loss: 17.0442\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 4.1597 - val_loss: 7.6560\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 3.4855 - val_loss: 6.6394\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 4.9653 - val_loss: 9.1978\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 4.2180 - val_loss: 5.4700\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 3.7530 - val_loss: 4.8320\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 3.4586 - val_loss: 8.7300\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 3.4333 - val_loss: 6.4633\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 3.4488 - val_loss: 5.2551\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 2.9256 - val_loss: 5.7641\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.8630 - val_loss: 5.3245\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.7549 - val_loss: 7.1949\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 2.6176 - val_loss: 4.5103\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 2.5950 - val_loss: 6.2699\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 2.2338 - val_loss: 65.5644\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 2.3926 - val_loss: 8.9356\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 3.2111 - val_loss: 4.2180\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.7937 - val_loss: 3.6373\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.1951 - val_loss: 4.0215\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 2.1402 - val_loss: 4.7524\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.3877 - val_loss: 4.7369\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.3213 - val_loss: 4.6151\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.7298 - val_loss: 3.6267\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 2.9429 - val_loss: 7.0996\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 1.2933 - val_loss: 4.2492\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 1.4630 - val_loss: 4.0198\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.5628 - val_loss: 4.5323\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 73s 86ms/step - loss: 1.3257 - val_loss: 3.9657\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 2.0079 - val_loss: 3.9582\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.4038 - val_loss: 3.6447\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.2383 - val_loss: 4.1534\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 1.2500 - val_loss: 4.7914\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.5824 - val_loss: 4.6598\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.7412 - val_loss: 3.7935\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.7160 - val_loss: 3.9693\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.8121 - val_loss: 3.2140\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 1.3593 - val_loss: 4.2506\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.9063 - val_loss: 3.3570\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 1.0077 - val_loss: 3.1178\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.1538 - val_loss: 3.6700\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.0701 - val_loss: 3.7147\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.0757 - val_loss: 3.7834\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.8659 - val_loss: 3.3312\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.5105 - val_loss: 4.3140\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.2395 - val_loss: 4.6605\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 0.6636 - val_loss: 3.1430\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.0221 - val_loss: 3.5977\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.0470 - val_loss: 19.1298\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 0.9958 - val_loss: 3.6596\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6393 - val_loss: 3.1894\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.3009 - val_loss: 4.0637\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.6813 - val_loss: 3.2044\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 0.8898 - val_loss: 3.6035\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6604 - val_loss: 2.8032\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 69s 82ms/step - loss: 1.1199 - val_loss: 3.1837\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.8005 - val_loss: 3.2592\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.5610 - val_loss: 3.1302\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.7603 - val_loss: 2.9978\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.2282 - val_loss: 3.9371\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 0.6977 - val_loss: 2.7065\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.5404 - val_loss: 2.9330\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.6324 - val_loss: 3.4963\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6906 - val_loss: 2.8284\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.1340 - val_loss: 10.4809\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 0.7786 - val_loss: 3.1478\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 75s 89ms/step - loss: 0.4443 - val_loss: 2.9265\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.5222 - val_loss: 3.2656\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 0.7137 - val_loss: 2.9344\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6094 - val_loss: 29.6343\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.6618 - val_loss: 3.9200\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.6730 - val_loss: 3.3195\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.5864 - val_loss: 3.0188\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.5027 - val_loss: 2.9649\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.6682 - val_loss: 3.4974\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.5397 - val_loss: 2.9135\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.9166 - val_loss: 3.0209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20cc50db048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          #use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.9) Supervised Euclidean for SIMPLED with difference image\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_9_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLED\\train\\0'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLED\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLED\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLED\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True,\n",
    "                           multi_channel='diff')\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une,\n",
    "                                multi_channel='diff')\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = train_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       ...,\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,:,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Julian\\workspace\\endolas\\simplegen.py:129: RuntimeWarning: invalid value encountered in true_divide\n",
      "  image_diff = 255.0 * image_diff / image_diff.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Julian\\workspace\\endolas\\simplegen.py:129: RuntimeWarning: invalid value encountered in true_divide\n",
      "  image_diff = 255.0 * image_diff / image_diff.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 79s 94ms/step - loss: 839.9462 - val_loss: 1154.7513\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 869.8591 - val_loss: 4064.9566\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 741.6891 - val_loss: 1843.6055\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 698.1401 - val_loss: 4865.0217\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 683.6324 - val_loss: 7445.8121\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 74s 88ms/step - loss: 677.5561 - val_loss: 1462.5711\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 674.6057 - val_loss: 4304.5708\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 673.2408 - val_loss: 2507.0141\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 672.2076 - val_loss: 5259.3942\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 670.2299 - val_loss: 1567.6938\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 669.3433 - val_loss: 8294.9734\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 667.8607 - val_loss: 6707.3853\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 667.9544 - val_loss: 12533.1362\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 666.9700 - val_loss: 10204.6904\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 666.5674 - val_loss: 3182.3529\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 665.7496 - val_loss: 18937.8301\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 665.6106 - val_loss: 8687.3048\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 74s 88ms/step - loss: 664.5185 - val_loss: 8747.2800\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 665.1169 - val_loss: 8614.3310\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 664.1051 - val_loss: 9789.5079\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 663.9527 - val_loss: 5732.9681\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 663.6057 - val_loss: 7292.1086\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 663.0203 - val_loss: 12160.5839\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 662.2160 - val_loss: 11675.4371\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 662.5415 - val_loss: 10945.9271\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 662.5941 - val_loss: 8409.1455\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 73s 87ms/step - loss: 662.2449 - val_loss: 13620.3092\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 662.0308 - val_loss: 7793.7909\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 661.4261 - val_loss: 4961.2474\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 662.0818 - val_loss: 4615.7049\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 661.5752 - val_loss: 7129.1069\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 661.1677 - val_loss: 3020.8251\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 660.9717 - val_loss: 7745.6403\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 661.0709 - val_loss: 3544.0615\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 660.3304 - val_loss: 6558.5907\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 659.9664 - val_loss: 5401.2090\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 659.7861 - val_loss: 2517.4311\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 659.8058 - val_loss: 4611.9086\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 660.3136 - val_loss: 4022.5391\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 660.0542 - val_loss: 6884.2036\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 659.2608 - val_loss: 3072.4886\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 658.7258 - val_loss: 3772.7324\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 659.2830 - val_loss: 1574.2572\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 659.0936 - val_loss: 1390.0374\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 658.5937 - val_loss: 2250.5492\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 658.6560 - val_loss: 2058.6215\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 658.3364 - val_loss: 1977.7434\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 658.5829 - val_loss: 2319.9733\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 658.0853 - val_loss: 3971.4860\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 657.9429 - val_loss: 3022.7024\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 657.7640 - val_loss: 4006.7390\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 657.3049 - val_loss: 3301.9941\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 657.1732 - val_loss: 6389.1073\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 657.0163 - val_loss: 4899.3167\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 656.9035 - val_loss: 2334.6884\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 656.6824 - val_loss: 3962.5113\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 656.8777 - val_loss: 2731.6938\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 655.7483 - val_loss: 2920.6627\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 75s 89ms/step - loss: 656.7725 - val_loss: 2633.0478\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 655.7421 - val_loss: 4697.5509\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 655.7065 - val_loss: 3130.6300\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 655.6893 - val_loss: 5923.6532\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 655.4943 - val_loss: 9735.0942\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 655.4304 - val_loss: 8684.6280\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 655.0950 - val_loss: 9366.2586\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 655.1096 - val_loss: 7772.3395\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 653.6975 - val_loss: 8086.7171\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 654.4043 - val_loss: 6441.7503\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 653.9404 - val_loss: 4315.2534\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 654.1677 - val_loss: 6974.2475\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 653.0461 - val_loss: 5286.5049\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 653.6491 - val_loss: 7611.0746\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 653.4378 - val_loss: 7068.0334\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 653.2227 - val_loss: 8274.6803\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 652.8173 - val_loss: 6648.6442\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 73s 86ms/step - loss: 652.6103 - val_loss: 7182.0573\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 652.6247 - val_loss: 6063.2471\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 75s 90ms/step - loss: 652.0835 - val_loss: 5482.3776\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 651.9201 - val_loss: 4927.7967\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 74s 88ms/step - loss: 651.3849 - val_loss: 5375.4925\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 651.4203 - val_loss: 7119.1953\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 651.0909 - val_loss: 6078.8338\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 650.5286 - val_loss: 3789.1765\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 650.9451 - val_loss: 6070.9046\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 650.7498 - val_loss: 6163.6043\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 650.0199 - val_loss: 5976.2428\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 74s 88ms/step - loss: 649.2316 - val_loss: 6637.0200\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 650.0399 - val_loss: 4571.1781\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 649.7279 - val_loss: 5352.6527\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 649.6011 - val_loss: 4942.9829\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 74s 88ms/step - loss: 648.8632 - val_loss: 6205.9061\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 648.5201 - val_loss: 5576.8794\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 649.0101 - val_loss: 6519.3450\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 648.4436 - val_loss: 8053.5708\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 647.8984 - val_loss: 8131.9243\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 647.9728 - val_loss: 4652.1478\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 647.1591 - val_loss: 5274.8849\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 647.4203 - val_loss: 7670.9844\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 647.2458 - val_loss: 4979.9354\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 646.3871 - val_loss: 7386.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ca03f9b88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          #use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.10) Supervised Euclidean for SIMPLED with difference image and gradient\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_10_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLED\\train\\0'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLED\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLED\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLED\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True,\n",
    "                           multi_channel='grad')\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une,\n",
    "                                multi_channel='grad')\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Julian\\workspace\\endolas\\simplegen.py:136: RuntimeWarning: invalid value encountered in true_divide\n",
      "  image_diff = 255.0 * image_diff / image_diff.max()\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\skimage\\filters\\rank\\generic.py:119: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  out_dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "D:\\Julian\\workspace\\endolas\\simplegen.py:136: RuntimeWarning: invalid value encountered in true_divide\n",
      "  image_diff = 255.0 * image_diff / image_diff.max()\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\skimage\\filters\\rank\\generic.py:119: UserWarning: Possible precision loss converting image of type float32 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
      "  out_dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 137s 163ms/step - loss: 815.4325 - val_loss: 1250.0230\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 150s 178ms/step - loss: 877.2024 - val_loss: 1919.5403\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 151s 180ms/step - loss: 753.7293 - val_loss: 20131.9531\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 151s 179ms/step - loss: 703.7980 - val_loss: 44238.7665\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 157s 186ms/step - loss: 685.9553 - val_loss: 68452.7398\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 155s 185ms/step - loss: 678.1999 - val_loss: 42379.2052\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 157s 187ms/step - loss: 674.9416 - val_loss: 39023.9318\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 158s 188ms/step - loss: 673.2630 - val_loss: 67738.0150\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 131s 156ms/step - loss: 672.2045 - val_loss: 46857.3610\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 132s 157ms/step - loss: 670.3289 - val_loss: 90719.8666\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 149s 177ms/step - loss: 669.4735 - val_loss: 24488.3569\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 131s 156ms/step - loss: 667.6838 - val_loss: 107333.4052\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 132s 157ms/step - loss: 668.2971 - val_loss: 13464.8785\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 133s 159ms/step - loss: 667.1152 - val_loss: 23367.2066\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 156s 185ms/step - loss: 666.6486 - val_loss: 22372.5994\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 149s 178ms/step - loss: 665.9514 - val_loss: 26936.2112\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 148s 177ms/step - loss: 665.8591 - val_loss: 32497.4344\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 131s 156ms/step - loss: 664.8367 - val_loss: 6221.3390\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 151s 180ms/step - loss: 665.5359 - val_loss: 13944.8429\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 147s 175ms/step - loss: 664.5784 - val_loss: 31736.5274\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 154s 184ms/step - loss: 664.6052 - val_loss: 24055.8545\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 153s 182ms/step - loss: 664.2330 - val_loss: 21787.5990\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 151s 180ms/step - loss: 663.5757 - val_loss: 33545.5792\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 148s 176ms/step - loss: 662.8672 - val_loss: 41762.3072\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 151s 179ms/step - loss: 663.2491 - val_loss: 21445.0618\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 131s 155ms/step - loss: 663.1417 - val_loss: 30985.9974\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 156s 186ms/step - loss: 662.9367 - val_loss: 29991.5457\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 144s 171ms/step - loss: 662.6527 - val_loss: 33397.8960\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 154s 184ms/step - loss: 662.2426 - val_loss: 24503.1504\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 155s 184ms/step - loss: 662.6810 - val_loss: 47094.4400\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 154s 183ms/step - loss: 662.2700 - val_loss: 41949.8818\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 145s 173ms/step - loss: 661.6675 - val_loss: 28446.8285\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 155s 185ms/step - loss: 661.5997 - val_loss: 29028.4770\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 158s 188ms/step - loss: 661.7739 - val_loss: 33735.2617\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 155s 185ms/step - loss: 660.9700 - val_loss: 21772.4468\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 147s 175ms/step - loss: 660.6720 - val_loss: 32703.8709\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 135s 161ms/step - loss: 660.3480 - val_loss: 39462.8088\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 155s 185ms/step - loss: 660.5579 - val_loss: 32722.2094\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 149s 177ms/step - loss: 661.0756 - val_loss: 33893.1083\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 150s 179ms/step - loss: 660.8965 - val_loss: 36943.0106\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 150s 179ms/step - loss: 660.0541 - val_loss: 33328.6893\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 154s 184ms/step - loss: 659.7391 - val_loss: 26918.4578\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 151s 180ms/step - loss: 660.2773 - val_loss: 41774.4533\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 146s 174ms/step - loss: 659.9936 - val_loss: 43590.5005\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 157s 187ms/step - loss: 659.5417 - val_loss: 39316.3967\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 153s 182ms/step - loss: 659.7112 - val_loss: 41158.2789\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 153s 182ms/step - loss: 659.3880 - val_loss: 32463.2497\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 131s 156ms/step - loss: 659.7257 - val_loss: 45346.0207\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 151s 180ms/step - loss: 659.1221 - val_loss: 36450.3839\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 132s 158ms/step - loss: 658.8727 - val_loss: 35012.7268\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 134s 160ms/step - loss: 658.8715 - val_loss: 33197.0592\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 151s 180ms/step - loss: 658.4623 - val_loss: 39826.3131\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 152s 181ms/step - loss: 658.4297 - val_loss: 34181.6199\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 136s 161ms/step - loss: 658.1693 - val_loss: 36669.7424\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 146s 174ms/step - loss: 658.1745 - val_loss: 42596.4755\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 155s 184ms/step - loss: 658.0814 - val_loss: 30699.4829\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 132s 157ms/step - loss: 658.1685 - val_loss: 38816.6620\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 132s 157ms/step - loss: 657.1275 - val_loss: 52713.5295\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 131s 157ms/step - loss: 658.3194 - val_loss: 32634.8725\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 153s 183ms/step - loss: 657.2334 - val_loss: 32445.6200\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 149s 178ms/step - loss: 657.2521 - val_loss: 25911.7786\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 155s 184ms/step - loss: 657.3362 - val_loss: 35362.6566\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 150s 178ms/step - loss: 657.2752 - val_loss: 33984.6160\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 146s 174ms/step - loss: 657.1932 - val_loss: 38500.8626\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 154s 183ms/step - loss: 656.9635 - val_loss: 37820.5778\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 159s 190ms/step - loss: 656.7258 - val_loss: 40842.9637\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 154s 183ms/step - loss: 655.5034 - val_loss: 49688.6628\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 152s 181ms/step - loss: 656.3929 - val_loss: 28418.7939\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 155s 184ms/step - loss: 655.9081 - val_loss: 37831.9016\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 157s 187ms/step - loss: 655.9854 - val_loss: 28144.6965\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 146s 174ms/step - loss: 655.0495 - val_loss: 24600.0097\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 152s 181ms/step - loss: 655.5815 - val_loss: 28412.5939\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 146s 174ms/step - loss: 655.5187 - val_loss: 26672.6838\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 150s 179ms/step - loss: 655.2923 - val_loss: 29020.5641\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 149s 178ms/step - loss: 655.0829 - val_loss: 32393.3206\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 151s 179ms/step - loss: 654.9131 - val_loss: 33860.4097\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 155s 185ms/step - loss: 654.8942 - val_loss: 34794.1306\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 151s 180ms/step - loss: 654.4790 - val_loss: 28588.4297\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 151s 180ms/step - loss: 654.1978 - val_loss: 27709.4504\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 153s 182ms/step - loss: 653.8935 - val_loss: 28464.4756\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 155s 184ms/step - loss: 653.9705 - val_loss: 31702.8865\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 152s 181ms/step - loss: 653.7984 - val_loss: 30193.5095\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 133s 158ms/step - loss: 653.1879 - val_loss: 34231.3419\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 132s 157ms/step - loss: 653.5965 - val_loss: 32481.3142\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 153s 182ms/step - loss: 653.4786 - val_loss: 34936.9019\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 150s 179ms/step - loss: 653.0177 - val_loss: 31197.1367\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 132s 157ms/step - loss: 652.2179 - val_loss: 22705.9054\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 154s 183ms/step - loss: 653.0165 - val_loss: 24780.6429\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 147s 176ms/step - loss: 652.7754 - val_loss: 28190.3766\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 155s 185ms/step - loss: 652.6818 - val_loss: 30680.6731\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 144s 172ms/step - loss: 652.4130 - val_loss: 25770.9412\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 150s 179ms/step - loss: 651.6713 - val_loss: 29353.2089\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 156s 185ms/step - loss: 652.4519 - val_loss: 26585.5019\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 132s 157ms/step - loss: 651.6937 - val_loss: 26167.1427\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 150s 178ms/step - loss: 651.2617 - val_loss: 31193.4013\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 155s 184ms/step - loss: 651.5718 - val_loss: 24431.3622\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 153s 182ms/step - loss: 650.8079 - val_loss: 26829.1656\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 149s 178ms/step - loss: 651.2208 - val_loss: 24659.0909\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 137s 163ms/step - loss: 651.0184 - val_loss: 31889.7383\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 157s 187ms/step - loss: 650.3062 - val_loss: 30234.0279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ca9fa4988>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          #use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARIklEQVR4nO3dfYxc1X3G8e8TYxzxVuzwIjCmNmCiQkUXYvEiCkpLE4NVxVCV1KgCN0VdkEACKZVqQGqt/pWmASTU1pERKCaivBTz4j+cGsdCQZEwYBNjcIyxTRxYbNlAIoNK5GDz6x/3jBnWu+x47ty9d/Y8H2k1d87cmfmNx/PMOXdmzlFEYGb5+lLdBZhZvRwCZplzCJhlziFgljmHgFnmHAJmmassBCRdKWmLpG2SFlV1P2ZWjqr4noCkScCbwDeAIeBl4LqI+GXP78zMSqmqJ3AhsC0i3oqI3wOPAvMrui8zK+GIim53OvBO2/kh4KLRdj5h2qSYOWMyb248qqJyzPJ29nkfs37jvvcj4sThl1UVAhqh7XPjDkmDwCDA6dOP4KVVM5h76kBF5ZjlbdWqDUw6ZduvR7qsquHAEDCj7fxpwM72HSJiaUTMiYg5v333WAeAWYW+6PVVVQi8DMyWNEvSkcACYEVF92VmJVQyHIiI/ZJuBVYBk4AHI2JTFfdlZuVUdUyAiFgJrKzq9s2sN/yNQbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMtc1yEgaYak5yRtlrRJ0m2pfbGkdyVtSH/zeleumfVamUlF9gPfjYhXJB0LrJe0Ol12b0T8oHx5Zla1rkMgInYBu9L2R5I2U0w1bmZ9pCfHBCTNBM4HXkxNt0raKOlBSVN7cR9mVo3SISDpGGA5cHtEfAgsAc4EBih6CnePcr1BSeskrfuEfWXLMLMulQoBSZMpAuDhiHgSICJ2R8SBiPgUuJ9iSbJDtK87MJkpZcowsxLKfDog4AFgc0Tc09Z+Sttu1wCvd1+emVWtzKcDlwLXA69J2pDa7gSukzRAsezYDuCmUhWaWaXKfDrwc0Zec9BrDZj1EX9j0CxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLXJmZhQCQtAP4CDgA7I+IOZKmAY8BMylmF/p2RPy27H2ZWe/1qifwZxExEBFz0vlFwJqImA2sSefNrIGqGg7MB5al7WXA1RXdj5mV1IsQCOBZSeslDaa2k9MKRa2Vik4afiWvO2DWDKWPCQCXRsROSScBqyW90cmVImIpsBTgOE2LHtRhZl0o3ROIiJ3pdA/wFMViI7tb6w+k0z1l78fMqlF2BaKj04rESDoa+CbFYiMrgIVpt4XAM2Xux8yqU3Y4cDLwVLEYEUcA/x0R/yvpZeBxSTcCbwPXlrwfM6tIqRCIiLeAPxmh/QPgijK3bWbjw98YNMucQ8Ascw4Bs8w5BMwy14svC5kdlvcHLzm4fcLSF2qsxMA9AbPsuSdgY/I798TmEJjgmvgCbkodVvBwwCxz7gk0wKqdGw5uzz11oKe3vX7xks9ue2l3tz38nbuKeqv8N7Av5p5Aw7w/eMnnuvBmVXMImGXOw4EGaHV/q+gBVNG17pfbtM44BBrER82tDh4OmGWu656ApK9SrC3Qcgbwz8DxwD8A76X2OyNiZdcVmlmlug6BiNgCDABImgS8SzHH4HeAeyPiBz2p0Mwq1avhwBXA9oj4dY9uz8zGSa9CYAHwSNv5WyVtlPSgpKk9ug8zq0DpEJB0JPAt4H9S0xLgTIqhwi7g7lGu58VHzBqgFz2Bq4BXImI3QETsjogDEfEpcD/FOgSHiIilETEnIuZMZkoPyjCzbvQiBK6jbSjQWnQkuYZiHQIza6hSXxaSdBTwDeCmtubvSxqgWKNwx7DLzKxhyq478DHwlWFt15eqyMzGlb8xaJY5h4BZ5hwCZplzCJhlzj8lto41cdJSK88hYLVzuNTLwwGzzLknYB3zu/TE5BBogCqn2+6H6cFPWPrCZ7e52PMNjjcPBxrGU47beHMImGXOw4EG8JTjHgLUySHQID7wZnXwcMAscw4Bs8x1FAJpwtA9kl5va5smabWkrel0amqXpPskbUuTjV5QVfFmVl6nPYEfAVcOa1sErImI2cCadB6KOQdnp79BiolHzayhOgqBiHge+M2w5vnAsrS9DLi6rf2hKKwFjh8276CZNUiZYwInR8QugHR6UmqfDrzTtt9QajOzBqriI0KN0BaH7CQNUgwX+DJHVVCGmXWiTE9gd6ubn073pPYhYEbbfqcBO4df2esOmDVDmRBYASxM2wuBZ9rab0ifElwM7G0NG8yseToaDkh6BPg6cIKkIeBfgO8Bj0u6EXgbuDbtvhKYB2wDPqZYpdjMGqqjEIiI60a56IoR9g3gljJFmdn48TcGzTLnEDDLnH9FaBOWJzDtjEPAGmHvyrMObv/BvG01VpIfDwfMMueewATXy0lBW93r9YuL34RdvOGvD17WxHfv1hBg1c4NsLho8wxGh3IIZKpp3e+1A08c3J6LX6jjycMBs8yp+G5PvY7TtLhIh3zvyHpgtCPkTesJWPV+Gk+sj4g5w9s9HMiUX/jW4hBoqF69U/vzcRuLjwmYZc4hYJY5DwcaymN2Gy/uCZhlziFglrkxQ2CUhUf+XdIbaXGRpyQdn9pnSvqdpA3p74dVFm9m5XXSE/gRhy48shr444g4D3gTuKPtsu0RMZD+bu5NmWZWlTFDYKSFRyLi2YjYn86upZhR2Mz6UC+OCfw98JO287Mk/ULSzyRdNtqVJA1KWidp3Sfs60EZZtaNUh8RSroL2A88nJp2AadHxAeSvgY8LenciPhw+HUjYimwFIrfDpSpw8y613VPQNJC4C+Bv00zDBMR+yLig7S9HtgOnN2LQs2sGl2FgKQrgX8CvhURH7e1nyhpUto+g2Jl4rd6UaiZVWPM4cAoC4/cAUwBVksCWJs+Cbgc+FdJ+4EDwM0RMXw1YzNrkDFDYJSFRx4YZd/lwPKyRZnZ+PFvB2xC87TjY3MINEAvJwMdz9tuafosRa2JUVnsiUZH4hCwxmp6uEwU/gFRRtq7xrnwEGBs7gk0QJVd1NZtVxkATX+X9hDgizkEMtUPXe2m1jXROAQarJdHtt0tttE4BBpq78qzmMx7AHzy9Ik1V2MTmUMgU+5qW4s/HegD7spbldwTaCi/U9t4cU/ALHMOAbPMOQTMMucQMMtct+sOLJb0btv6AvPaLrtD0jZJWyTNrapwM+uNbtcdALi3bX2BlQCSzgEWAOem6/xXa7oxM2umrtYd+ALzgUfThKO/ArYBF5aoz8wqVuaYwK1pGbIHJU1NbdOBd9r2GUpth/C6A2bN0G0ILAHOBAYo1hq4O7VrhH1HXFMgIpZGxJyImDOZKV2WYWZldRUCEbE7Ig5ExKfA/XzW5R8CZrTtehqws1yJZlalbtcdOKXt7DVA65ODFcACSVMkzaJYd+ClciWaWZW6XXfg65IGKLr6O4CbACJik6THgV9SLE92S0QcqKZ0M+sFpRXEanWcpsVFuqLuMswmtJ/GE+sjYs7wdv+KsAH6fcrxXuiXOicih4A1zvuDlxycQ6GquRD7YY7F8eLfDphlzj2BBhiPKcer1It31bmnDmS5LkITOASsMUaaRq2qrnruQ4B2DoFMeUxsLQ4BK80h0t98YDBDHntbO/cEMtVa0MTTmZtDoA/0cjkys+EcAhlykFg7h0Af8IvWquQDg2aZcwiYZc4hYJa5btcdeKxtzYEdkjak9pmSftd22Q+rLN7MyuvkwOCPgP8AHmo1RMTftLYl3Q3sbdt/e0T4B+FmfWLMEIiI5yXNHOkySQK+Dfx5b8sys/FS9pjAZcDuiNja1jZL0i8k/UzSZSVv38wqVvZ7AtcBj7Sd3wWcHhEfSPoa8LSkcyPiw+FXlDQIDAJ8maNKlmFm3eq6JyDpCOCvgMdabWn5sQ/S9npgO3D2SNf34iNmzVBmOPAXwBsRMdRqkHRiawFSSWdQrDvwVrkSzaxKnXxE+AjwAvBVSUOSbkwXLeDzQwGAy4GNkl4FngBujohOFzM1sxp08unAdaO0/90IbcuB5eXLMrPx4h8QWbY8xVrBXxs2y5x7Apnzu6E5BCxbDr2ChwNmmXNPIHN+NzSHQB/x+N2q4OGAWeYcAmaZ83Cgj3gIYFVwT8Ascw4Bs8w5BMwy5xAwy5xDwCxznUwqMkPSc5I2S9ok6bbUPk3Saklb0+nU1C5J90naJmmjpAuqfhBm1r1OegL7ge9GxB8BFwO3SDoHWASsiYjZwJp0HuAqimnFZlNMJLqk51WbWc+MGQIRsSsiXknbHwGbgenAfGBZ2m0ZcHXang88FIW1wPGSTul55WbWE4d1TCAtQnI+8CJwckTsgiIogJPSbtOBd9quNpTazKyBOg4BScdQzB94+0jrCLTvOkJbjHB7g5LWSVr3Cfs6LcPMeqyjEJA0mSIAHo6IJ1Pz7lY3P53uSe1DwIy2q58G7Bx+m+3rDnxp9nHd1m9mY9i78qzP/QJ1uE4+HRDwALA5Iu5pu2gFsDBtLwSeaWu/IX1KcDGwtzVsMLPm6eQHRJcC1wOvtZYgB+4Evgc8ntYheBu4Nl22EpgHbAM+Br7T04rNrKc6WXfg54w8zge4YoT9A7jlcIqYtHXf6Pdg2fNkKuWM9W/mbwyaZc7zCVjj+d2/Wu4JmGXOIWCWOQ8H7CAfgMuTewJmmXMImGXOw4EJpGx33kOAPLknYJY5h4BZ5jwcmEDcnbduuCdgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYaEQJnn/cxq3ZuGHtHM+vKF72+VMwGVi9J7wH/B7xfdy0lnEB/1w/9/xj6vX6o9jH8YUScOLyxESEAIGldRMypu45u9Xv90P+Pod/rh3oeQyOGA2ZWH4eAWeaaFAJL6y6gpH6vH/r/MfR7/VDDY2jMMQEzq0eTegJmVoPaQ0DSlZK2SNomaVHd9XRK0g5Jr0naIGldapsmabWkrel0at11tpP0oKQ9kl5vaxux5rSW5H3pedko6YL6Kj9Y60j1L5b0bnoeNkia13bZHan+LZLm1lP1ZyTNkPScpM2SNkm6LbXX+xxERG1/wCRgO3AGcCTwKnBOnTUdRu07gBOGtX0fWJS2FwH/Vnedw+q7HLgAeH2sminWk/wJxQJxFwMvNrT+xcA/jrDvOen/0xRgVvp/Nqnm+k8BLkjbxwJvpjprfQ7q7glcCGyLiLci4vfAo8D8mmsqYz6wLG0vA66usZZDRMTzwG+GNY9W83zgoSisBY5vLUVfl1HqH8184NGI2BcRv6JYIPfCyorrQETsiohX0vZHwGZgOjU/B3WHwHTgnbbzQ6mtHwTwrKT1kgZT28mRlmFPpyfVVl3nRqu5n56bW1N3+cG2IVij65c0EzgfeJGan4O6Q2CktYj75eOKSyPiAuAq4BZJl9ddUI/1y3OzBDgTGAB2AXen9sbWL+kYYDlwe0R8+EW7jtDW88dQdwgMATPazp8G7KyplsMSETvT6R7gKYqu5u5Wdy2d7qmvwo6NVnNfPDcRsTsiDkTEp8D9fNblb2T9kiZTBMDDEfFkaq71Oag7BF4GZkuaJelIYAGwouaaxiTpaEnHtraBbwKvU9S+MO22EHimngoPy2g1rwBuSEeoLwb2trqsTTJsjHwNxfMARf0LJE2RNAuYDbw03vW1kyTgAWBzRNzTdlG9z0GdR0vbjoC+SXH09q666+mw5jMojjy/Cmxq1Q18BVgDbE2n0+qudVjdj1B0mT+heJe5cbSaKbqi/5mel9eAOQ2t/8epvo3pRXNK2/53pfq3AFc1oP4/pejObwQ2pL95dT8H/sagWebqHg6YWc0cAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFglrn/B7/mJUAyB5XSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
