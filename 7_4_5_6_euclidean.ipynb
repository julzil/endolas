{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements\n",
    "Following packages are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "import closs\n",
    "import ccall\n",
    "\n",
    "from simplegen import SIMPLESequence\n",
    "from lastengen import LASTENSequence\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "from unet import UNet\n",
    "from unet import preprocess_input as pre_une\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Checks\n",
    "The version of tensorflow as well as the GPU support are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality\n",
    "Necessary funcionality is added here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cube(img, x, y, val):\n",
    "    \n",
    "    img[y][x] = val\n",
    "    img[y][x-1] = val\n",
    "    img[y][x+1] = val\n",
    "    img[y-1][x] = val\n",
    "    img[y-1][x-1] = val\n",
    "    img[y-1][x+1] = val\n",
    "    img[y+1][x] = val\n",
    "    img[y+1][x-1] = val\n",
    "    img[y+1][x+1] = val  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4) Supervised Euclidean for LASTENA BS=4\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/7_4_euclidean'\n",
    "\n",
    "#path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENA/fix'\n",
    "#path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENA/train'\n",
    "#path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENA/validation'\n",
    "#path_validation_2 = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/validation'\n",
    "#path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENA/test'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\LASTENA\\fix'\n",
    "path_train = r'D:\\Julian\\data\\LASTENA\\train'\n",
    "path_validation = r'D:\\Julian\\data\\LASTENA\\validation'\n",
    "path_validation_2 = r'D:\\Julian\\data\\LASTEN\\validation'\n",
    "path_test = r'D:\\Julian\\data\\LASTENA\\test'\n",
    "\n",
    "width = 384\n",
    "height = 384\n",
    "\n",
    "grid_width = 18\n",
    "grid_height = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(width, height, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "batch_size=4\n",
    "\n",
    "train_gen = LASTENSequence(path_train,\n",
    "                           path_fixed,\n",
    "                           batch_size=batch_size,\n",
    "                           width=width,\n",
    "                           height=height,\n",
    "                           grid_width=grid_width, \n",
    "                           grid_height=grid_height,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True,\n",
    "                           label=\"keypoints\",\n",
    "                           channel=\"moving+fixed\")\n",
    "\n",
    "val_gen = LASTENSequence(path_validation,\n",
    "                           path_fixed,\n",
    "                           batch_size=batch_size,\n",
    "                           width=width,\n",
    "                           height=height,\n",
    "                           grid_width=grid_width, \n",
    "                           grid_height=grid_height,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=False,\n",
    "                           label=\"keypoints\",\n",
    "                           channel=\"moving+fixed\")\n",
    "\n",
    "val_gen_2 = LASTENSequence(path_validation_2,\n",
    "                           path_fixed,\n",
    "                           batch_size=batch_size,\n",
    "                           width=width,\n",
    "                           height=height,\n",
    "                           grid_width=grid_width, \n",
    "                           grid_height=grid_height,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=False,\n",
    "                           label=\"keypoints\",\n",
    "                           channel=\"moving+fixed\")\n",
    "\n",
    "timelogger = ccall.TimeHistory(store_path)\n",
    "vallogger = ccall.ValidationHistory(store_path, val_gen_2)\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\", period=10)\n",
    "checker_best = ModelCheckpoint(store_path + \"/best_weights.{epoch:02d}.hdf5\", save_best_only=True)\n",
    "callbacks = [timelogger, logger, checker, checker_best, vallogger]\n",
    "\n",
    "eu_loss = closs.EuclideanLoss(batch_size=batch_size, grid_width=grid_width, grid_height=grid_height, loss_type='msed')\n",
    "eu_met = closs.EuclideanLoss(batch_size=batch_size, grid_width=grid_width, grid_height=grid_height, loss_type='maed')\n",
    "\n",
    "model.compile(optimizer='adam', loss=eu_loss, metrics=[eu_met])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(store_path + \"/weights.50.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839/840 [============================>.] - ETA: 0s - loss: 1349.8408 - maed: 28.9907WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 305ms/step - loss: 927.4241 - maed: 27.3086\n",
      "840/840 [==============================] - 183s 217ms/step - loss: 1349.0133 - maed: 28.9813 - val_loss: 1232.1411 - val_maed: 28.7403\n",
      "Epoch 2/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 515.4189 - maed: 17.8119WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 255ms/step - loss: 182.3121 - maed: 11.5772\n",
      "840/840 [==============================] - 154s 183ms/step - loss: 515.0526 - maed: 17.8045 - val_loss: 422.7169 - val_maed: 16.2267\n",
      "Epoch 3/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 330.9732 - maed: 14.2123WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 270ms/step - loss: 169.6862 - maed: 11.3955\n",
      "840/840 [==============================] - 152s 181ms/step - loss: 331.0035 - maed: 14.2115 - val_loss: 446.7629 - val_maed: 16.8756\n",
      "Epoch 4/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 265.2695 - maed: 12.6572-  - ETA: 3s - loss: 266 - ETA: 0s - loss: 265.7948 - maed:WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 252ms/step - loss: 88.1263 - maed: 7.6608\n",
      "840/840 [==============================] - 140s 166ms/step - loss: 265.4450 - maed: 12.6609 - val_loss: 290.5238 - val_maed: 12.9563\n",
      "Epoch 5/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 228.8430 - maed: 11.7119WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 261ms/step - loss: 91.9742 - maed: 8.2413\n",
      "840/840 [==============================] - 152s 181ms/step - loss: 228.9038 - maed: 11.7131 - val_loss: 259.4880 - val_maed: 12.1677\n",
      "Epoch 6/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 206.0271 - maed: 11.0944WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 285ms/step - loss: 66.8758 - maed: 6.8071\n",
      "840/840 [==============================] - 153s 183ms/step - loss: 206.0210 - maed: 11.0945 - val_loss: 233.2778 - val_maed: 11.5528\n",
      "Epoch 7/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 187.5033 - maed: 10.5437WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 258ms/step - loss: 97.0309 - maed: 8.4584\n",
      "840/840 [==============================] - 159s 190ms/step - loss: 187.4616 - maed: 10.5428 - val_loss: 270.4729 - val_maed: 12.5307\n",
      "Epoch 8/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 164.2572 - maed: 9.8343WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 275ms/step - loss: 249.8441 - maed: 12.6169\n",
      "840/840 [==============================] - 154s 183ms/step - loss: 164.2498 - maed: 9.8344 - val_loss: 376.5034 - val_maed: 15.0717\n",
      "Epoch 9/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 142.8370 - maed: 9.1914WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 274ms/step - loss: 135.8731 - maed: 10.5195\n",
      "840/840 [==============================] - 153s 182ms/step - loss: 142.8234 - maed: 9.1908 - val_loss: 266.6701 - val_maed: 12.7680\n",
      "Epoch 10/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 121.1965 - maed: 8.4417WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 276ms/step - loss: 199.3682 - maed: 12.5078\n",
      "840/840 [==============================] - 145s 172ms/step - loss: 121.1546 - maed: 8.4404 - val_loss: 291.2400 - val_maed: 13.6384\n",
      "Epoch 11/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 107.1100 - maed: 7.9296WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 259ms/step - loss: 67.7397 - maed: 6.7305\n",
      "840/840 [==============================] - 151s 179ms/step - loss: 107.0719 - maed: 7.9281 - val_loss: 150.6359 - val_maed: 9.2942\n",
      "Epoch 12/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 97.3002 - maed: 7.5810WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 301ms/step - loss: 38.2617 - maed: 5.2467\n",
      "840/840 [==============================] - 159s 189ms/step - loss: 97.2584 - maed: 7.5795 - val_loss: 119.4155 - val_maed: 8.2220\n",
      "Epoch 13/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 90.2442 - maed: 7.2898- ETA: 2s - loss: 90WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 252ms/step - loss: 44.4250 - maed: 5.7253\n",
      "840/840 [==============================] - 160s 190ms/step - loss: 90.2338 - maed: 7.2894 - val_loss: 132.8434 - val_maed: 8.6746\n",
      "Epoch 14/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 77.6063 - maed: 6.7834WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 282ms/step - loss: 90.1925 - maed: 8.5333\n",
      "840/840 [==============================] - 153s 182ms/step - loss: 77.5865 - maed: 6.7826 - val_loss: 188.9505 - val_maed: 10.8990\n",
      "Epoch 15/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 70.7439 - maed: 6.4797WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 254ms/step - loss: 100.3934 - maed: 8.6983\n",
      "840/840 [==============================] - 148s 176ms/step - loss: 70.7391 - maed: 6.4795 - val_loss: 127.4490 - val_maed: 8.9665\n",
      "Epoch 16/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 62.4439 - maed: 6.0976WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 264ms/step - loss: 33.5755 - maed: 5.0280\n",
      "840/840 [==============================] - 152s 181ms/step - loss: 62.4678 - maed: 6.0979 - val_loss: 89.4191 - val_maed: 7.2353\n",
      "Epoch 17/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 59.6926 - maed: 5.9624WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 308ms/step - loss: 551.7404 - maed: 19.2100\n",
      "840/840 [==============================] - 165s 196ms/step - loss: 59.7492 - maed: 5.9647 - val_loss: 631.9414 - val_maed: 19.0198\n",
      "Epoch 18/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 53.2560 - maed: 5.6257WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 282ms/step - loss: 34.7167 - maed: 5.3217\n",
      "840/840 [==============================] - 159s 189ms/step - loss: 53.2401 - maed: 5.6248 - val_loss: 87.8224 - val_maed: 7.2260\n",
      "Epoch 19/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 53.9314 - maed: 5.6725WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 38.4554 - maed: 5.3974\n",
      "840/840 [==============================] - 159s 190ms/step - loss: 53.9354 - maed: 5.6726 - val_loss: 89.9735 - val_maed: 7.3039\n",
      "Epoch 20/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 47.3387 - maed: 5.2992WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 346ms/step - loss: 56.4961 - maed: 6.3054\n",
      "840/840 [==============================] - 149s 177ms/step - loss: 47.3304 - maed: 5.2987 - val_loss: 136.0636 - val_maed: 9.0626\n",
      "Epoch 21/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 44.3084 - maed: 5.1397WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 21.8351 - maed: 4.0166\n",
      "840/840 [==============================] - 156s 185ms/step - loss: 44.2961 - maed: 5.1390 - val_loss: 77.4665 - val_maed: 6.5989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 42.3877 - maed: 5.0202WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 15.1075 - maed: 3.2282\n",
      "840/840 [==============================] - 160s 190ms/step - loss: 42.3627 - maed: 5.0185 - val_loss: 71.9092 - val_maed: 6.3002\n",
      "Epoch 23/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 41.7114 - maed: 4.9933WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 265ms/step - loss: 15.6627 - maed: 3.3165\n",
      "840/840 [==============================] - 163s 194ms/step - loss: 41.7212 - maed: 4.9942 - val_loss: 83.8410 - val_maed: 6.6709\n",
      "Epoch 24/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 35.9181 - maed: 4.6226- ETA: 1s - loss: 35.9703 - maedWARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 262ms/step - loss: 24.6246 - maed: 4.2197\n",
      "840/840 [==============================] - 158s 188ms/step - loss: 35.9089 - maed: 4.6218 - val_loss: 87.4420 - val_maed: 6.9186\n",
      "Epoch 25/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 35.9630 - maed: 4.6268- ETA: 6s  - ETA: 3s - lWARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 28.6506 - maed: 4.4416\n",
      "840/840 [==============================] - 153s 183ms/step - loss: 35.9521 - maed: 4.6262 - val_loss: 78.8883 - val_maed: 6.7959\n",
      "Epoch 26/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 36.5056 - maed: 4.6715WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 322ms/step - loss: 24.3023 - maed: 4.2855\n",
      "840/840 [==============================] - 147s 175ms/step - loss: 36.4908 - maed: 4.6705 - val_loss: 85.9615 - val_maed: 6.9783\n",
      "Epoch 27/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 31.6337 - maed: 4.3527- ETA: 1s - loss: 31.5862  - ETA: 0s - loss: 31.6269 - maed: 4.352WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 289ms/step - loss: 30.4756 - maed: 4.9534\n",
      "840/840 [==============================] - 157s 187ms/step - loss: 31.6674 - maed: 4.3541 - val_loss: 85.5945 - val_maed: 7.1012\n",
      "Epoch 28/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 30.8862 - maed: 4.3047WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 260ms/step - loss: 41.2622 - maed: 5.4850\n",
      "840/840 [==============================] - 163s 194ms/step - loss: 30.9108 - maed: 4.3066 - val_loss: 122.9844 - val_maed: 8.5287\n",
      "Epoch 29/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 30.5851 - maed: 4.2804WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 149.5135 - maed: 10.8660\n",
      "840/840 [==============================] - 159s 189ms/step - loss: 30.6057 - maed: 4.2818 - val_loss: 214.0083 - val_maed: 11.8762\n",
      "Epoch 30/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 26.2515 - maed: 3.9586WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 279ms/step - loss: 14.5172 - maed: 3.3050\n",
      "840/840 [==============================] - 157s 187ms/step - loss: 26.2503 - maed: 3.9588 - val_loss: 68.1614 - val_maed: 6.0729\n",
      "Epoch 31/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 26.5215 - maed: 3.9947WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 276ms/step - loss: 10.8466 - maed: 2.6915\n",
      "840/840 [==============================] - 152s 181ms/step - loss: 26.5196 - maed: 3.9944 - val_loss: 65.2680 - val_maed: 5.8009\n",
      "Epoch 32/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 25.1980 - maed: 3.8933WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 361ms/step - loss: 7.9905 - maed: 2.3904\n",
      "840/840 [==============================] - 159s 190ms/step - loss: 25.1969 - maed: 3.8933 - val_loss: 60.9703 - val_maed: 5.5519\n",
      "Epoch 33/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 23.1239 - maed: 3.7263WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 294ms/step - loss: 15.3193 - maed: 3.3572\n",
      "840/840 [==============================] - 167s 199ms/step - loss: 23.1240 - maed: 3.7265 - val_loss: 78.7596 - val_maed: 6.5046\n",
      "Epoch 34/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 23.1471 - maed: 3.7240WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 266ms/step - loss: 8.4169 - maed: 2.3760\n",
      "840/840 [==============================] - 166s 198ms/step - loss: 23.1388 - maed: 3.7234 - val_loss: 59.0076 - val_maed: 5.4312\n",
      "Epoch 35/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 22.4711 - maed: 3.686 - ETA: 0s - loss: 22.4745 - maed: 3.6862WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 250ms/step - loss: 13.5214 - maed: 3.1880\n",
      "840/840 [==============================] - 158s 189ms/step - loss: 22.4779 - maed: 3.6863 - val_loss: 62.2574 - val_maed: 5.7529\n",
      "Epoch 36/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 20.7796 - maed: 3.5347- ETA: 3s - loss: 20. - ETA: 1s - loss: 20.7783 - maeWARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 260ms/step - loss: 435.5416 - maed: 15.2669\n",
      "840/840 [==============================] - 156s 186ms/step - loss: 20.7709 - maed: 3.5340 - val_loss: 468.4613 - val_maed: 15.2776\n",
      "Epoch 37/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 19.4332 - maed: 3.4194WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 259ms/step - loss: 6.9981 - maed: 2.2002\n",
      "840/840 [==============================] - 156s 185ms/step - loss: 19.4265 - maed: 3.4189 - val_loss: 60.2715 - val_maed: 5.4517\n",
      "Epoch 38/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 20.1407 - maed: 3.4714WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 297ms/step - loss: 13.0489 - maed: 3.1412\n",
      "840/840 [==============================] - 165s 197ms/step - loss: 20.1404 - maed: 3.4714 - val_loss: 62.5886 - val_maed: 5.7402\n",
      "Epoch 39/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 17.7844 - maed: 3.2768WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 14.9436 - maed: 3.3739\n",
      "840/840 [==============================] - 169s 201ms/step - loss: 17.7871 - maed: 3.2772 - val_loss: 68.6969 - val_maed: 6.1311\n",
      "Epoch 40/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 18.3304 - maed: 3.3394WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 273ms/step - loss: 15.8078 - maed: 3.4935\n",
      "840/840 [==============================] - 168s 200ms/step - loss: 18.3370 - maed: 3.3399 - val_loss: 61.0690 - val_maed: 5.6873\n",
      "Epoch 41/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 16.8330 - maed: 3.1858-WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 29.3695 - maed: 4.6355\n",
      "840/840 [==============================] - 156s 185ms/step - loss: 16.8345 - maed: 3.1862 - val_loss: 84.9862 - val_maed: 7.0068\n",
      "Epoch 42/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 16.5968 - maed: 3.1643- ETA: 4s - loss: 16.50 - ETA: 2s - loss:WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 307ms/step - loss: 7.2042 - maed: 2.2765\n",
      "840/840 [==============================] - 156s 185ms/step - loss: 16.5934 - maed: 3.1639 - val_loss: 62.1629 - val_maed: 5.5454\n",
      "Epoch 43/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 15.7613 - maed: 3.0913WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 297ms/step - loss: 9.6390 - maed: 2.6083\n",
      "840/840 [==============================] - 161s 192ms/step - loss: 15.7527 - maed: 3.0904 - val_loss: 64.5453 - val_maed: 5.7986\n",
      "Epoch 44/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 15.5927 - maed: 3.0804WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 260ms/step - loss: 15.2096 - maed: 3.2898\n",
      "840/840 [==============================] - 173s 206ms/step - loss: 15.5877 - maed: 3.0800 - val_loss: 71.1600 - val_maed: 6.1643\n",
      "Epoch 45/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 15.3275 - maed: 3.0468WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 7.5173 - maed: 2.3355\n",
      "840/840 [==============================] - 169s 201ms/step - loss: 15.3186 - maed: 3.0457 - val_loss: 59.2094 - val_maed: 5.4290\n",
      "Epoch 46/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 14.4461 - maed: 2.9477- ETA: 3s - loss: 14.41 - ETA: 1s - loss: 14.4646 - mWARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 272ms/step - loss: 10.1423 - maed: 2.6956\n",
      "840/840 [==============================] - 159s 189ms/step - loss: 14.4425 - maed: 2.9474 - val_loss: 60.2360 - val_maed: 5.5167\n",
      "Epoch 47/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 13.8143 - maed: 2.8872WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 286ms/step - loss: 13.6556 - maed: 3.0636\n",
      "840/840 [==============================] - 152s 181ms/step - loss: 13.8140 - maed: 2.8874 - val_loss: 68.2376 - val_maed: 5.9531\n",
      "Epoch 48/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 12.7360 - maed: 2.7747WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 307ms/step - loss: 10.2752 - maed: 2.7292\n",
      "840/840 [==============================] - 161s 191ms/step - loss: 12.7338 - maed: 2.7745 - val_loss: 62.7062 - val_maed: 5.6804\n",
      "Epoch 49/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 13.2698 - maed: 2.8338- ETA: 0s - loss: 13.2671 - maed: 2.833WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 7.5678 - maed: 2.2616\n",
      "840/840 [==============================] - 174s 208ms/step - loss: 13.2710 - maed: 2.8339 - val_loss: 58.2787 - val_maed: 5.3032\n",
      "Epoch 50/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 12.2605 - maed: 2.7245WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 313ms/step - loss: 8.3859 - maed: 2.4549\n",
      "840/840 [==============================] - 170s 202ms/step - loss: 12.2673 - maed: 2.7253 - val_loss: 62.5731 - val_maed: 5.5967\n",
      "Epoch 51/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 12.1046 - maed: 2.7085WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 311ms/step - loss: 22.1453 - maed: 4.2447\n",
      "840/840 [==============================] - 165s 197ms/step - loss: 12.1265 - maed: 2.7107 - val_loss: 70.9516 - val_maed: 6.3076\n",
      "Epoch 52/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 11.8213 - maed: 2.6738- ETWARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 283ms/step - loss: 6.5554 - maed: 2.1254\n",
      "840/840 [==============================] - 159s 190ms/step - loss: 11.8205 - maed: 2.6738 - val_loss: 57.0999 - val_maed: 5.2789\n",
      "Epoch 53/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 11.1316 - maed: 2.5803WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 273ms/step - loss: 7.4775 - maed: 2.3328\n",
      "840/840 [==============================] - 159s 189ms/step - loss: 11.1317 - maed: 2.5804 - val_loss: 55.2415 - val_maed: 5.2455\n",
      "Epoch 54/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 11.2070 - maed: 2.5914WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 282ms/step - loss: 5.4057 - maed: 1.9836\n",
      "840/840 [==============================] - 171s 204ms/step - loss: 11.2052 - maed: 2.5912 - val_loss: 55.9970 - val_maed: 5.2422\n",
      "Epoch 55/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 12.2657 - maed: 2.7070WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 6.5762 - maed: 2.1512\n",
      "840/840 [==============================] - 177s 210ms/step - loss: 12.2651 - maed: 2.7070 - val_loss: 56.1038 - val_maed: 5.1959\n",
      "Epoch 56/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 10.3764 - maed: 2.4895WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 3.1375 - maed: 1.4230\n",
      "840/840 [==============================] - 173s 206ms/step - loss: 10.3767 - maed: 2.4896 - val_loss: 53.7013 - val_maed: 4.9020\n",
      "Epoch 57/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 10.6843 - maed: 2.5170WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 301ms/step - loss: 11.4961 - maed: 2.9019\n",
      "840/840 [==============================] - 160s 190ms/step - loss: 10.6828 - maed: 2.5169 - val_loss: 64.3288 - val_maed: 5.7457\n",
      "Epoch 58/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 9.8481 - maed: 2.4112WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 2s 269ms/step - loss: 11.7033 - maed: 3.0794\n",
      "840/840 [==============================] - 158s 188ms/step - loss: 9.8489 - maed: 2.4115 - val_loss: 60.6570 - val_maed: 5.5556\n",
      "Epoch 59/100\n",
      "839/840 [============================>.] - ETA: 0s - loss: 9.3316 - maed: 2.3584WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "9/9 [==============================] - 3s 292ms/step - loss: 10.5204 - maed: 2.7688\n",
      "840/840 [==============================] - 162s 193ms/step - loss: 9.3407 - maed: 2.3596 - val_loss: 59.4361 - val_maed: 5.4904\n",
      "Epoch 60/100\n",
      " 11/840 [..............................] - ETA: 4:14 - loss: 9.3170 - maed: 2.4260"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m       \u001b[1;32myield\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  MemoryError: Unable to allocate 1.12 MiB for an array with shape (384, 384, 2) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\", line 881, in get\n    six.reraise(*sys.exc_info())\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\six.py\", line 703, in reraise\n    raise value\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\", line 875, in get\n    inputs = self.queue.get(block=True).get()\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\multiprocessing\\pool.py\", line 657, in get\n    raise self._value\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\multiprocessing\\pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\", line 663, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"D:\\Julian\\workspace\\endolas\\lastengen.py\", line 100, in __getitem__\n    X, y = self._get_batch(batch_image_ids)\n\n  File \"D:\\Julian\\workspace\\endolas\\lastengen.py\", line 121, in _get_batch\n    X[batch_index] = np.concatenate((image, fixed), axis=2) if self._channel == \"moving+fixed\" else image\n\n  File \"<__array_function__ internals>\", line 6, in concatenate\n\nMemoryError: Unable to allocate 1.12 MiB for an array with shape (384, 384, 2) and data type float32\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  MemoryError: Unable to allocate 1.12 MiB for an array with shape (384, 384, 2) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\", line 881, in get\n    six.reraise(*sys.exc_info())\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\six.py\", line 703, in reraise\n    raise value\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\", line 875, in get\n    inputs = self.queue.get(block=True).get()\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\multiprocessing\\pool.py\", line 657, in get\n    raise self._value\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\multiprocessing\\pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\", line 663, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"D:\\Julian\\workspace\\endolas\\lastengen.py\", line 100, in __getitem__\n    X, y = self._get_batch(batch_image_ids)\n\n  File \"D:\\Julian\\workspace\\endolas\\lastengen.py\", line 121, in _get_batch\n    X[batch_index] = np.concatenate((image, fixed), axis=2) if self._channel == \"moving+fixed\" else image\n\n  File \"<__array_function__ internals>\", line 6, in concatenate\n\nMemoryError: Unable to allocate 1.12 MiB for an array with shape (384, 384, 2) and data type float32\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_367203]\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1fd8c1cd6563>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[1;31m#use_multiprocessing=True,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m           max_queue_size=32)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   2044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m     \u001b[0mrow_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m     \u001b[0mrow_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2047\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2048\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf2-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m     \u001b[0mrow_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m     \u001b[0mrow_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2047\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2048\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          initial_epoch=50,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=val_gen,\n",
    "          validation_freq=1,\n",
    "          #use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = val_gen[0]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,grid_width*grid_height):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5) Supervised Euclidean for LASTENAS BS=4\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/7_5_euclidean'\n",
    "\n",
    "#path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENAS/fix'\n",
    "#path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENAS/train'\n",
    "#path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENAS/validation'\n",
    "#path_validation_2 = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENAS/validation'\n",
    "#path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENAS/test'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\LASTENAS\\fix'\n",
    "path_train = r'D:\\Julian\\data\\LASTENAS\\train'\n",
    "path_validation = r'D:\\Julian\\data\\LASTENAS\\validation'\n",
    "path_validation_2 = r'D:\\Julian\\data\\LASTEN\\validation'\n",
    "path_test = r'D:\\Julian\\data\\LASTENAS\\test'\n",
    "\n",
    "width = 384\n",
    "height = 384\n",
    "\n",
    "grid_width = 18\n",
    "grid_height = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(width, height, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "\n",
    "train_gen = LASTENSequence(path_train,\n",
    "                           path_fixed,\n",
    "                           batch_size=batch_size,\n",
    "                           width=width,\n",
    "                           height=height,\n",
    "                           grid_width=grid_width, \n",
    "                           grid_height=grid_height,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True,\n",
    "                           label=\"keypoints\",\n",
    "                           channel=\"moving+fixed\")\n",
    "\n",
    "val_gen = LASTENSequence(path_validation,\n",
    "                           path_fixed,\n",
    "                           batch_size=batch_size,\n",
    "                           width=width,\n",
    "                           height=height,\n",
    "                           grid_width=grid_width, \n",
    "                           grid_height=grid_height,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=False,\n",
    "                           label=\"keypoints\",\n",
    "                           channel=\"moving+fixed\")\n",
    "\n",
    "val_gen_2 = LASTENSequence(path_validation_2,\n",
    "                           path_fixed,\n",
    "                           batch_size=batch_size,\n",
    "                           width=width,\n",
    "                           height=height,\n",
    "                           grid_width=grid_width, \n",
    "                           grid_height=grid_height,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=False,\n",
    "                           label=\"keypoints\",\n",
    "                           channel=\"moving+fixed\")\n",
    "\n",
    "timelogger = ccall.TimeHistory(store_path)\n",
    "vallogger = ccall.ValidationHistory(store_path, val_gen_2)\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\", period=10)\n",
    "checker_best = ModelCheckpoint(store_path + \"/best_weights.{epoch:02d}.hdf5\", save_best_only=True)\n",
    "callbacks = [timelogger, logger, checker, checker_best, vallogger]\n",
    "\n",
    "eu_loss = closs.EuclideanLoss(batch_size=batch_size, grid_width=grid_width, grid_height=grid_height, loss_type='msed')\n",
    "eu_met = closs.EuclideanLoss(batch_size=batch_size, grid_width=grid_width, grid_height=grid_height, loss_type='maed')\n",
    "\n",
    "model.compile(optimizer='adam', loss=eu_loss, metrics=[eu_met])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=val_gen,\n",
    "          validation_freq=1,\n",
    "          #use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = val_gen[0]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,grid_width*grid_height):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6) Supervised Euclidean for LASTENS+LASTEN BS=4\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/7_6_euclidean'\n",
    "\n",
    "#path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENS_LASTEN/fix'\n",
    "#path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENS_LASTEN/train'\n",
    "#path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENS_LASTEN/validation'\n",
    "#path_validation_2 = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENS_LASTEN/validation'\n",
    "#path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENS_LASTEN/test'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\LASTENS_LASTEN\\fix'\n",
    "path_train = r'D:\\Julian\\data\\LASTENS_LASTEN\\train'\n",
    "path_validation = r'D:\\Julian\\data\\LASTENS_LASTEN\\validation'\n",
    "path_validation_2 = r'D:\\Julian\\data\\LASTEN\\validation'\n",
    "path_test = r'D:\\Julian\\data\\LASTENS_LASTEN\\test'\n",
    "\n",
    "width = 384\n",
    "height = 384\n",
    "\n",
    "grid_width = 18\n",
    "grid_height = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(width, height, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "\n",
    "train_gen = LASTENSequence(path_train,\n",
    "                           path_fixed,\n",
    "                           batch_size=batch_size,\n",
    "                           width=width,\n",
    "                           height=height,\n",
    "                           grid_width=grid_width, \n",
    "                           grid_height=grid_height,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True,\n",
    "                           label=\"keypoints\",\n",
    "                           channel=\"moving+fixed\")\n",
    "\n",
    "val_gen = LASTENSequence(path_validation,\n",
    "                           path_fixed,\n",
    "                           batch_size=batch_size,\n",
    "                           width=width,\n",
    "                           height=height,\n",
    "                           grid_width=grid_width, \n",
    "                           grid_height=grid_height,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=False,\n",
    "                           label=\"keypoints\",\n",
    "                           channel=\"moving+fixed\")\n",
    "\n",
    "val_gen_2 = LASTENSequence(path_validation_2,\n",
    "                           path_fixed,\n",
    "                           batch_size=batch_size,\n",
    "                           width=width,\n",
    "                           height=height,\n",
    "                           grid_width=grid_width, \n",
    "                           grid_height=grid_height,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=False,\n",
    "                           label=\"keypoints\",\n",
    "                           channel=\"moving+fixed\")\n",
    "\n",
    "timelogger = ccall.TimeHistory(store_path)\n",
    "vallogger = ccall.ValidationHistory(store_path, val_gen_2)\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\", period=10)\n",
    "checker_best = ModelCheckpoint(store_path + \"/best_weights.{epoch:02d}.hdf5\", save_best_only=True)\n",
    "callbacks = [timelogger, logger, checker, checker_best, vallogger]\n",
    "\n",
    "eu_loss = closs.EuclideanLoss(batch_size=batch_size, grid_width=grid_width, grid_height=grid_height, loss_type='msed')\n",
    "eu_met = closs.EuclideanLoss(batch_size=batch_size, grid_width=grid_width, grid_height=grid_height, loss_type='maed')\n",
    "\n",
    "model.compile(optimizer='adam', loss=eu_loss, metrics=[eu_met])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=val_gen,\n",
    "          validation_freq=1,\n",
    "          #use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = val_gen[0]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,grid_width*grid_height):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
