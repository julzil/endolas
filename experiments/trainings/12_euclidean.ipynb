{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements\n",
    "Following packages are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:\\Julian\\workspace\\endolas\\packages\")\n",
    "\n",
    "import random\n",
    "from endolas import utils\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "from endolas  import closs\n",
    "from endolas import ccall\n",
    "\n",
    "from endolas import LASTENSequence\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "from endolas import UNet\n",
    "from endolas import preprocess_input as pre_une\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Checks\n",
    "The version of tensorflow as well as the GPU support are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12) Supervised Euclidean for LASTEN2AK with Crossvalidation\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "width = shape #Get through papermill\n",
    "height = shape #Get through papermill\n",
    "\n",
    "spacing_x = spacing #Get through papermill\n",
    "spacing_y = spacing #Get through papermill\n",
    "\n",
    "experiment = experiment #Get through papermill\n",
    "\n",
    "grid_width = 18\n",
    "grid_height = 18\n",
    "\n",
    "store_path = '../results/12_{}_euclidean'.format(experiment)\n",
    "data_path = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN2AK'\n",
    "\n",
    "#store_path = '..\\results\\12_{}_euclidean'.format(experiment)\n",
    "#data_path = r'D:\\Julian\\data\\LASTEN2AK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality\n",
    "Functionality to reinitalize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinit_weights(model):\n",
    "    for ix, layer in enumerate(model.layers):\n",
    "        if hasattr(model.layers[ix], 'kernel_initializer') and hasattr(model.layers[ix], 'bias_initializer'):\n",
    "            weight_initializer = model.layers[ix].kernel_initializer\n",
    "            #bias_initializer = model.layers[ix].bias_initializer\n",
    "\n",
    "            old_weights = model.layers[ix].get_weights()[0]\n",
    "            #old_biases = model.layers[ix].get_weights()[1]\n",
    "            \n",
    "            model.layers[ix].set_weights([weight_initializer(shape=old_weights.shape)])#,bias_initializer(shape=len(old_biases))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Loop\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Clear session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Training parameters\n",
    "batch_size=4\n",
    "folds = 5\n",
    "\n",
    "# Get the model\n",
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(width, height, 2))\n",
    "\n",
    "eu_loss = closs.EuclideanLoss(batch_size=batch_size, grid_width=grid_width, grid_height=grid_height, loss_type='msed')\n",
    "eu_met = closs.EuclideanLoss(batch_size=batch_size, grid_width=grid_width,\n",
    "                             grid_height=grid_height, loss_type='medn', grid_spacing=spacing)\n",
    "\n",
    "model.compile(optimizer='adam', loss=eu_loss, metrics=[eu_met])\n",
    "\n",
    "for fold in range(folds):\n",
    "    # Reinit model\n",
    "    reinit_weights(model)\n",
    "    \n",
    "    # Determine data paths\n",
    "    folds = [0, 1, 2, 3, 4]\n",
    "    folds.remove(fold)\n",
    "    path_train = data_path + os.sep + str(fold) + os.sep + 'fold_{}_{}_{}_{}'.format(folds[0],\n",
    "                                                                                     folds[1],\n",
    "                                                                                     folds[2],\n",
    "                                                                                     folds[3])\n",
    "    path_validation = data_path + os.sep + str(fold) + os.sep + 'fold_{}'.format(fold)\n",
    "    \n",
    "    path_fixed = data_path + os.sep + 'fixed_images' + os.sep + '{}_{}'.format(width, spacing)\n",
    "    \n",
    "    # Get all training folds\n",
    "    train_gen = LASTENSequence(path_train,\n",
    "                               path_fixed,\n",
    "                               batch_size=batch_size,\n",
    "                               width=width,\n",
    "                               height=height,\n",
    "                               grid_width=grid_width, \n",
    "                               grid_height=grid_height,\n",
    "                               preprocess_input=pre_une,\n",
    "                               shuffle=True,\n",
    "                               label=\"keypoints\",\n",
    "                               channel=\"moving+fixed\")\n",
    "    \n",
    "    # Get validation fold\n",
    "    val_gen = LASTENSequence(path_validation,\n",
    "                             path_fixed,\n",
    "                             batch_size=batch_size,\n",
    "                             width=width,\n",
    "                             height=height,\n",
    "                             grid_width=grid_width, \n",
    "                             grid_height=grid_height,\n",
    "                             preprocess_input=pre_une,\n",
    "                             shuffle=False,\n",
    "                             label=\"keypoints\",\n",
    "                             channel=\"moving+fixed\")\n",
    "\n",
    "    # Callbacks\n",
    "    store_fold_path = store_path + os.sep + int(fold)\n",
    "    \n",
    "    logger = CSVLogger(store_fold_path + os.sep + 'log')\n",
    "    timelogger = ccall.TimeHistory(store_fold_path)\n",
    "    checker_best = ModelCheckpoint(store_fold_path + os.sep + \"best_weights.hdf5\", save_best_only=True)\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=10, patience=5, mode='min')\n",
    "    callbacks = [timelogger, logger, checker_best, early_stopping]\n",
    "\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_gen,\n",
    "              epochs=70,\n",
    "              callbacks=callbacks,\n",
    "              validation_data=val_gen,\n",
    "              validation_freq=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
