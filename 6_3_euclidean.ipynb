{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3) Supervised Euclidean\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements\n",
    "Following packages are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "from simplegen import SIMPLESequence\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "from unet import UNet\n",
    "from unet import preprocess_input as pre_une\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Checks\n",
    "The version of tensorflow as well as the GPU support are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable all GPUS\n",
    "  tf.config.set_visible_devices([], 'GPU')\n",
    "  visible_devices = tf.config.get_visible_devices()\n",
    "  for device in visible_devices:\n",
    "    assert device.device_type != 'GPU'\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "\n",
    "print(tf.config.get_visible_devices('GPU'))\n",
    "print(tf.config.get_visible_devices('CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_3_euclidean'\n",
    "\n",
    "path_train = r'/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLEA/train'\n",
    "path_validation = r'/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLEA/validation'\n",
    "path_test = r'/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLEA/test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 224, 224, 32) 288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 224, 224, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 224, 224, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 112, 112, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 112, 112, 64) 18432       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 112, 112, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 112, 112, 64) 36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 112, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 112, 112, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 128)  73728       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 128)  147456      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 128)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 28, 28, 256)  294912      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 28, 28, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 256)  589824      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 28, 28, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 256)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 14, 14, 512)  1179648     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 14, 14, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 14, 14, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 256)  1179648     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 14, 14, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 14, 14, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 28, 28, 256)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28, 28, 512)  0           up_sampling2d[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 28, 28, 256)  1179648     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 28, 28, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 128)  294912      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 56, 56, 128)  0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 56, 56, 256)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 56, 56, 128)  294912      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 56, 56, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 56, 56, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 56, 56, 64)   73728       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 56, 56, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 56, 56, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 112, 112, 64) 0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 112, 112, 64) 73728       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 112, 112, 64) 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 112, 112, 64) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 112, 112, 32) 18432       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 112, 112, 32) 128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 112, 112, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 32) 0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 224, 224, 64) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 224, 224, 32) 18432       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 224, 224, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 224, 224, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 224, 224, 32) 9216        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 224, 224, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 224, 224, 32) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "segmentation (Conv2D)           (None, 224, 224, 2)  64          activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,502,944\n",
      "Trainable params: 5,498,016\n",
      "Non-trainable params: 4,928\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Preparation\n",
    "A batch with only one image is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = None\n",
    "\n",
    "train_gen = SIMPLESequence(path_train,\n",
    "                           batch_size=4,\n",
    "                           image_ids=image_ids,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True)\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une,\n",
    "                                width=width,\n",
    "                                height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/anaconda3/envs/endolas/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 94s 2s/step - loss: 1647.4834 - val_loss: 76013.1562\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 96s 2s/step - loss: 1592.3396 - val_loss: 31418.7461\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 94s 2s/step - loss: 1439.4880 - val_loss: 1776.9485\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 1251.7740 - val_loss: 1852.0380\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 1158.3163 - val_loss: 6923.8613\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 1117.8339 - val_loss: 1265.5198\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 94s 2s/step - loss: 1006.9386 - val_loss: 950.7366\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 984.0272 - val_loss: 969.9189\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 958.3377 - val_loss: 876.8878\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 94s 2s/step - loss: 923.0211 - val_loss: 932.6155\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 94s 2s/step - loss: 901.4372 - val_loss: 895.5882\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 875.3589 - val_loss: 885.3427\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 878.4565 - val_loss: 868.1161\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 897.5081 - val_loss: 948.3976\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 940.3409 - val_loss: 1350.7286\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 854.3359 - val_loss: 836.7081\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 807.4623 - val_loss: 872.5845\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 843.6061 - val_loss: 784.2178\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 771.0117 - val_loss: 1046.8348\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 711.5347 - val_loss: 987.7058\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 572.8770 - val_loss: 570.8204\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 463.7630 - val_loss: 612.2140\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 414.9995 - val_loss: 481.6228\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 342.8188 - val_loss: 298.7174\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 94s 2s/step - loss: 274.8852 - val_loss: 326.2852\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 222.9575 - val_loss: 190.5440\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 158.9648 - val_loss: 216.9567\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 159.8441 - val_loss: 148.9675\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 194.5555 - val_loss: 128.0675\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 144.0359 - val_loss: 153.9287\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 154.2733 - val_loss: 145.8139\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 120.7444 - val_loss: 143.6268\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 126.5329 - val_loss: 136.4421\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 176.5514 - val_loss: 187.4586\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 135.9498 - val_loss: 127.7432\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 98.8224 - val_loss: 135.7000\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 86.6126 - val_loss: 107.4785\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 108.3327 - val_loss: 119.4296\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 101.0851 - val_loss: 82.6512\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 76.0952 - val_loss: 99.6482\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 74.6087 - val_loss: 95.3968\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 59.5672 - val_loss: 75.7925\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 66.9286 - val_loss: 82.2673\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 58.3041 - val_loss: 91.9976\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 56.5454 - val_loss: 91.3112\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 60.1367 - val_loss: 76.4278\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 72.8044 - val_loss: 107.6835\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 67.6017 - val_loss: 79.4781\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 72.1293 - val_loss: 128.4239\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 60.7143 - val_loss: 84.5692\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 56.0395 - val_loss: 72.9923\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 60.6914 - val_loss: 111.0541\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 78.3043 - val_loss: 128.1787\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 65.9223 - val_loss: 77.8410\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 52.2195 - val_loss: 79.1746\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 49.1908 - val_loss: 88.0779\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 41.4474 - val_loss: 72.4828\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 34.9524 - val_loss: 83.3969\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 34.5908 - val_loss: 80.8355\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 34.8279 - val_loss: 85.8004\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 59.1123 - val_loss: 136.0760\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 48.8780 - val_loss: 92.2482\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 37.3931 - val_loss: 70.7719\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 34.4687 - val_loss: 92.9031\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 53.1932 - val_loss: 108.7003\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 51.2765 - val_loss: 80.3776\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 43.4606 - val_loss: 142.0469\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 43.9316 - val_loss: 79.0765\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 36.8162 - val_loss: 77.8513\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 27.9156 - val_loss: 72.4646\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 33.5381 - val_loss: 100.4575\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 50.1005 - val_loss: 83.2493\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 40.6903 - val_loss: 89.1201\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 35.2417 - val_loss: 67.0151\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 29.6673 - val_loss: 78.3223\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 21.0953 - val_loss: 66.6869\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 22.4996 - val_loss: 67.7525\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 18.6300 - val_loss: 61.6473\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 20.7163 - val_loss: 73.9785\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 92s 2s/step - loss: 24.9627 - val_loss: 71.0056\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 33.7835 - val_loss: 67.9118\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 27.1884 - val_loss: 67.7256\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 25.4797 - val_loss: 85.7473\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 31.6529 - val_loss: 81.2704\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 27.8994 - val_loss: 68.0241\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 31.3915 - val_loss: 73.8643\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 24.0720 - val_loss: 61.6139\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 28.9994 - val_loss: 65.8815\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 40.1114 - val_loss: 132.6927\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 43.8634 - val_loss: 100.4892\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 36.1609 - val_loss: 82.9543\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 29.1166 - val_loss: 70.2988\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 28.4652 - val_loss: 67.6313\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 32.6438 - val_loss: 81.2423\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 41.6624 - val_loss: 94.2963\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 32.8058 - val_loss: 73.5898\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 32.4747 - val_loss: 87.5491\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 34.3812 - val_loss: 88.5686\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 30.0377 - val_loss: 74.2898\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 17.3698 - val_loss: 62.2787\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 20.4742 - val_loss: 70.2947\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 17.8610 - val_loss: 70.7531\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 19.8287 - val_loss: 85.4531\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 22.9339 - val_loss: 62.8144\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 15.6319 - val_loss: 80.2230\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 20.9656 - val_loss: 65.1250\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 20.3766 - val_loss: 57.2957\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 16.3121 - val_loss: 63.2378\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 17.6005 - val_loss: 60.8533\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 23.3379 - val_loss: 60.1379\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 13.9319 - val_loss: 65.9987\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 16.4689 - val_loss: 75.7100\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 34.2229 - val_loss: 64.0459\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 29.9681 - val_loss: 66.3617\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 15.5795 - val_loss: 60.7740\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 21.4132 - val_loss: 60.9228\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 25.9837 - val_loss: 74.6211\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 14.4286 - val_loss: 62.5420\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 13.5437 - val_loss: 61.0991\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 13.6275 - val_loss: 52.9608\n",
      "Epoch 121/300\n",
      "42/42 [==============================] - 94s 2s/step - loss: 11.9550 - val_loss: 60.4420\n",
      "Epoch 122/300\n",
      "42/42 [==============================] - 95s 2s/step - loss: 15.3012 - val_loss: 64.0740\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 19.2981 - val_loss: 57.4231\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 14.0870 - val_loss: 61.6368\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - 94s 2s/step - loss: 13.8685 - val_loss: 60.4648\n",
      "Epoch 126/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 13.7338 - val_loss: 64.5233\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - 94s 2s/step - loss: 18.6409 - val_loss: 81.3030\n",
      "Epoch 128/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 23.0014 - val_loss: 68.5360\n",
      "Epoch 129/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 19.5620 - val_loss: 65.3184\n",
      "Epoch 130/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 42.5982 - val_loss: 73.6164\n",
      "Epoch 131/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 31.9610 - val_loss: 99.3878\n",
      "Epoch 132/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 21.5583 - val_loss: 64.0188\n",
      "Epoch 133/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 14.1531 - val_loss: 69.2513\n",
      "Epoch 134/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 19.1279 - val_loss: 85.1885\n",
      "Epoch 135/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 28.9696 - val_loss: 71.4565\n",
      "Epoch 136/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 16.8835 - val_loss: 70.6467\n",
      "Epoch 137/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 23.4414 - val_loss: 64.5076\n",
      "Epoch 138/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 24.9357 - val_loss: 64.9150\n",
      "Epoch 139/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 15.0159 - val_loss: 62.9392\n",
      "Epoch 140/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 12.1867 - val_loss: 56.3934\n",
      "Epoch 141/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 11.6935 - val_loss: 60.6333\n",
      "Epoch 142/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 15.0188 - val_loss: 53.0714\n",
      "Epoch 143/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 13.7662 - val_loss: 59.6267\n",
      "Epoch 144/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 10.5756 - val_loss: 52.3348\n",
      "Epoch 145/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 10.3223 - val_loss: 52.6011\n",
      "Epoch 146/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 8.9285 - val_loss: 54.6760\n",
      "Epoch 147/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 10.6818 - val_loss: 54.2676\n",
      "Epoch 148/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 8.3497 - val_loss: 51.9820\n",
      "Epoch 149/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 7.4073 - val_loss: 61.2916\n",
      "Epoch 150/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 9.1432 - val_loss: 54.0908\n",
      "Epoch 151/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 16.4966 - val_loss: 75.6179\n",
      "Epoch 152/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 19.8505 - val_loss: 58.6261\n",
      "Epoch 153/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 26.0913 - val_loss: 83.9344\n",
      "Epoch 154/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 17.3264 - val_loss: 57.3589\n",
      "Epoch 155/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 11.9302 - val_loss: 58.4068\n",
      "Epoch 156/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 12.3462 - val_loss: 53.3924\n",
      "Epoch 157/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 11.7228 - val_loss: 55.6353\n",
      "Epoch 158/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 15.9078 - val_loss: 55.5195\n",
      "Epoch 159/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 17.8642 - val_loss: 59.1524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 12.3819 - val_loss: 56.0758\n",
      "Epoch 161/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 8.6034 - val_loss: 55.6001\n",
      "Epoch 162/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 7.4882 - val_loss: 54.7066\n",
      "Epoch 163/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 8.6375 - val_loss: 48.6266\n",
      "Epoch 164/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 8.3696 - val_loss: 54.7379\n",
      "Epoch 165/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 6.0901 - val_loss: 51.6694\n",
      "Epoch 166/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 6.4561 - val_loss: 52.7668\n",
      "Epoch 167/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.1767 - val_loss: 50.8533\n",
      "Epoch 168/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.4358 - val_loss: 50.5342\n",
      "Epoch 169/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 7.8576 - val_loss: 52.4084\n",
      "Epoch 170/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 13.9638 - val_loss: 59.7090\n",
      "Epoch 171/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 25.4366 - val_loss: 64.6620\n",
      "Epoch 172/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 56.4326 - val_loss: 107.2306\n",
      "Epoch 173/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 63.5869 - val_loss: 155.3792\n",
      "Epoch 174/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 50.9048 - val_loss: 112.5377\n",
      "Epoch 175/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 48.1419 - val_loss: 75.0266\n",
      "Epoch 176/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 21.2552 - val_loss: 69.0229\n",
      "Epoch 177/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 13.2359 - val_loss: 55.9485\n",
      "Epoch 178/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 10.2375 - val_loss: 52.6993\n",
      "Epoch 179/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 8.6604 - val_loss: 55.5268\n",
      "Epoch 180/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.2213 - val_loss: 50.2429\n",
      "Epoch 181/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.6503 - val_loss: 50.6108\n",
      "Epoch 182/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 4.5770 - val_loss: 49.2566\n",
      "Epoch 183/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.5133 - val_loss: 48.8370\n",
      "Epoch 184/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 6.0046 - val_loss: 49.4927\n",
      "Epoch 185/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.9273 - val_loss: 50.8104\n",
      "Epoch 186/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.2802 - val_loss: 49.7617\n",
      "Epoch 187/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.6966 - val_loss: 52.7759\n",
      "Epoch 188/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.4197 - val_loss: 49.4096\n",
      "Epoch 189/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.4149 - val_loss: 49.6865\n",
      "Epoch 190/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.0851 - val_loss: 48.2994\n",
      "Epoch 191/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 4.9059 - val_loss: 50.9677\n",
      "Epoch 192/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 6.4248 - val_loss: 53.2701\n",
      "Epoch 193/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 7.2303 - val_loss: 54.6054\n",
      "Epoch 194/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.8108 - val_loss: 50.1323\n",
      "Epoch 195/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.7487 - val_loss: 48.8935\n",
      "Epoch 196/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.8284 - val_loss: 53.8528\n",
      "Epoch 197/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 4.6593 - val_loss: 50.3439\n",
      "Epoch 198/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 6.3407 - val_loss: 51.1601\n",
      "Epoch 199/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.2654 - val_loss: 59.2912\n",
      "Epoch 200/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 8.1758 - val_loss: 55.5337\n",
      "Epoch 201/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 11.2896 - val_loss: 60.1379\n",
      "Epoch 202/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 13.2649 - val_loss: 53.8541\n",
      "Epoch 203/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 10.7331 - val_loss: 59.2329\n",
      "Epoch 204/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 9.4180 - val_loss: 55.7564\n",
      "Epoch 205/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 7.3117 - val_loss: 61.9646\n",
      "Epoch 206/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 10.1333 - val_loss: 54.9650\n",
      "Epoch 207/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 7.0196 - val_loss: 53.2776\n",
      "Epoch 208/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 8.0215 - val_loss: 58.2654\n",
      "Epoch 209/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 12.4115 - val_loss: 57.5304\n",
      "Epoch 210/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 22.0271 - val_loss: 69.5508\n",
      "Epoch 211/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 20.4672 - val_loss: 50.5713\n",
      "Epoch 212/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 16.5960 - val_loss: 60.0750\n",
      "Epoch 213/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 14.3786 - val_loss: 52.6484\n",
      "Epoch 214/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 11.1152 - val_loss: 62.0120\n",
      "Epoch 215/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 7.9708 - val_loss: 54.7217\n",
      "Epoch 216/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 8.0347 - val_loss: 52.6503\n",
      "Epoch 217/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 8.4223 - val_loss: 56.7647\n",
      "Epoch 218/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 8.5268 - val_loss: 56.1489\n",
      "Epoch 219/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 7.9473 - val_loss: 53.1815\n",
      "Epoch 220/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 7.6259 - val_loss: 53.8630\n",
      "Epoch 221/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 8.2083 - val_loss: 54.0772\n",
      "Epoch 222/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 9.2986 - val_loss: 65.3540\n",
      "Epoch 223/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 9.4270 - val_loss: 56.3751\n",
      "Epoch 224/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 13.4714 - val_loss: 70.1078\n",
      "Epoch 225/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 22.6686 - val_loss: 72.6565\n",
      "Epoch 226/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 26.4211 - val_loss: 70.1873\n",
      "Epoch 227/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 22.3697 - val_loss: 73.7632\n",
      "Epoch 228/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 23.0447 - val_loss: 60.8943\n",
      "Epoch 229/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 9.8875 - val_loss: 55.6313\n",
      "Epoch 230/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 8.5639 - val_loss: 55.3783\n",
      "Epoch 231/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 7.8608 - val_loss: 50.9734\n",
      "Epoch 232/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 6.1288 - val_loss: 47.7012\n",
      "Epoch 233/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.1202 - val_loss: 51.6082\n",
      "Epoch 234/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.8939 - val_loss: 49.7912\n",
      "Epoch 235/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.1384 - val_loss: 52.6152\n",
      "Epoch 236/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.9196 - val_loss: 49.3725\n",
      "Epoch 237/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.5057 - val_loss: 51.2173\n",
      "Epoch 238/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.1334 - val_loss: 52.2106\n",
      "Epoch 239/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.7603 - val_loss: 49.2734\n",
      "Epoch 240/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 92s 2s/step - loss: 4.9528 - val_loss: 48.0733\n",
      "Epoch 241/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.7786 - val_loss: 56.6047\n",
      "Epoch 242/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 6.7816 - val_loss: 52.3789\n",
      "Epoch 243/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 8.7328 - val_loss: 50.0263\n",
      "Epoch 244/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 7.1497 - val_loss: 50.2398\n",
      "Epoch 245/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 5.2702 - val_loss: 50.7327\n",
      "Epoch 246/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 3.4392 - val_loss: 48.3459\n",
      "Epoch 247/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 6.0337 - val_loss: 52.1342\n",
      "Epoch 248/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 8.0339 - val_loss: 50.1806\n",
      "Epoch 249/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 6.6637 - val_loss: 48.9225\n",
      "Epoch 250/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.7417 - val_loss: 49.0384\n",
      "Epoch 251/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 7.3374 - val_loss: 48.8540\n",
      "Epoch 252/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 7.0817 - val_loss: 53.0437\n",
      "Epoch 253/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 7.7899 - val_loss: 56.7221\n",
      "Epoch 254/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 7.7278 - val_loss: 54.2843\n",
      "Epoch 255/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 6.9025 - val_loss: 51.4256\n",
      "Epoch 256/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 6.9637 - val_loss: 57.3408\n",
      "Epoch 257/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 8.1008 - val_loss: 54.7868\n",
      "Epoch 258/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 14.0565 - val_loss: 58.2213\n",
      "Epoch 259/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 9.9912 - val_loss: 55.0963\n",
      "Epoch 260/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 19.4200 - val_loss: 73.8604\n",
      "Epoch 261/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 29.1260 - val_loss: 64.5560\n",
      "Epoch 262/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 16.8509 - val_loss: 63.3457\n",
      "Epoch 263/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 12.1417 - val_loss: 67.4219\n",
      "Epoch 264/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 8.4907 - val_loss: 53.8592\n",
      "Epoch 265/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 9.3707 - val_loss: 63.8715\n",
      "Epoch 266/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 12.2281 - val_loss: 67.0552\n",
      "Epoch 267/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 14.5193 - val_loss: 62.3347\n",
      "Epoch 268/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 12.7605 - val_loss: 55.4757\n",
      "Epoch 269/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 7.0378 - val_loss: 59.8468\n",
      "Epoch 270/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 8.1436 - val_loss: 49.4408\n",
      "Epoch 271/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 3.8638 - val_loss: 53.0009\n",
      "Epoch 272/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.3904 - val_loss: 48.9465\n",
      "Epoch 273/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 3.2858 - val_loss: 47.1420\n",
      "Epoch 274/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.8135 - val_loss: 49.3841\n",
      "Epoch 275/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 3.2175 - val_loss: 47.1946\n",
      "Epoch 276/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 2.5806 - val_loss: 47.0258\n",
      "Epoch 277/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 2.6831 - val_loss: 48.8608\n",
      "Epoch 278/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 1.6295 - val_loss: 46.3672\n",
      "Epoch 279/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 1.4425 - val_loss: 47.0193\n",
      "Epoch 280/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 1.7264 - val_loss: 47.5215\n",
      "Epoch 281/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 2.0809 - val_loss: 45.8941\n",
      "Epoch 282/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 3.7953 - val_loss: 51.4292\n",
      "Epoch 283/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 3.6746 - val_loss: 49.8974\n",
      "Epoch 284/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.2364 - val_loss: 49.7668\n",
      "Epoch 285/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.0364 - val_loss: 49.4999\n",
      "Epoch 286/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 6.2959 - val_loss: 53.6595\n",
      "Epoch 287/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 6.6868 - val_loss: 58.1132\n",
      "Epoch 288/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 10.9265 - val_loss: 53.8207\n",
      "Epoch 289/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 7.5362 - val_loss: 55.3979\n",
      "Epoch 290/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 9.0692 - val_loss: 55.1885\n",
      "Epoch 291/300\n",
      "42/42 [==============================] - 94s 2s/step - loss: 6.3434 - val_loss: 49.8221\n",
      "Epoch 292/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.0518 - val_loss: 48.5566\n",
      "Epoch 293/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 2.8328 - val_loss: 48.5943\n",
      "Epoch 294/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 1.9905 - val_loss: 48.4807\n",
      "Epoch 295/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 3.0597 - val_loss: 48.3464\n",
      "Epoch 296/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 5.2067 - val_loss: 50.2436\n",
      "Epoch 297/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 6.1982 - val_loss: 50.0109\n",
      "Epoch 298/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 5.1423 - val_loss: 50.1363\n",
      "Epoch 299/300\n",
      "42/42 [==============================] - 92s 2s/step - loss: 4.9952 - val_loss: 49.3760\n",
      "Epoch 300/300\n",
      "42/42 [==============================] - 93s 2s/step - loss: 4.3344 - val_loss: 51.5995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3320486340>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = CSVLogger(store_path + \"/log\")\n",
    "\n",
    "callbacks = [logger]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)\n",
    "#model.fit_generator(train_gen,\n",
    "#          validation_data=validation_gen,\n",
    "#          callbacks=callbacks,\n",
    "#          epochs=100)\n",
    "\n",
    "\n",
    "model.fit(train_gen,\n",
    "          epochs=300,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          #use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(store_path + \"/weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cube(img, x, y, val):\n",
    "    \n",
    "    img[y][x] = val\n",
    "    img[y][x-1] = val\n",
    "    img[y][x+1] = val\n",
    "    img[y-1][x] = val\n",
    "    img[y-1][x-1] = val\n",
    "    img[y-1][x+1] = val\n",
    "    img[y+1][x] = val\n",
    "    img[y+1][x-1] = val\n",
    "    img[y+1][x+1] = val  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
