{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements\n",
    "Following packages are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "from simplegen import SIMPLESequence\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "from unet import UNet\n",
    "from unet import preprocess_input as pre_une\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Checks\n",
    "The version of tensorflow as well as the GPU support are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable all GPUS\n",
    "  tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "  visible_devices = tf.config.experimental.get_visible_devices()\n",
    "  for device in visible_devices:\n",
    "    assert device.device_type != 'GPU'\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "\n",
    "print(tf.config.experimental.get_visible_devices('GPU'))\n",
    "print(tf.config.experimental.get_visible_devices('CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality\n",
    "Necessary funcionality is added here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cube(img, x, y, val):\n",
    "    \n",
    "    img[y][x] = val\n",
    "    img[y][x-1] = val\n",
    "    img[y][x+1] = val\n",
    "    img[y-1][x] = val\n",
    "    img[y-1][x-1] = val\n",
    "    img[y-1][x+1] = val\n",
    "    img[y+1][x] = val\n",
    "    img[y+1][x-1] = val\n",
    "    img[y+1][x+1] = val  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4) Supervised Euclidean for SIMPLEA\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_4_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLEA\\train\\0_f.json'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLEA\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLEA\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLEA\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True)\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une)\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 65s 78ms/step - loss: 1000.0686 - val_loss: 779.0770\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 55s 65ms/step - loss: 770.5267 - val_loss: 785.7555\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 56s 67ms/step - loss: 640.2238 - val_loss: 203.9792\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 56s 66ms/step - loss: 110.0115 - val_loss: 96.7095\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 54s 65ms/step - loss: 71.9209 - val_loss: 65.6165\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 56s 67ms/step - loss: 55.8573 - val_loss: 70.3511\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 55s 65ms/step - loss: 49.1558 - val_loss: 45.4132\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 57s 68ms/step - loss: 44.7916 - val_loss: 47.3470\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 54s 65ms/step - loss: 38.6117 - val_loss: 44.6555\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 57s 67ms/step - loss: 35.3207 - val_loss: 39.3393\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 56s 67ms/step - loss: 31.8075 - val_loss: 37.6797\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 55s 66ms/step - loss: 29.9514 - val_loss: 41.6000\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 28.0792 - val_loss: 34.0515\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 25.1876 - val_loss: 39.4385\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 25.0670 - val_loss: 37.1771\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 22.4001 - val_loss: 30.1022\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 21.0528 - val_loss: 32.9449\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 18.2958 - val_loss: 33.7210\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 18.3885 - val_loss: 35.8641\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 15.9081 - val_loss: 30.8212\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 63s 76ms/step - loss: 15.5924 - val_loss: 29.2261\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 13.2640 - val_loss: 32.0408\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 12.3691 - val_loss: 31.0905\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 11.6770 - val_loss: 33.5991\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 10.4832 - val_loss: 27.9381\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 10.2589 - val_loss: 31.6415\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 9.0508 - val_loss: 27.8978\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 8.3828 - val_loss: 30.4146\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 7.9143 - val_loss: 29.0121\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 7.3853 - val_loss: 30.7737\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 6.3916 - val_loss: 29.1227\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 7.3611 - val_loss: 29.1986\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 6.3400 - val_loss: 30.2488\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 5.5802 - val_loss: 26.2786\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 5.2948 - val_loss: 26.6510\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 63s 76ms/step - loss: 4.5210 - val_loss: 27.7300\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 5.3524 - val_loss: 29.0133\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 5.2755 - val_loss: 30.6721\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 3.8224 - val_loss: 26.9378\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 3.2466 - val_loss: 28.8255\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 4.3809 - val_loss: 27.4141\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 3.4545 - val_loss: 26.7955\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 3.7328 - val_loss: 25.3571\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 3.5277 - val_loss: 28.0292\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 3.1989 - val_loss: 27.0763\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 2.7814 - val_loss: 27.4415\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 3.2091 - val_loss: 25.4786\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 2.5193 - val_loss: 29.3244\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 3.1183 - val_loss: 26.2341\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 2.5428 - val_loss: 25.3373\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 3.1708 - val_loss: 27.7892\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 2.3685 - val_loss: 25.4635\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 2.1101 - val_loss: 24.8881\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 2.4425 - val_loss: 28.2351\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 2.1767 - val_loss: 27.3080\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 2.1323 - val_loss: 26.3834\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 2.2127 - val_loss: 25.1787\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 1.9275 - val_loss: 26.9120\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 2.2242 - val_loss: 25.3215\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 1.4680 - val_loss: 25.0411\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 1.8506 - val_loss: 24.8424\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 1.9740 - val_loss: 27.7326\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 2.2389 - val_loss: 26.4469\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 1.1527 - val_loss: 25.8645\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.7448 - val_loss: 25.6271\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 63s 76ms/step - loss: 1.6289 - val_loss: 25.6772\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.6089 - val_loss: 24.6643\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 1.3802 - val_loss: 24.0204\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 1.0767 - val_loss: 23.6231\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 1.8465 - val_loss: 28.1107\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: 2.4476 - val_loss: 25.1882\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 0.9473 - val_loss: 25.1572\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 1.2654 - val_loss: 25.5561\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 1.0129 - val_loss: 26.0562\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 1.6339 - val_loss: 25.7656\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 2.1547 - val_loss: 27.1450\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 0.9151 - val_loss: 24.8995\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 0.6563 - val_loss: 25.2296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 1.2380 - val_loss: 24.7611\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 1.0668 - val_loss: 26.5021\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 1.9711 - val_loss: 27.2345\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 1.5429 - val_loss: 26.8496\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 0.7263 - val_loss: 25.4412\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 0.5927 - val_loss: 25.1284\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 1.2762 - val_loss: 24.8073\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.3195 - val_loss: 25.8591\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.6377 - val_loss: 27.4232\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 0.9557 - val_loss: 26.6343\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 0.7350 - val_loss: 25.9545\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 0.7367 - val_loss: 25.5105\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 0.8406 - val_loss: 24.8690\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 0.8510 - val_loss: 25.4533\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 2.0647 - val_loss: 27.2922\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 0.9005 - val_loss: 26.0584\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 0.5703 - val_loss: 24.7690\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 0.6818 - val_loss: 24.8121\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 0.6938 - val_loss: 25.3604\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.4487 - val_loss: 28.9895\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 0.9725 - val_loss: 25.3670\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.5412 - val_loss: 25.9498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2238019a548>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          #use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5) Supervised Euclidean for SIMPLEN\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_5_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLEN\\train\\0_f.json'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLEN\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLEN\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLEN\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True)\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une)\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 74s 88ms/step - loss: 804.5185 - val_loss: 687.5201\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 647.8115 - val_loss: 661.3540\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 630.6889 - val_loss: 548.5919\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 228.7215 - val_loss: 129.3611\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 74.6355 - val_loss: 69.6957\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 51.9818 - val_loss: 55.6849\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 45.6530 - val_loss: 74.7533\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 38.4881 - val_loss: 42.3087\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 32.9382 - val_loss: 53.3336\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 31.1455 - val_loss: 42.6666\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 26.8525 - val_loss: 51.7318\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 25.2726 - val_loss: 33.6132\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 23.7660 - val_loss: 33.4663\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 18.5520 - val_loss: 34.4306\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 63s 76ms/step - loss: 17.5580 - val_loss: 32.8619\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 14.4608 - val_loss: 27.4797\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 14.3649 - val_loss: 28.0372\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 12.7499 - val_loss: 27.2085\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 11.2304 - val_loss: 26.7114\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 9.7901 - val_loss: 23.8609\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 9.2398 - val_loss: 31.2717\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 8.3010 - val_loss: 29.7952\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 7.9014 - val_loss: 25.0624\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 7.3763 - val_loss: 23.2247\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 6.1797 - val_loss: 28.3865\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 6.8323 - val_loss: 23.4964\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 4.9236 - val_loss: 26.2421\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 5.4775 - val_loss: 22.4423\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 4.8716 - val_loss: 21.2017\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 4.7370 - val_loss: 20.8310\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 65s 78ms/step - loss: 4.2528 - val_loss: 22.2856\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 4.3314 - val_loss: 23.6437\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 4.1447 - val_loss: 19.0561\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 3.5117 - val_loss: 20.4685\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 3.6748 - val_loss: 20.6579\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 3.2095 - val_loss: 20.0514\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 2.7133 - val_loss: 19.8751\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 3.9099 - val_loss: 20.8502\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 3.2460 - val_loss: 19.3562\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 2.5692 - val_loss: 22.5099\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 3.5440 - val_loss: 21.4738\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 2.4237 - val_loss: 19.8269\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 63s 76ms/step - loss: 1.8319 - val_loss: 18.0055\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 3.4927 - val_loss: 20.8809\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 66s 78ms/step - loss: 2.1780 - val_loss: 18.0484\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 1.8107 - val_loss: 18.4961\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 2.1587 - val_loss: 23.0932\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 2.8191 - val_loss: 20.1541\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.8276 - val_loss: 18.6257\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 1.6097 - val_loss: 19.5766\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 2.6027 - val_loss: 20.7604\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 1.5731 - val_loss: 19.6667\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.3732 - val_loss: 18.3277\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 2.4680 - val_loss: 22.1881\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 1.3585 - val_loss: 18.9832\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 1.0743 - val_loss: 19.6322\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 1.9069 - val_loss: 25.5105\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 2.2860 - val_loss: 18.9445\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 1.0868 - val_loss: 18.1736\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 1.2863 - val_loss: 18.1121\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 65s 77ms/step - loss: 2.5182 - val_loss: 20.3326\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 64s 77ms/step - loss: 1.0982 - val_loss: 17.7853\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 0.7739 - val_loss: 17.4195\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.0484 - val_loss: 20.5161\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 2.7331 - val_loss: 22.1031\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.1230 - val_loss: 19.7126\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 0.7827 - val_loss: 18.2704\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 0.8956 - val_loss: 17.7557\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.7056 - val_loss: 21.6066\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.8116 - val_loss: 18.5421\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 63s 76ms/step - loss: 0.7379 - val_loss: 17.9098\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 0.6398 - val_loss: 18.0917\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.0934 - val_loss: 19.4749\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 1.9918 - val_loss: 21.3724\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 1.4402 - val_loss: 20.7832\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 0.7057 - val_loss: 18.4149\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.6704 - val_loss: 19.6203\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.8175 - val_loss: 18.2829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 0.8302 - val_loss: 27.2190\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 1.6088 - val_loss: 18.7437\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 0.7429 - val_loss: 18.4543\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 0.7867 - val_loss: 18.0485\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.9716 - val_loss: 18.9572\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 0.6137 - val_loss: 17.9031\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 0.8308 - val_loss: 18.6511\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 1.2129 - val_loss: 22.3935\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.1719 - val_loss: 19.4210\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.6381 - val_loss: 18.3222\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 0.6233 - val_loss: 19.0405\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 0.8797 - val_loss: 20.6731\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.8064 - val_loss: 22.0121\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.8972 - val_loss: 18.4163\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.8693 - val_loss: 21.6201\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 0.5882 - val_loss: 18.2218\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.6117 - val_loss: 20.5403\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 1.2944 - val_loss: 19.0570\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.4757 - val_loss: 17.8951\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.4836 - val_loss: 18.0992\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 0.6267 - val_loss: 18.5055\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 1.1818 - val_loss: 25.6374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22390077a08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          #use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6) Supervised Euclidean for SIMPLED\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_6_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLED\\train\\0_f.json'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLED\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLED\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLED\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True)\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une)\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 79s 94ms/step - loss: 779.6459 - val_loss: 641.4883\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 611.1755 - val_loss: 568.3593\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 265.6559 - val_loss: 108.7318\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 63s 75ms/step - loss: 80.8760 - val_loss: 77.2299\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 59s 70ms/step - loss: 64.0341 - val_loss: 63.1243\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 57.6748 - val_loss: 58.6149\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 47.8577 - val_loss: 54.1050\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 40.7174 - val_loss: 47.9560\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 59s 71ms/step - loss: 36.8257 - val_loss: 40.5744\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 31.8501 - val_loss: 46.0011\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 28.0352 - val_loss: 40.1829\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 25.8780 - val_loss: 40.9808\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 59s 71ms/step - loss: 22.3933 - val_loss: 37.6382\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 20.7760 - val_loss: 33.6590\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 17.6420 - val_loss: 42.0075\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 14.5810 - val_loss: 32.1182\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 14.6057 - val_loss: 32.4166\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 11.9415 - val_loss: 29.3502\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 11.0317 - val_loss: 30.4387\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 10.5065 - val_loss: 29.7343\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 8.9109 - val_loss: 24.8935\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 8.3035 - val_loss: 25.9764\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 7.8312 - val_loss: 29.0356\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 6.4384 - val_loss: 26.7405\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 6.4712 - val_loss: 29.5447\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 6.0974 - val_loss: 27.8343\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 5.6235 - val_loss: 23.5751\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 5.0154 - val_loss: 29.8789\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 5.0822 - val_loss: 22.7096\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 3.8245 - val_loss: 24.1488\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 5.2230 - val_loss: 29.2072\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 59s 70ms/step - loss: 3.4139 - val_loss: 24.7417\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 59s 71ms/step - loss: 3.2917 - val_loss: 23.2559\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 4.3415 - val_loss: 24.0541\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 59s 71ms/step - loss: 2.7594 - val_loss: 22.2870\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 2.5900 - val_loss: 21.8352\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 3.1922 - val_loss: 25.8175\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 58s 69ms/step - loss: 4.0880 - val_loss: 25.0971\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 2.1044 - val_loss: 22.2568\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 2.3525 - val_loss: 22.5406\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 1.9870 - val_loss: 23.3600\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 3.6408 - val_loss: 28.8932\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 2.3973 - val_loss: 24.8577\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 1.7240 - val_loss: 22.3363\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 1.4477 - val_loss: 46.7367\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 59s 71ms/step - loss: 3.2698 - val_loss: 23.5268\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 1.7739 - val_loss: 21.8410\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 59s 70ms/step - loss: 1.5324 - val_loss: 24.1195\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 2.4577 - val_loss: 22.5978\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 1.2792 - val_loss: 22.5968\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 2.8016 - val_loss: 56.4055\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 1.5693 - val_loss: 21.8660\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 59s 71ms/step - loss: 1.2645 - val_loss: 21.4897\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 1.5643 - val_loss: 27.0836\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 59s 71ms/step - loss: 2.1968 - val_loss: 23.8912\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 1.4384 - val_loss: 25.2484\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 1.5107 - val_loss: 22.2238\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 1.1366 - val_loss: 21.6733\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 1.0687 - val_loss: 21.0787\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 62s 73ms/step - loss: 1.4907 - val_loss: 22.1270\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 2.0575 - val_loss: 24.1139\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 1.1372 - val_loss: 21.7260\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 0.8361 - val_loss: 21.2595\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 59s 70ms/step - loss: 1.6900 - val_loss: 74.6455\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 0.8403 - val_loss: 21.2530\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 59s 70ms/step - loss: 0.7516 - val_loss: 21.5609\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 1.8434 - val_loss: 26.4010\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 59s 71ms/step - loss: 1.3996 - val_loss: 22.3366\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 64s 76ms/step - loss: 0.7619 - val_loss: 23.5568\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 0.8680 - val_loss: 22.4733\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 1.0364 - val_loss: 26.5642\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.6413 - val_loss: 23.4314\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 0.5959 - val_loss: 22.4366\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 0.6562 - val_loss: 22.6212\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 0.7949 - val_loss: 22.0039\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 1.3599 - val_loss: 35.9915\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 2.1897 - val_loss: 22.1251\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 0.4471 - val_loss: 20.9190\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 0.5036 - val_loss: 21.4118\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 0.6009 - val_loss: 21.3618\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 1.8033 - val_loss: 24.9976\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 1.0828 - val_loss: 22.5872\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 0.9061 - val_loss: 22.7579\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 0.5067 - val_loss: 20.9867\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 0.4567 - val_loss: 21.1293\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 58s 69ms/step - loss: 0.5788 - val_loss: 23.2045\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 62s 74ms/step - loss: 1.6492 - val_loss: 24.2290\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 59s 70ms/step - loss: 0.6135 - val_loss: 24.7320\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 0.9053 - val_loss: 24.2037\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 0.6486 - val_loss: 22.3463\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 0.4315 - val_loss: 22.5242\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 0.5419 - val_loss: 21.3749\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 61s 73ms/step - loss: 0.6807 - val_loss: 30.1347\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 1.6759 - val_loss: 24.0992\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 0.4720 - val_loss: 22.4954\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 0.3495 - val_loss: 21.6131\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 0.3913 - val_loss: 21.7223\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 60s 72ms/step - loss: 0.7952 - val_loss: 23.4121\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 60s 71ms/step - loss: 1.5132 - val_loss: 23.2021\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 61s 72ms/step - loss: 0.4114 - val_loss: 22.8499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15232d0a388>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          #use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1520ddb3448>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
