{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements\n",
    "Following packages are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "from simplegen import SIMPLESequence\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "from unet import UNet\n",
    "from unet import preprocess_input as pre_une\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Checks\n",
    "The version of tensorflow as well as the GPU support are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality\n",
    "Necessary funcionality is added here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cube(img, x, y, val):\n",
    "    \n",
    "    img[y][x] = val\n",
    "    img[y][x-1] = val\n",
    "    img[y][x+1] = val\n",
    "    img[y-1][x] = val\n",
    "    img[y-1][x-1] = val\n",
    "    img[y-1][x+1] = val\n",
    "    img[y+1][x] = val\n",
    "    img[y+1][x-1] = val\n",
    "    img[y+1][x+1] = val  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.8) Supervised Euclidean for SIMPLED with fixed image\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_8_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLED\\train\\0'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLED\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLED\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLED\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True,\n",
    "                           multi_channel='fixed')\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une,\n",
    "                                multi_channel='fixed')\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 82s 98ms/step - loss: 722.3557 - val_loss: 609.9671\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 73s 86ms/step - loss: 295.2440 - val_loss: 69.2219\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 63.9594 - val_loss: 40.3651\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 43.8902 - val_loss: 134.2030\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 34.9258 - val_loss: 44.4679\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 29.1634 - val_loss: 24.8344\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 26.7894 - val_loss: 35.6561\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 24.6091 - val_loss: 23.7568\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 21.0550 - val_loss: 21.3612\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 20.4461 - val_loss: 25.2225\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 15.3134 - val_loss: 18.1396\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 16.7065 - val_loss: 35.5319\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 14.9690 - val_loss: 18.6292\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 14.2445 - val_loss: 10.4626\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 11.7442 - val_loss: 13.6364\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 10.3303 - val_loss: 14.6317\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 9.4774 - val_loss: 12.4873\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 8.8505 - val_loss: 8.6820\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 8.4456 - val_loss: 10.3180\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 7.0369 - val_loss: 10.1059\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 7.7543 - val_loss: 7.7725\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 6.5877 - val_loss: 6.6305\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 6.4059 - val_loss: 11.5036\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 5.6017 - val_loss: 6.6035\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 7.3943 - val_loss: 17.0442\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 4.1597 - val_loss: 7.6560\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 3.4855 - val_loss: 6.6394\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 4.9653 - val_loss: 9.1978\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 4.2180 - val_loss: 5.4700\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 3.7530 - val_loss: 4.8320\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 3.4586 - val_loss: 8.7300\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 3.4333 - val_loss: 6.4633\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 3.4488 - val_loss: 5.2551\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 2.9256 - val_loss: 5.7641\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.8630 - val_loss: 5.3245\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.7549 - val_loss: 7.1949\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 2.6176 - val_loss: 4.5103\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 2.5950 - val_loss: 6.2699\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 2.2338 - val_loss: 65.5644\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 2.3926 - val_loss: 8.9356\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 3.2111 - val_loss: 4.2180\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.7937 - val_loss: 3.6373\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.1951 - val_loss: 4.0215\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 2.1402 - val_loss: 4.7524\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.3877 - val_loss: 4.7369\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.3213 - val_loss: 4.6151\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.7298 - val_loss: 3.6267\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 2.9429 - val_loss: 7.0996\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 1.2933 - val_loss: 4.2492\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 1.4630 - val_loss: 4.0198\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.5628 - val_loss: 4.5323\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 73s 86ms/step - loss: 1.3257 - val_loss: 3.9657\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 2.0079 - val_loss: 3.9582\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.4038 - val_loss: 3.6447\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.2383 - val_loss: 4.1534\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 1.2500 - val_loss: 4.7914\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.5824 - val_loss: 4.6598\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.7412 - val_loss: 3.7935\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.7160 - val_loss: 3.9693\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.8121 - val_loss: 3.2140\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 1.3593 - val_loss: 4.2506\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.9063 - val_loss: 3.3570\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 1.0077 - val_loss: 3.1178\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.1538 - val_loss: 3.6700\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.0701 - val_loss: 3.7147\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.0757 - val_loss: 3.7834\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.8659 - val_loss: 3.3312\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.5105 - val_loss: 4.3140\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.2395 - val_loss: 4.6605\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 0.6636 - val_loss: 3.1430\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.0221 - val_loss: 3.5977\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.0470 - val_loss: 19.1298\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 0.9958 - val_loss: 3.6596\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6393 - val_loss: 3.1894\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.3009 - val_loss: 4.0637\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.6813 - val_loss: 3.2044\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 0.8898 - val_loss: 3.6035\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6604 - val_loss: 2.8032\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.1199 - val_loss: 3.1837\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.8005 - val_loss: 3.2592\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.5610 - val_loss: 3.1302\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.7603 - val_loss: 2.9978\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.2282 - val_loss: 3.9371\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 0.6977 - val_loss: 2.7065\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.5404 - val_loss: 2.9330\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.6324 - val_loss: 3.4963\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6906 - val_loss: 2.8284\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.1340 - val_loss: 10.4809\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 0.7786 - val_loss: 3.1478\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 75s 89ms/step - loss: 0.4443 - val_loss: 2.9265\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.5222 - val_loss: 3.2656\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 0.7137 - val_loss: 2.9344\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6094 - val_loss: 29.6343\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.6618 - val_loss: 3.9200\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.6730 - val_loss: 3.3195\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.5864 - val_loss: 3.0188\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.5027 - val_loss: 2.9649\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.6682 - val_loss: 3.4974\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.5397 - val_loss: 2.9135\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.9166 - val_loss: 3.0209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20cc50db048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          #use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.9) Supervised Euclidean for SIMPLED with difference image\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/6_9_euclidean'\n",
    "\n",
    "path_fixed = r'D:\\Julian\\data\\SIMPLED\\train\\0'\n",
    "path_train = r'D:\\Julian\\data\\SIMPLED\\train'\n",
    "path_validation = r'D:\\Julian\\data\\SIMPLED\\validation'\n",
    "path_test = r'D:\\Julian\\data\\SIMPLED\\test'\n",
    "\n",
    "width = 224\n",
    "height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = SIMPLESequence(path_train, path_fixed,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True,\n",
    "                           multi_channel='diff')\n",
    "\n",
    "validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                batch_size=4,\n",
    "                                preprocess_input=pre_une,\n",
    "                                multi_channel='diff')\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "model.compile(optimizer='adam', loss = utils.msed_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 81s 96ms/step - loss: 757.4069 - val_loss: 640.1477\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 439.2043 - val_loss: 150.0228\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 79.9807 - val_loss: 75.4312\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 52.3318 - val_loss: 76.3395\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 73s 87ms/step - loss: 39.2280 - val_loss: 65.4678\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 35.5460 - val_loss: 77.2352\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 28.2335 - val_loss: 32.8263\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 27.1812 - val_loss: 22.8728\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 26.4021 - val_loss: 20.6045\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 18.4600 - val_loss: 44.5524\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 18.3134 - val_loss: 17.1779\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 19.5034 - val_loss: 52.8568\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 16.4010 - val_loss: 22.0580\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 17.4825 - val_loss: 21.6539\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 11.8730 - val_loss: 24.4566\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: 12.6390 - val_loss: 18.0994\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 14.0031 - val_loss: 11.8254\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 9.7723 - val_loss: 11.1713\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 68s 82ms/step - loss: 9.2784 - val_loss: 12.2530\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 9.3440 - val_loss: 14.4865\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 10.4172 - val_loss: 19.4509\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 7.9696 - val_loss: 10.8588\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 7.5513 - val_loss: 12.6281\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 8.8119 - val_loss: 8.0306\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 5.8594 - val_loss: 13.8541\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 5.6662 - val_loss: 8.3343\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 5.6210 - val_loss: 11.5610\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 5.4941 - val_loss: 14.2426\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 5.7018 - val_loss: 7.4105\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 5.6251 - val_loss: 8.2537\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 68s 82ms/step - loss: 4.5493 - val_loss: 8.1514\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 5.0679 - val_loss: 11.8772\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 4.9511 - val_loss: 10.5936\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 3.9330 - val_loss: 8.6905\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 68s 82ms/step - loss: 3.7379 - val_loss: 10.8000\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 3.7151 - val_loss: 13.2936\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 67s 79ms/step - loss: 4.6912 - val_loss: 6.9193\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 3.4355 - val_loss: 6.1304\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 4.0892 - val_loss: 10.2954\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 3.3225 - val_loss: 12.2125\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 3.0061 - val_loss: 4.9648\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 2.7785 - val_loss: 6.6441\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 3.7505 - val_loss: 9.2728\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 4.4313 - val_loss: 5.8715\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 2.7096 - val_loss: 6.4335\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 2.0794 - val_loss: 6.7528\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.3213 - val_loss: 7.9594\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 2.4580 - val_loss: 10.6667\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 3.8301 - val_loss: 10.8036\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.2104 - val_loss: 5.6546\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.9305 - val_loss: 6.6734\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.5775 - val_loss: 6.1830\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 3.3171 - val_loss: 6.4063\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.5320 - val_loss: 6.5424\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.7548 - val_loss: 7.9011\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 1.8027 - val_loss: 6.0857\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 3.0063 - val_loss: 6.7792\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.7677 - val_loss: 5.5337\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.0919 - val_loss: 5.4737\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 2.2223 - val_loss: 4.6179\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.8878 - val_loss: 7.0208\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 68s 80ms/step - loss: 1.3662 - val_loss: 5.7641\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.3374 - val_loss: 5.6684\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 2.3202 - val_loss: 6.9372\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.5204 - val_loss: 5.9781\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.2329 - val_loss: 5.7274\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.2508 - val_loss: 5.3900\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 1.9604 - val_loss: 6.2575\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.1883 - val_loss: 6.5609\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.3849 - val_loss: 6.8082\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 1.3849 - val_loss: 7.2827\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 1.5915 - val_loss: 5.6540\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.0349 - val_loss: 5.6681\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.0119 - val_loss: 6.1981\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.7980 - val_loss: 6.1941\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.5986 - val_loss: 5.1010\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 0.7863 - val_loss: 5.5739\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 67s 80ms/step - loss: 0.9161 - val_loss: 5.9827\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 68s 80ms/step - loss: 0.9114 - val_loss: 5.8119\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 3.1391 - val_loss: 6.7221\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 1.0048 - val_loss: 5.1509\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 0.6147 - val_loss: 5.2415\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 68s 80ms/step - loss: 0.6738 - val_loss: 5.7482\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.2051 - val_loss: 5.6797\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.2956 - val_loss: 6.0088\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 0.8488 - val_loss: 7.3573\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.7169 - val_loss: 5.9673\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 68s 80ms/step - loss: 1.4873 - val_loss: 13.4750\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.1492 - val_loss: 8.4052\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.8019 - val_loss: 5.9606\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 0.7705 - val_loss: 5.7761\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.8044 - val_loss: 6.4328\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 0.8314 - val_loss: 6.0891\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.1528 - val_loss: 27.9982\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.8800 - val_loss: 5.2670\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.4639 - val_loss: 5.1131\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 0.4156 - val_loss: 5.7118\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.7861 - val_loss: 5.8070\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.1926 - val_loss: 5.8400\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.1997 - val_loss: 9.4214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2128035a7c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
