{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing of Ground Truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statments. Ensure that the package 'endolas' that is shipped with this notebook can be imported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import warp\n",
    "from skimage.morphology import flood\n",
    "from skimage.filters import gaussian\n",
    "from glob import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "from endolas import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality\n",
    "This functionality block contains functionality needed to create the data sets. 4 Different files are created per sample point. Those are:\n",
    "- Endoscopic image of the current frame\n",
    "- Segmentation mask\n",
    "- File containing the x- and y-coordinates of each keypoint\n",
    "- Moving image. That is an imaginary camera projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_store(base_dir, save_dir, sources, image_index, height, width, sigma, sigma_back):\n",
    "    \"\"\" Extract all frames from .avi and keypoints from .rois.\n",
    "        Store single images, masks, moving images and keypoints.\n",
    "    \"\"\"\n",
    "    \n",
    "    image_index_2_roi_2_xy = dict()\n",
    "    for video in sources:\n",
    "        video_path = os.path.join(base_dir, \"{}.avi\".format(video))\n",
    "        rois_path = os.path.join(base_dir, \"{}.rois\".format(video))\n",
    "\n",
    "        reader = imageio.get_reader(video_path)\n",
    "\n",
    "        file = open(rois_path)\n",
    "        roi_data = json.load(file)\n",
    "\n",
    "        for frame, image in enumerate(reader):  \n",
    "            # Extract image\n",
    "            save_path = os.path.join(save_dir, \"{}.png\".format(image_index))\n",
    "            plt.imsave(save_path, image, cmap=\"gray\")\n",
    "\n",
    "            rois = roi_data[\"frames\"][frame][\"roi_positions\"]\n",
    "            roi_2_xy = dict()\n",
    "\n",
    "            # Create mask\n",
    "            mask = np.zeros(image.shape)\n",
    "            for roi in rois:\n",
    "                if not roi['placed']:\n",
    "                    continue\n",
    "\n",
    "                id = roi['id']\n",
    "                x = roi['pos']['x']\n",
    "                y = roi['pos']['y']\n",
    "\n",
    "                x = int(round(roi['pos']['x'], 0))\n",
    "                y = int(round(roi['pos']['y'], 0))\n",
    "\n",
    "                roi_2_xy[id] = (x, y)\n",
    "                mask[y][x] =  255\n",
    "\n",
    "            mask = gaussian(mask,sigma=0.9)\n",
    "            mask = (mask / mask.max()) * 255\n",
    "            mask = np.where(mask>0.1, 1.0, 0.0)\n",
    "\n",
    "            plt.imshow(mask, cmap=\"gray\")\n",
    "            mask_path = os.path.join(save_dir, \"{}_m.png\".format(image_index))\n",
    "            plt.imsave(mask_path, mask, cmap=\"gray\")\n",
    "            \n",
    "            # Create keypoints .json\n",
    "            json_path = os.path.join(save_dir, \"{}.json\".format(image_index))\n",
    "            json_file = json.dumps(roi_2_xy)\n",
    "\n",
    "            f = open(json_path, \"w\")\n",
    "            f.write(json_file)\n",
    "            f.close() \n",
    "            file.close()\n",
    "            \n",
    "            # Create moving image\n",
    "            moving = np.zeros((height, width))\n",
    "            for key, value in roi_2_xy.items():\n",
    "                moving[value[1]][value[0]] = 1\n",
    "            moving = utils.apply_smoothing(moving, sigma=2, sigma_back=15)\n",
    "            save_path = save_dir + os.sep + \"{}_mov.png\".format(image_index)\n",
    "            plt.imsave(save_path, moving, cmap='gray')\n",
    "\n",
    "            image_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "Parameters used for the specific data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the image space\n",
    "height = 768\n",
    "width = 768\n",
    "\n",
    "# Amount of smoothing\n",
    "sigma = 2\n",
    "\n",
    "# Amount of smoothing for the background\n",
    "sigma_back= 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set\n",
    "Here the training set is create. Ensure the reuired directories are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 0\n",
    "base_dir = \"Data/LASTEN/raw\"\n",
    "save_dir = \"Data/LASTEN/train\"\n",
    "sources = [\"KK2_gap0_Cam_16904_Cine2_0_19\",\n",
    "           \"KK4_gap0_Cam_16904_Cine2_0_19\",\n",
    "           \"KK11_gap0_Cam_16904_Cine3_0_19\",\n",
    "           \"KK16_gap0_Cam_16904_Cine2_0_19\",\n",
    "           \"KK17_gap0_Cam_16904_Cine2_0_19\",\n",
    "           \"KK18_gap0_Cam_16904_Cine2_0_19\",\n",
    "           \"KK19_gap0_Cam_16904_Cine2_0_19\",\n",
    "           \"KK24_gap0_Cam_16904_Cine2_0_19\"]\n",
    "\n",
    "create_and_store(base_dir, save_dir, sources, image_index, height, width, sigma, sigma_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set\n",
    "Here the validation set is create. Ensure the reuired directories are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 160\n",
    "base_dir = \"Data/LASTEN/raw\"\n",
    "save_dir = \"Data/LASTEN/validation\"\n",
    "sources = [\"KK3_gap0_Cam_16904_Cine2_0_19\",\n",
    "           \"KK9_gap0_Cam_16904_Cine2_0_19\"]\n",
    "\n",
    "create_and_store(base_dir, save_dir, sources, image_index, height, width, sigma, sigma_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set\n",
    "Here the test set is create. Ensure the reuired directories are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 200\n",
    "base_dir = \"Data/LASTEN/raw\"\n",
    "save_dir = \"Data/LASTEN/test\"\n",
    "sources = [\"KK5_gap0_Cam_16904_Cine2_0_19\",\n",
    "           \"KK20_gap0_Cam_16904_Cine2_0_19\"]\n",
    "\n",
    "create_and_store(base_dir, save_dir, sources, image_index, height, width, sigma, sigma_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a fixed image with specified shape. That is the imaginary laser projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 768\n",
    "height = 768\n",
    "\n",
    "n_x = 18\n",
    "n_y = 18\n",
    "\n",
    "spacing_x = 20\n",
    "spacing_y = 20\n",
    "\n",
    "offset_x = (width - ((n_x - 1) * spacing_x)) / 2.0\n",
    "offset_y = (height - ((n_y - 1) * spacing_y)) / 2.0\n",
    "\n",
    "sigma = (2 / 32) * spacing_x\n",
    "sigma_back = (15 / 32) * spacing_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_data(sample_index):  \n",
    "    fixed = np.zeros((height, width))\n",
    "    index_2_xy = dict()\n",
    "    index = 0\n",
    "    for index_y in reversed(range(n_y)):\n",
    "        y = int(round(offset_y + (spacing_y * index_y)))\n",
    "\n",
    "        for index_x in range(n_x):\n",
    "            x = int(round(offset_x + (spacing_x * index_x)))\n",
    "            \n",
    "            fixed[y][x] = 1\n",
    "            index_2_xy[index] = (x, y)\n",
    "            \n",
    "            index += 1\n",
    "            \n",
    "    return fixed, index_2_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed, index_2_xy = get_fixed_data(0)\n",
    "\n",
    "padding = 30\n",
    "fixed = np.pad(fixed, padding, mode='constant')\n",
    "fixed = utils.apply_smoothing(fixed, sigma=sigma, sigma_back=sigma_back)\n",
    "fixed = fixed[padding:height+padding, padding:width+padding]\n",
    "\n",
    "save_des = \"Data/LASTEN/fix\"\n",
    "file = \"_{}_{}\".format(width, spacing_x)\n",
    "plt.imsave(save_des + file + \".png\", fixed, cmap='gray', vmin=0)\n",
    "\n",
    "json_file = json.dumps(index_2_xy)\n",
    "f = open(save_des + file + \".json\", \"w\")\n",
    "f.write(json_file)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
