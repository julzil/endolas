{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements\n",
    "Following packages are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "import closs\n",
    "\n",
    "from simplegen import SIMPLESequence\n",
    "from lastengen import LASTENSequence\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "from unet import UNet\n",
    "from unet import preprocess_input as pre_une\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Checks\n",
    "The version of tensorflow as well as the GPU support are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality\n",
    "Necessary funcionality is added here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cube(img, x, y, val):\n",
    "    \n",
    "    img[y][x] = val\n",
    "    img[y][x-1] = val\n",
    "    img[y][x+1] = val\n",
    "    img[y-1][x] = val\n",
    "    img[y-1][x-1] = val\n",
    "    img[y-1][x+1] = val\n",
    "    img[y+1][x] = val\n",
    "    img[y+1][x-1] = val\n",
    "    img[y+1][x+1] = val  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1) Supervised Euclidean for LASTEN with fixed image\n",
    "A U-Net is trained here to predict a displacement field and the euclidean distance is taken as error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data\n",
    "Import training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "store_path = 'experiments/7_1_euclidean'\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/train/0'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/test'\n",
    "\n",
    "#path_fixed = r'D:\\Julian\\data\\SIMPLED\\train\\0'\n",
    "#path_train = r'D:\\Julian\\data\\SIMPLED\\train'\n",
    "#path_validation = r'D:\\Julian\\data\\SIMPLED\\validation'\n",
    "#path_test = r'D:\\Julian\\data\\SIMPLED\\test'\n",
    "\n",
    "width = 384\n",
    "height = 384\n",
    "\n",
    "grid_width = 18\n",
    "grid_height = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Seeding\n",
    "Seeds are set to ensure reproducible training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Network\n",
    "A U-Net based network is instantiated with keras to run a semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(width, height, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training Preparation\n",
    "Prepare the settings for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "train_gen = LASTENSequence(path_train,\n",
    "                           batch_size=4,\n",
    "                           preprocess_input=pre_une,\n",
    "                           shuffle=True,\n",
    "                           multi_channel='fixed')\n",
    "\n",
    "logger = CSVLogger(store_path + \"/log\")\n",
    "checker = ModelCheckpoint(store_path + \"/weights.{epoch:02d}.hdf5\",\n",
    "                          period=10)\n",
    "callbacks = [logger, checker]\n",
    "\n",
    "eu_loss = closs.EuclideanLoss(batch_size=4, loss_type='maed')\n",
    "\n",
    "#model.compile(optimizer='adam', grid_width=\"\", grid_height=\"\", loss=eu_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[-0.98431373],\n",
       "          [-0.97647059],\n",
       "          [-0.98431373],\n",
       "          ...,\n",
       "          [-0.98431373],\n",
       "          [-0.98431373],\n",
       "          [-1.        ]],\n",
       " \n",
       "         [[-0.98431373],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686],\n",
       "          ...,\n",
       "          [-0.98431373],\n",
       "          [-0.98431373],\n",
       "          [-0.99215686]],\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-0.98431373],\n",
       "          [-1.        ],\n",
       "          ...,\n",
       "          [-0.98431373],\n",
       "          [-0.97647059],\n",
       "          [-0.98431373]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.98431373],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686],\n",
       "          ...,\n",
       "          [-0.98431373],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686]],\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-0.99215686],\n",
       "          [-1.        ],\n",
       "          ...,\n",
       "          [-0.99215686],\n",
       "          [-0.99215686],\n",
       "          [-1.        ]],\n",
       " \n",
       "         [[-0.97647059],\n",
       "          [-0.97647059],\n",
       "          [-0.98431373],\n",
       "          ...,\n",
       "          [-1.        ],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686]]],\n",
       " \n",
       " \n",
       "        [[[-0.99215686],\n",
       "          [-0.98431373],\n",
       "          [-0.97647059],\n",
       "          ...,\n",
       "          [-0.99215686],\n",
       "          [-0.98431373],\n",
       "          [-0.99215686]],\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-0.99215686],\n",
       "          [-0.98431373],\n",
       "          ...,\n",
       "          [-0.97647059],\n",
       "          [-0.98431373],\n",
       "          [-0.98431373]],\n",
       " \n",
       "         [[-0.98431373],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686],\n",
       "          ...,\n",
       "          [-0.99215686],\n",
       "          [-0.98431373],\n",
       "          [-0.98431373]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686],\n",
       "          ...,\n",
       "          [-1.        ],\n",
       "          [-0.99215686],\n",
       "          [-1.        ]],\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686],\n",
       "          ...,\n",
       "          [-0.99215686],\n",
       "          [-1.        ],\n",
       "          [-0.99215686]],\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686],\n",
       "          ...,\n",
       "          [-0.99215686],\n",
       "          [-1.        ],\n",
       "          [-0.99215686]]],\n",
       " \n",
       " \n",
       "        [[[-1.        ],\n",
       "          [-0.98431373],\n",
       "          [-0.98431373],\n",
       "          ...,\n",
       "          [-0.98431373],\n",
       "          [-0.98431373],\n",
       "          [-0.98431373]],\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686],\n",
       "          ...,\n",
       "          [-0.98431373],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686]],\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-1.        ],\n",
       "          [-0.98431373],\n",
       "          ...,\n",
       "          [-0.98431373],\n",
       "          [-0.97647059],\n",
       "          [-0.99215686]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-1.        ],\n",
       "          [-1.        ],\n",
       "          ...,\n",
       "          [-0.99215686],\n",
       "          [-1.        ],\n",
       "          [-1.        ]],\n",
       " \n",
       "         [[-1.        ],\n",
       "          [-1.        ],\n",
       "          [-0.99215686],\n",
       "          ...,\n",
       "          [-1.        ],\n",
       "          [-0.98431373],\n",
       "          [-0.99215686]],\n",
       " \n",
       "         [[-1.        ],\n",
       "          [-1.        ],\n",
       "          [-1.        ],\n",
       "          ...,\n",
       "          [-0.98431373],\n",
       "          [-0.97647059],\n",
       "          [-0.98431373]]],\n",
       " \n",
       " \n",
       "        [[[-1.        ],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686],\n",
       "          ...,\n",
       "          [-0.98431373],\n",
       "          [-0.97647059],\n",
       "          [-0.99215686]],\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-0.99215686],\n",
       "          [-1.        ],\n",
       "          ...,\n",
       "          [-0.98431373],\n",
       "          [-0.98431373],\n",
       "          [-1.        ]],\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686],\n",
       "          ...,\n",
       "          [-0.98431373],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.99215686],\n",
       "          [-1.        ],\n",
       "          [-1.        ],\n",
       "          ...,\n",
       "          [-1.        ],\n",
       "          [-1.        ],\n",
       "          [-1.        ]],\n",
       " \n",
       "         [[-1.        ],\n",
       "          [-0.99215686],\n",
       "          [-1.        ],\n",
       "          ...,\n",
       "          [-1.        ],\n",
       "          [-0.99215686],\n",
       "          [-0.99215686]],\n",
       " \n",
       "         [[-1.        ],\n",
       "          [-1.        ],\n",
       "          [-1.        ],\n",
       "          ...,\n",
       "          [-0.99215686],\n",
       "          [-0.98431373],\n",
       "          [-0.99215686]]]]),\n",
       " array([[[[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]]],\n",
       " \n",
       " \n",
       "        [[[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]]],\n",
       " \n",
       " \n",
       "        [[[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]]],\n",
       " \n",
       " \n",
       "        [[[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]]]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 840 steps, validate for 180 steps\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\zilkerjn\\AppData\\Local\\Continuum\\anaconda3\\envs\\glotax\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840/840 [==============================] - 82s 98ms/step - loss: 722.3557 - val_loss: 609.9671\n",
      "Epoch 2/100\n",
      "840/840 [==============================] - 73s 86ms/step - loss: 295.2440 - val_loss: 69.2219\n",
      "Epoch 3/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 63.9594 - val_loss: 40.3651\n",
      "Epoch 4/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 43.8902 - val_loss: 134.2030\n",
      "Epoch 5/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 34.9258 - val_loss: 44.4679\n",
      "Epoch 6/100\n",
      "840/840 [==============================] - 72s 86ms/step - loss: 29.1634 - val_loss: 24.8344\n",
      "Epoch 7/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 26.7894 - val_loss: 35.6561\n",
      "Epoch 8/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 24.6091 - val_loss: 23.7568\n",
      "Epoch 9/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 21.0550 - val_loss: 21.3612\n",
      "Epoch 10/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 20.4461 - val_loss: 25.2225\n",
      "Epoch 11/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 15.3134 - val_loss: 18.1396\n",
      "Epoch 12/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 16.7065 - val_loss: 35.5319\n",
      "Epoch 13/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 14.9690 - val_loss: 18.6292\n",
      "Epoch 14/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 14.2445 - val_loss: 10.4626\n",
      "Epoch 15/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 11.7442 - val_loss: 13.6364\n",
      "Epoch 16/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 10.3303 - val_loss: 14.6317\n",
      "Epoch 17/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 9.4774 - val_loss: 12.4873\n",
      "Epoch 18/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 8.8505 - val_loss: 8.6820\n",
      "Epoch 19/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 8.4456 - val_loss: 10.3180\n",
      "Epoch 20/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 7.0369 - val_loss: 10.1059\n",
      "Epoch 21/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 7.7543 - val_loss: 7.7725\n",
      "Epoch 22/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 6.5877 - val_loss: 6.6305\n",
      "Epoch 23/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 6.4059 - val_loss: 11.5036\n",
      "Epoch 24/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 5.6017 - val_loss: 6.6035\n",
      "Epoch 25/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 7.3943 - val_loss: 17.0442\n",
      "Epoch 26/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 4.1597 - val_loss: 7.6560\n",
      "Epoch 27/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 3.4855 - val_loss: 6.6394\n",
      "Epoch 28/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 4.9653 - val_loss: 9.1978\n",
      "Epoch 29/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 4.2180 - val_loss: 5.4700\n",
      "Epoch 30/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 3.7530 - val_loss: 4.8320\n",
      "Epoch 31/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 3.4586 - val_loss: 8.7300\n",
      "Epoch 32/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 3.4333 - val_loss: 6.4633\n",
      "Epoch 33/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 3.4488 - val_loss: 5.2551\n",
      "Epoch 34/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 2.9256 - val_loss: 5.7641\n",
      "Epoch 35/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.8630 - val_loss: 5.3245\n",
      "Epoch 36/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.7549 - val_loss: 7.1949\n",
      "Epoch 37/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 2.6176 - val_loss: 4.5103\n",
      "Epoch 38/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 2.5950 - val_loss: 6.2699\n",
      "Epoch 39/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 2.2338 - val_loss: 65.5644\n",
      "Epoch 40/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 2.3926 - val_loss: 8.9356\n",
      "Epoch 41/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 3.2111 - val_loss: 4.2180\n",
      "Epoch 42/100\n",
      "840/840 [==============================] - 68s 81ms/step - loss: 1.7937 - val_loss: 3.6373\n",
      "Epoch 43/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.1951 - val_loss: 4.0215\n",
      "Epoch 44/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 2.1402 - val_loss: 4.7524\n",
      "Epoch 45/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 2.3877 - val_loss: 4.7369\n",
      "Epoch 46/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.3213 - val_loss: 4.6151\n",
      "Epoch 47/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.7298 - val_loss: 3.6267\n",
      "Epoch 48/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 2.9429 - val_loss: 7.0996\n",
      "Epoch 49/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 1.2933 - val_loss: 4.2492\n",
      "Epoch 50/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 1.4630 - val_loss: 4.0198\n",
      "Epoch 51/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.5628 - val_loss: 4.5323\n",
      "Epoch 52/100\n",
      "840/840 [==============================] - 73s 86ms/step - loss: 1.3257 - val_loss: 3.9657\n",
      "Epoch 53/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 2.0079 - val_loss: 3.9582\n",
      "Epoch 54/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.4038 - val_loss: 3.6447\n",
      "Epoch 55/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.2383 - val_loss: 4.1534\n",
      "Epoch 56/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 1.2500 - val_loss: 4.7914\n",
      "Epoch 57/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.5824 - val_loss: 4.6598\n",
      "Epoch 58/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.7412 - val_loss: 3.7935\n",
      "Epoch 59/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.7160 - val_loss: 3.9693\n",
      "Epoch 60/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.8121 - val_loss: 3.2140\n",
      "Epoch 61/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 1.3593 - val_loss: 4.2506\n",
      "Epoch 62/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.9063 - val_loss: 3.3570\n",
      "Epoch 63/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 1.0077 - val_loss: 3.1178\n",
      "Epoch 64/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.1538 - val_loss: 3.6700\n",
      "Epoch 65/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.0701 - val_loss: 3.7147\n",
      "Epoch 66/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.0757 - val_loss: 3.7834\n",
      "Epoch 67/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.8659 - val_loss: 3.3312\n",
      "Epoch 68/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.5105 - val_loss: 4.3140\n",
      "Epoch 69/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.2395 - val_loss: 4.6605\n",
      "Epoch 70/100\n",
      "840/840 [==============================] - 72s 85ms/step - loss: 0.6636 - val_loss: 3.1430\n",
      "Epoch 71/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.0221 - val_loss: 3.5977\n",
      "Epoch 72/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.0470 - val_loss: 19.1298\n",
      "Epoch 73/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 0.9958 - val_loss: 3.6596\n",
      "Epoch 74/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6393 - val_loss: 3.1894\n",
      "Epoch 75/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 1.3009 - val_loss: 4.0637\n",
      "Epoch 76/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.6813 - val_loss: 3.2044\n",
      "Epoch 77/100\n",
      "840/840 [==============================] - 71s 84ms/step - loss: 0.8898 - val_loss: 3.6035\n",
      "Epoch 78/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6604 - val_loss: 2.8032\n",
      "Epoch 79/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 1.1199 - val_loss: 3.1837\n",
      "Epoch 80/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.8005 - val_loss: 3.2592\n",
      "Epoch 81/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.5610 - val_loss: 3.1302\n",
      "Epoch 82/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.7603 - val_loss: 2.9978\n",
      "Epoch 83/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.2282 - val_loss: 3.9371\n",
      "Epoch 84/100\n",
      "840/840 [==============================] - 71s 85ms/step - loss: 0.6977 - val_loss: 2.7065\n",
      "Epoch 85/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.5404 - val_loss: 2.9330\n",
      "Epoch 86/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.6324 - val_loss: 3.4963\n",
      "Epoch 87/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6906 - val_loss: 2.8284\n",
      "Epoch 88/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 1.1340 - val_loss: 10.4809\n",
      "Epoch 89/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 0.7786 - val_loss: 3.1478\n",
      "Epoch 90/100\n",
      "840/840 [==============================] - 75s 89ms/step - loss: 0.4443 - val_loss: 2.9265\n",
      "Epoch 91/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.5222 - val_loss: 3.2656\n",
      "Epoch 92/100\n",
      "840/840 [==============================] - 70s 84ms/step - loss: 0.7137 - val_loss: 2.9344\n",
      "Epoch 93/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.6094 - val_loss: 29.6343\n",
      "Epoch 94/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.6618 - val_loss: 3.9200\n",
      "Epoch 95/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.6730 - val_loss: 3.3195\n",
      "Epoch 96/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.5864 - val_loss: 3.0188\n",
      "Epoch 97/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.5027 - val_loss: 2.9649\n",
      "Epoch 98/100\n",
      "840/840 [==============================] - 69s 83ms/step - loss: 0.6682 - val_loss: 3.4974\n",
      "Epoch 99/100\n",
      "840/840 [==============================] - 70s 83ms/step - loss: 0.5397 - val_loss: 2.9135\n",
      "Epoch 100/100\n",
      "840/840 [==============================] - 69s 82ms/step - loss: 0.9166 - val_loss: 3.0209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20cc50db048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_gen,\n",
    "          epochs=100,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=validation_gen,\n",
    "          validation_freq=1,\n",
    "          use_multiprocessing=True,\n",
    "          workers=10,\n",
    "          max_queue_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = validation_gen[1]\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "u_x = y_pred[0,:,:,0]\n",
    "u_y = y_pred[0,:,:,1]\n",
    "\n",
    "plt.imshow(y_pred[0,:,:,0], cmap=\"gray\")\n",
    "\n",
    "plt.imsave(store_path + \"/u_x.png\", u_x, cmap=\"gray\")\n",
    "plt.imsave(store_path + \"/u_y.png\", u_y, cmap=\"gray\")\n",
    "\n",
    "u_x.dump(store_path + \"/u_x\")\n",
    "u_y.dump(store_path + \"/u_y\")\n",
    "\n",
    "warp = np.zeros((width, height))\n",
    "\n",
    "for index in range(0,25):\n",
    "    x_pos = int(y[0, index, 0, 0])\n",
    "    y_pos = int(y[0, index, 1, 0])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 1) #blue\n",
    "    \n",
    "    ux_field = y_pred[0,:,:,0]\n",
    "    uy_field = y_pred[0,:,:,1]\n",
    "    \n",
    "    ux = ux_field[y_pos][x_pos]\n",
    "    uy = uy_field[y_pos][x_pos]\n",
    "    \n",
    "    x_pos = int(round(x_pos + ux))\n",
    "    y_pos = int(round(y_pos + uy))\n",
    "            \n",
    "    plot_cube(warp, x_pos, y_pos, 2) #green    \n",
    "    \n",
    "    x_pos = int(y[0, index, 0, 1])\n",
    "    y_pos = int(y[0, index, 1, 1])\n",
    "    \n",
    "    plot_cube(warp, x_pos, y_pos, 3) #yellow    \n",
    "    \n",
    "plt.imshow(warp)\n",
    "plt.imsave(store_path + \"/warp.png\", warp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
