{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements\n",
    "Following packages are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import closs\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "from lastengen import LASTENSequence\n",
    "import importlib\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "from unet import UNet\n",
    "from unet import preprocess_input as pre_une\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Checks\n",
    "The version of tensorflow as well as the GPU support are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable all GPUS\n",
    "  tf.config.set_visible_devices([], 'GPU')\n",
    "  visible_devices = tf.config.get_visible_devices()\n",
    "  for device in visible_devices:\n",
    "    assert device.device_type != 'GPU'\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "\n",
    "print(tf.config.get_visible_devices('GPU'))\n",
    "print(tf.config.get_visible_devices('CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition\n",
    "Size definition is done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 384\n",
    "height = 384\n",
    "\n",
    "grid_width = 18\n",
    "grid_height = 18\n",
    "\n",
    "grid_points = grid_width * grid_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality\n",
    "Necessary funcionality is added here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path):\n",
    "    test_gen = LASTENSequence(path_test,\n",
    "                               path_fixed,\n",
    "                               batch_size=1,\n",
    "                               width=width,\n",
    "                               height=height,\n",
    "                               grid_width=grid_width, \n",
    "                               grid_height=grid_height,\n",
    "                               preprocess_input=pre_une,\n",
    "                               shuffle=True,\n",
    "                               label=\"keypoints\",\n",
    "                               channel=\"moving+fixed\")\n",
    "\n",
    "    validation_gen = LASTENSequence(path_validation,\n",
    "                               path_fixed,\n",
    "                               batch_size=1,\n",
    "                               width=width,\n",
    "                               height=height,\n",
    "                               grid_width=grid_width, \n",
    "                               grid_height=grid_height,\n",
    "                               preprocess_input=pre_une,\n",
    "                               shuffle=False,\n",
    "                               label=\"keypoints\",\n",
    "                               channel=\"moving+fixed\")\n",
    "\n",
    "    eu_loss = closs.EuclideanLoss(batch_size=1, grid_width=grid_width, grid_height=grid_height, loss_type='maed')\n",
    "\n",
    "    model.compile(optimizer='adam', loss = eu_loss)\n",
    "    model.load_weights(store_path+'/weights.100.hdf5')\n",
    "\n",
    "    warp_val = dict()\n",
    "    maed_val_array = np.zeros(len(validation_gen))\n",
    "    for index, val in enumerate(validation_gen):\n",
    "        image_id = validation_gen._image_ids[index]\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        X, y = val\n",
    "        maed = model.evaluate(X,y,verbose=0)\n",
    "        maed_val_array[index] = maed\n",
    "\n",
    "        y_pred = model.predict(X)\n",
    "        u_x = y_pred[0,:,:,0]\n",
    "        u_y = y_pred[0,:,:,1]\n",
    "\n",
    "        for inner_index in range(0,grid_points):\n",
    "            x_pos = int(y[0, inner_index, 0, 0])\n",
    "            y_pos = int(y[0, inner_index, 1, 0])\n",
    "\n",
    "            ux_field = y_pred[0,:,:,0]\n",
    "            uy_field = y_pred[0,:,:,1]\n",
    "\n",
    "            ux = ux_field[y_pos][x_pos]\n",
    "            uy = uy_field[y_pos][x_pos]\n",
    "\n",
    "            x_pos = int(round(x_pos + ux))\n",
    "            y_pos = int(round(y_pos + uy))\n",
    "\n",
    "            warp_val[str(inner_index)] = [x_pos, y_pos]\n",
    "            with open(store_path +'/val/{}_w.json'.format(image_id), 'w') as fp:\n",
    "                json.dump(warp_val, fp)    \n",
    "\n",
    "    warp_test = dict()\n",
    "    maed_test_array = np.zeros(len(test_gen))\n",
    "    for index, val in enumerate(test_gen):\n",
    "        image_id = test_gen._image_ids[index]\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        X, y = val\n",
    "        maed = model.evaluate(X,y,verbose=0)\n",
    "        maed_test_array[index] = maed\n",
    "        \n",
    "        y_pred = model.predict(X)\n",
    "        u_x = y_pred[0,:,:,0]\n",
    "        u_y = y_pred[0,:,:,1]\n",
    "\n",
    "        for inner_index in range(0,grid_points):\n",
    "            x_pos = int(y[0, inner_index, 0, 0])\n",
    "            y_pos = int(y[0, inner_index, 1, 0])\n",
    "\n",
    "            ux_field = y_pred[0,:,:,0]\n",
    "            uy_field = y_pred[0,:,:,1]\n",
    "\n",
    "            ux = ux_field[y_pos][x_pos]\n",
    "            uy = uy_field[y_pos][x_pos]\n",
    "\n",
    "            x_pos = int(round(x_pos + ux))\n",
    "            y_pos = int(round(y_pos + uy))\n",
    "\n",
    "            warp_test[str(inner_index)] = [x_pos, y_pos]\n",
    "            with open(store_path +'/test/{}_w.json'.format(image_id), 'w') as fp:\n",
    "                json.dump(warp_test, fp)\n",
    "\n",
    "    maed_array = np.concatenate((maed_val_array, maed_test_array))\n",
    "    val_set = ['val' for i in range(len(validation_gen))]\n",
    "    test_set = ['test' for i in range(len(test_gen))]\n",
    "    set_type = val_set + test_set\n",
    "    image_id = validation_gen._image_ids + test_gen._image_ids\n",
    "\n",
    "    dataset = pd.DataFrame({'MAED': maed_array, 'Set': set_type, 'Image': image_id})\n",
    "    dataset.to_csv(store_path + '/evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_nearest_neighbor(experiment_2_set_2_image_2_accuracy):\n",
    "    accuracys = []\n",
    "    images = []\n",
    "    set_types = []\n",
    "    experiments = []\n",
    "    \n",
    "    for experiment, set_2_image_2_accuracy in experiment_2_set_2_image_2_accuracy.items():\n",
    "        for set_type, image_2_accuracy in set_2_image_2_accuracy.items():\n",
    "            for image, accuracy in image_2_accuracy.items():\n",
    "                accuracys.append(accuracy)\n",
    "                images.append(image)\n",
    "                set_types.append(set_type)\n",
    "                experiments.append(experiment)\n",
    "                \n",
    "    dataset = pd.DataFrame({'Accuracy': accuracys, 'Image': images, 'Set': set_types, 'Experiment': experiments})\n",
    "    dataset.to_csv('experiments/7_euclidean/evaluation_nn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_distribution(store_path, path_fixed):\n",
    "    x_val = []\n",
    "    y_val = []\n",
    "    image = []\n",
    "    point = []\n",
    "    set_types = []\n",
    "    \n",
    "    for set_type in ['val', 'test']:\n",
    "        data_path = os.path.join(store_path, set_type)\n",
    "        globs = glob(data_path + os.sep + \"*_w.json\")\n",
    "        globs = [int(path.split(os.sep)[-1].split(\".\")[0].split(\"_\")[0]) for path in globs]\n",
    "        image_ids = sorted(globs)\n",
    "        \n",
    "        for image_id in image_ids:\n",
    "            # 0)Load data\n",
    "            warp_path = data_path + os.sep + \"{}_w.json\".format(image_id)\n",
    "            with open(warp_path) as warped_file:\n",
    "                warped_json = json.load(warped_file)\n",
    "\n",
    "            # 1) Sort out all obsolete points\n",
    "            for key, value in list(warped_json.items()):\n",
    "                if value[0] < 2.0 and value[1] < 2.0:\n",
    "                    _ = warped_json.pop(key)\n",
    "\n",
    "            # 2) Build arrays\n",
    "            for key, value in list(warped_json.items()):\n",
    "                x_val.append(value[0])\n",
    "                y_val.append(value[1])\n",
    "                image.append(image_id)\n",
    "                point.append(key)\n",
    "                set_types.append(set_type)\n",
    "            \n",
    "    # 3) Build dataframe\n",
    "    dataset = pd.DataFrame({'x': x_val, 'y': y_val, 'Set': set_types, 'Image': image, 'Point': point})\n",
    "    dataset.to_csv(store_path + '/evaluation_spatial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_display(store_path, path_validation, path_test):\n",
    "    x_val = []\n",
    "    y_val = []\n",
    "    image = []\n",
    "    point = []\n",
    "    set_types = []\n",
    "    image_types = []\n",
    "    \n",
    "    # Warp\n",
    "    for set_type in ['val', 'test']:\n",
    "        data_path = os.path.join(store_path, set_type)\n",
    "        globs = glob(data_path + os.sep + \"*_w.json\")\n",
    "        globs = [int(path.split(os.sep)[-1].split(\".\")[0].split(\"_\")[0]) for path in globs]\n",
    "        image_ids = sorted(globs)\n",
    "        \n",
    "        for image_id in image_ids:\n",
    "            # 0)Load data\n",
    "            warp_path = data_path + os.sep + \"{}_w.json\".format(image_id)\n",
    "            with open(warp_path) as warped_file:\n",
    "                warped_json = json.load(warped_file)\n",
    "\n",
    "            # 1) Sort out all obsolete points\n",
    "            for key, value in list(warped_json.items()):\n",
    "                if value[0] < 2.0 and value[1] < 2.0:\n",
    "                    _ = warped_json.pop(key)\n",
    "\n",
    "            # 2) Build arrays\n",
    "            for key, value in list(warped_json.items()):\n",
    "                x_val.append(value[0])\n",
    "                y_val.append(value[1])\n",
    "                image.append(image_id)\n",
    "                point.append(key)\n",
    "                set_types.append(set_type)\n",
    "                image_types.append('warped')\n",
    "                \n",
    "    # Moving validation\n",
    "    globs = glob(path_validation + os.sep + \"*.json\")\n",
    "    globs = [int(path.split(os.sep)[-1].split(\".\")[0].split(\"_\")[0]) for path in globs]\n",
    "    image_ids = sorted(globs)\n",
    "    \n",
    "    for image_id in image_ids:\n",
    "        # 0)Load data\n",
    "        moving_path = path_validation + os.sep + \"{}.json\".format(image_id)\n",
    "        with open(moving_path) as moving_file:\n",
    "            moving_json = json.load(moving_file)\n",
    "\n",
    "        # 1) Sort out all obsolete points\n",
    "        for key, value in list(moving_json.items()):\n",
    "            if value[0] < 2.0 and value[1] < 2.0:\n",
    "                _ = warped_json.pop(key)\n",
    "\n",
    "        # 2) Build arrays\n",
    "        for key, value in list(moving_json.items()):\n",
    "            x_val.append(value[0])\n",
    "            y_val.append(value[1])\n",
    "            image.append(image_id)\n",
    "            point.append(key)\n",
    "            set_types.append('val')\n",
    "            image_types.append('moving')\n",
    "            \n",
    "    # Moving test\n",
    "    globs = glob(path_test + os.sep + \"*.json\")\n",
    "    globs = [int(path.split(os.sep)[-1].split(\".\")[0].split(\"_\")[0]) for path in globs]\n",
    "    image_ids = sorted(globs)\n",
    "\n",
    "    for image_id in image_ids:\n",
    "        # 0)Load data\n",
    "        moving_path = path_test + os.sep + \"{}.json\".format(image_id)\n",
    "        with open(moving_path) as moving_file:\n",
    "            moving_json = json.load(moving_file)\n",
    "\n",
    "        # 1) Sort out all obsolete points\n",
    "        for key, value in list(moving_json.items()):\n",
    "            if value[0] < 2.0 and value[1] < 2.0:\n",
    "                _ = warped_json.pop(key)\n",
    "\n",
    "        # 2) Build arrays\n",
    "        for key, value in list(moving_json.items()):\n",
    "            x_val.append(value[0])\n",
    "            y_val.append(value[1])\n",
    "            image.append(image_id)\n",
    "            point.append(key)\n",
    "            set_types.append('test')\n",
    "            image_types.append('moving')\n",
    "            \n",
    "    # Build dataframe\n",
    "    dataset = pd.DataFrame({'x': x_val, 'y': y_val, 'Set': set_types, 'Image': image, 'Point': point, 'Type': image_types})\n",
    "    dataset.to_csv(store_path + '/evaluation_display.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_2_set_2_image_2_accuracy = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1) Supervised Euclidean for LASTEN with fixed image BS=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "experiment = 1\n",
    "store_path = 'experiments/7_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/fix'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/test'\n",
    "\n",
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(width, height, 2))\n",
    "eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path)\n",
    "\n",
    "accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val', scale_factor=0.5)\n",
    "accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test', scale_factor=0.5)\n",
    "\n",
    "set_2_image_2_accuracy = dict()\n",
    "set_2_image_2_accuracy['val'] = accuracy_val\n",
    "set_2_image_2_accuracy['test'] = accuracy_test\n",
    "experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy\n",
    "\n",
    "#spatial_distribution(store_path, path_fixed)\n",
    "spatial_display(store_path, path_validation, path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2) Supervised Euclidean for LASTEN with fixed image BS=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "experiment = 2\n",
    "store_path = 'experiments/7_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/fix'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/test'\n",
    "\n",
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(width, height, 2))\n",
    "eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path)\n",
    "\n",
    "accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val', scale_factor=0.5)\n",
    "accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test', scale_factor=0.5)\n",
    "\n",
    "set_2_image_2_accuracy = dict()\n",
    "set_2_image_2_accuracy['val'] = accuracy_val\n",
    "set_2_image_2_accuracy['test'] = accuracy_test\n",
    "experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy\n",
    "\n",
    "#spatial_distribution(store_path, path_fixed)\n",
    "spatial_display(store_path, path_validation, path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3) Supervised Euclidean for LASTENS with fixed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment = 3\n",
    "store_path = 'experiments/7_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENS/fix'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENS/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENS/validation'\n",
    "path_validation2 = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENS/test'\n",
    "path_test2 = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/test'\n",
    "\n",
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(width, height, 2))\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test2, store_path)\n",
    "\n",
    "#accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val', scale_factor=0.5)\n",
    "#accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test', scale_factor=0.5)\n",
    "\n",
    "#set_2_image_2_accuracy = dict()\n",
    "#set_2_image_2_accuracy['val'] = accuracy_val\n",
    "#set_2_image_2_accuracy['test'] = accuracy_test\n",
    "#experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy\n",
    "\n",
    "#spatial_distribution(store_path, path_fixed)\n",
    "spatial_display(store_path, path_validation, path_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4) Supervised Euclidean for LASTENA with fixed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiment = 4\n",
    "store_path = 'experiments/7_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENA/fix'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENA/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENA/validation'\n",
    "path_validation2 = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENA/test'\n",
    "path_test2 = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/test'\n",
    "\n",
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(width, height, 2))\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test2, store_path)\n",
    "\n",
    "#accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val', scale_factor=0.5)\n",
    "#accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test', scale_factor=0.5)\n",
    "\n",
    "#set_2_image_2_accuracy = dict()\n",
    "#set_2_image_2_accuracy['val'] = accuracy_val\n",
    "#set_2_image_2_accuracy['test'] = accuracy_test\n",
    "#experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy\n",
    "\n",
    "#spatial_distribution(store_path, path_fixed)\n",
    "spatial_display(store_path, path_validation, path_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5) Supervised Euclidean for LASTENAS with fixed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 5\n",
    "store_path = 'experiments/7_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENAS/fix'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENAS/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENAS/validation'\n",
    "path_validation2 = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTENAS/test'\n",
    "path_test2 = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/LASTEN/test'\n",
    "\n",
    "model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(width, height, 2))\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test2, store_path)\n",
    "\n",
    "#accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val', scale_factor=0.5)\n",
    "#accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test', scale_factor=0.5)\n",
    "\n",
    "#set_2_image_2_accuracy = dict()\n",
    "#set_2_image_2_accuracy['val'] = accuracy_val\n",
    "#set_2_image_2_accuracy['test'] = accuracy_test\n",
    "#experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy\n",
    "\n",
    "#spatial_distribution(store_path, path_fixed)\n",
    "spatial_display(store_path, path_validation, path_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_nearest_neighbor(experiment_2_set_2_image_2_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
