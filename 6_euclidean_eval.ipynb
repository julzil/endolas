{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements\n",
    "Following packages are necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import utils\n",
    "import closs\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "from simplegen import SIMPLESequence\n",
    "import importlib\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "from unet import UNet\n",
    "from unet import preprocess_input as pre_une\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Checks\n",
    "The version of tensorflow as well as the GPU support are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-rc3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.get_visible_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable all GPUS\n",
    "  tf.config.set_visible_devices([], 'GPU')\n",
    "  visible_devices = tf.config.get_visible_devices()\n",
    "  for device in visible_devices:\n",
    "    assert device.device_type != 'GPU'\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "\n",
    "print(tf.config.get_visible_devices('GPU'))\n",
    "print(tf.config.get_visible_devices('CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition\n",
    "Size definition is done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 224\n",
    "height = 224\n",
    "\n",
    "grid_width = 5\n",
    "grid_height = 5\n",
    "\n",
    "grid_points = grid_width * grid_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality\n",
    "Necessary funcionality is added here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path, multi_channel):\n",
    "    validation_gen = SIMPLESequence(path_validation, path_fixed,\n",
    "                                    batch_size=1,\n",
    "                                    preprocess_input=pre_une,\n",
    "                                    multi_channel=multi_channel)\n",
    "    \n",
    "    test_gen = SIMPLESequence(path_test, path_fixed,\n",
    "                                batch_size=1,\n",
    "                                preprocess_input=pre_une,\n",
    "                                multi_channel=multi_channel)\n",
    "\n",
    "    eu_loss = closs.EuclideanLoss(batch_size=1, loss_type='maed')\n",
    "\n",
    "    model.compile(optimizer='adam', loss = eu_loss)\n",
    "    model.load_weights(store_path+'/weights.100.hdf5')\n",
    "\n",
    "    warp_val = dict()\n",
    "    maed_val_array = np.zeros(len(validation_gen))\n",
    "    for index, val in enumerate(validation_gen):\n",
    "        image_id = validation_gen._image_ids[index]\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        X, y = val\n",
    "        maed = model.evaluate(X,y,verbose=0)\n",
    "        maed_val_array[index] = maed\n",
    "\n",
    "        y_pred = model.predict(X)\n",
    "        u_x = y_pred[0,:,:,0]\n",
    "        u_y = y_pred[0,:,:,1]\n",
    "\n",
    "        for inner_index in range(0,grid_points):\n",
    "            x_pos = int(y[0, inner_index, 0, 0])\n",
    "            y_pos = int(y[0, inner_index, 1, 0])\n",
    "\n",
    "            ux_field = y_pred[0,:,:,0]\n",
    "            uy_field = y_pred[0,:,:,1]\n",
    "\n",
    "            ux = ux_field[y_pos][x_pos]\n",
    "            uy = uy_field[y_pos][x_pos]\n",
    "\n",
    "            x_pos = int(round(x_pos + ux))\n",
    "            y_pos = int(round(y_pos + uy))\n",
    "\n",
    "            warp_val[str(inner_index)] = [x_pos, y_pos]\n",
    "            with open(store_path +'/val/{}_w.json'.format(image_id), 'w') as fp:\n",
    "                json.dump(warp_val, fp)\n",
    "\n",
    "\n",
    "    warp_test = dict()\n",
    "    maed_test_array = np.zeros(len(test_gen))\n",
    "    for index, val in enumerate(test_gen):\n",
    "        image_id = test_gen._image_ids[index]\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        X, y = val\n",
    "        maed = model.evaluate(X,y,verbose=0)\n",
    "        maed_test_array[index] = maed\n",
    "        \n",
    "        y_pred = model.predict(X)\n",
    "        u_x = y_pred[0,:,:,0]\n",
    "        u_y = y_pred[0,:,:,1]\n",
    "\n",
    "        for inner_index in range(0,grid_points):\n",
    "            x_pos = int(y[0, inner_index, 0, 0])\n",
    "            y_pos = int(y[0, inner_index, 1, 0])\n",
    "\n",
    "            ux_field = y_pred[0,:,:,0]\n",
    "            uy_field = y_pred[0,:,:,1]\n",
    "\n",
    "            ux = ux_field[y_pos][x_pos]\n",
    "            uy = uy_field[y_pos][x_pos]\n",
    "\n",
    "            x_pos = int(round(x_pos + ux))\n",
    "            y_pos = int(round(y_pos + uy))\n",
    "\n",
    "            warp_test[str(inner_index)] = [x_pos, y_pos]\n",
    "            with open(store_path +'/test/{}_w.json'.format(image_id), 'w') as fp:\n",
    "                json.dump(warp_test, fp)\n",
    "\n",
    "    maed_array = np.concatenate((maed_val_array, maed_test_array))\n",
    "    val_set = ['val' for i in range(len(validation_gen))]\n",
    "    test_set = ['test' for i in range(len(test_gen))]\n",
    "    set_type = val_set + test_set\n",
    "    image_id = validation_gen._image_ids + test_gen._image_ids\n",
    "\n",
    "    dataset = pd.DataFrame({'MAED': maed_array, 'Set': set_type, 'Image': image_id})\n",
    "    dataset.to_csv(store_path + '/evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_nearest_neighbor(experiment_2_set_2_image_2_accuracy):\n",
    "    accuracys = []\n",
    "    images = []\n",
    "    set_types = []\n",
    "    experiments = []\n",
    "    \n",
    "    for experiment, set_2_image_2_accuracy in experiment_2_set_2_image_2_accuracy.items():\n",
    "        for set_type, image_2_accuracy in set_2_image_2_accuracy.items():\n",
    "            for image, accuracy in image_2_accuracy.items():\n",
    "                accuracys.append(accuracy)\n",
    "                images.append(image)\n",
    "                set_types.append(set_type)\n",
    "                experiments.append(experiment)\n",
    "                \n",
    "    dataset = pd.DataFrame({'Accuracy': accuracys, 'Image': images, 'Set': set_types, 'Experiment': experiments})\n",
    "    dataset.to_csv('experiments/6_euclidean/evaluation_nn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_distribution(store_path, path_fixed):\n",
    "    x_val = []\n",
    "    y_val = []\n",
    "    image = []\n",
    "    point = []\n",
    "    set_types = []\n",
    "    \n",
    "    for set_type in ['val', 'test']:\n",
    "        data_path = os.path.join(store_path, set_type)\n",
    "        globs = glob(data_path + os.sep + \"*_w.json\")\n",
    "        globs = [int(path.split(os.sep)[-1].split(\".\")[0].split(\"_\")[0]) for path in globs]\n",
    "        image_ids = sorted(globs)\n",
    "        \n",
    "        for image_id in image_ids:\n",
    "            # 0)Load data\n",
    "            warp_path = data_path + os.sep + \"{}_w.json\".format(image_id)\n",
    "            with open(warp_path) as warped_file:\n",
    "                warped_json = json.load(warped_file)\n",
    "\n",
    "            # 1) Sort out all obsolete points\n",
    "            for key, value in list(warped_json.items()):\n",
    "                if value[0] < 2.0 and value[1] < 2.0:\n",
    "                    _ = warped_json.pop(key)\n",
    "\n",
    "            # 2) Build arrays\n",
    "            for key, value in list(warped_json.items()):\n",
    "                x_val.append(value[0])\n",
    "                y_val.append(value[1])\n",
    "                image.append(image_id)\n",
    "                point.append(key)\n",
    "                set_types.append(set_type)\n",
    "            \n",
    "    # 3) Build dataframe\n",
    "    dataset = pd.DataFrame({'x': x_val, 'y': y_val, 'Set': set_types, 'Image': image, 'Point': point})\n",
    "    dataset.to_csv(store_path + '/evaluation_spatial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_display(store_path, path_validation, path_test):\n",
    "    x_val = []\n",
    "    y_val = []\n",
    "    image = []\n",
    "    point = []\n",
    "    set_types = []\n",
    "    image_types = []\n",
    "    \n",
    "    # Warp\n",
    "    for set_type in ['val', 'test']:\n",
    "        data_path = os.path.join(store_path, set_type)\n",
    "        globs = glob(data_path + os.sep + \"*_w.json\")\n",
    "        globs = [int(path.split(os.sep)[-1].split(\".\")[0].split(\"_\")[0]) for path in globs]\n",
    "        image_ids = sorted(globs)\n",
    "        \n",
    "        for image_id in image_ids:\n",
    "            # 0)Load data\n",
    "            warp_path = data_path + os.sep + \"{}_w.json\".format(image_id)\n",
    "            with open(warp_path) as warped_file:\n",
    "                warped_json = json.load(warped_file)\n",
    "\n",
    "            # 1) Sort out all obsolete points\n",
    "            for key, value in list(warped_json.items()):\n",
    "                if value[0] < 2.0 and value[1] < 2.0:\n",
    "                    _ = warped_json.pop(key)\n",
    "\n",
    "            # 2) Build arrays\n",
    "            for key, value in list(warped_json.items()):\n",
    "                x_val.append(value[0])\n",
    "                y_val.append(value[1])\n",
    "                image.append(image_id)\n",
    "                point.append(key)\n",
    "                set_types.append(set_type)\n",
    "                image_types.append('warped')\n",
    "                \n",
    "    # Moving validation\n",
    "    globs = glob(path_validation + os.sep + \"*_m.json\")\n",
    "    globs = [int(path.split(os.sep)[-1].split(\".\")[0].split(\"_\")[0]) for path in globs]\n",
    "    image_ids = sorted(globs)\n",
    "\n",
    "    for image_id in image_ids:\n",
    "        # 0)Load data\n",
    "        moving_path = path_validation + os.sep + \"{}_m.json\".format(image_id)\n",
    "        with open(moving_path) as moving_file:\n",
    "            moving_json = json.load(moving_file)\n",
    "\n",
    "        # 1) Sort out all obsolete points\n",
    "        for key, value in list(moving_json.items()):\n",
    "            if value[0] < 2.0 and value[1] < 2.0:\n",
    "                _ = warped_json.pop(key)\n",
    "\n",
    "        # 2) Build arrays\n",
    "        for key, value in list(moving_json.items()):\n",
    "            x_val.append(value[0])\n",
    "            y_val.append(value[1])\n",
    "            image.append(image_id)\n",
    "            point.append(key)\n",
    "            set_types.append('val')\n",
    "            image_types.append('moving')\n",
    "            \n",
    "    # Moving test\n",
    "    globs = glob(path_test + os.sep + \"*_m.json\")\n",
    "    globs = [int(path.split(os.sep)[-1].split(\".\")[0].split(\"_\")[0]) for path in globs]\n",
    "    image_ids = sorted(globs)\n",
    "\n",
    "    for image_id in image_ids:\n",
    "        # 0)Load data\n",
    "        moving_path = path_test + os.sep + \"{}_m.json\".format(image_id)\n",
    "        with open(moving_path) as moving_file:\n",
    "            moving_json = json.load(moving_file)\n",
    "\n",
    "        # 1) Sort out all obsolete points\n",
    "        for key, value in list(moving_json.items()):\n",
    "            if value[0] < 2.0 and value[1] < 2.0:\n",
    "                _ = warped_json.pop(key)\n",
    "\n",
    "        # 2) Build arrays\n",
    "        for key, value in list(moving_json.items()):\n",
    "            x_val.append(value[0])\n",
    "            y_val.append(value[1])\n",
    "            image.append(image_id)\n",
    "            point.append(key)\n",
    "            set_types.append('test')\n",
    "            image_types.append('moving')\n",
    "            \n",
    "    # Build dataframe\n",
    "    dataset = pd.DataFrame({'x': x_val, 'y': y_val, 'Set': set_types, 'Image': image, 'Point': point, 'Type': image_types})\n",
    "    dataset.to_csv(store_path + '/evaluation_display.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_2_set_2_image_2_accuracy = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4) Supervised Euclidean for SIMPLEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 4\n",
    "store_path = 'experiments/6_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLEA/train/0'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLEA/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLEA/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLEA/test'\n",
    "\n",
    "#model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 1))\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path, 'moving')\n",
    "importlib.reload(utils)\n",
    "utils.nearest_neighbor(store_path, path_fixed, 'val')\n",
    "\n",
    "accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val')\n",
    "accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test')\n",
    "\n",
    "set_2_image_2_accuracy = dict()\n",
    "set_2_image_2_accuracy['val'] = accuracy_val\n",
    "set_2_image_2_accuracy['test'] = accuracy_test\n",
    "\n",
    "experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.5) Supervised Euclidean for SIMPLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 5\n",
    "store_path = 'experiments/6_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLEN/train/0'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLEN/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLEN/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLEN/test'\n",
    "\n",
    "#model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 1))\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path, 'moving')\n",
    "\n",
    "accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val')\n",
    "accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test')\n",
    "\n",
    "set_2_image_2_accuracy = dict()\n",
    "set_2_image_2_accuracy['val'] = accuracy_val\n",
    "set_2_image_2_accuracy['test'] = accuracy_test\n",
    "\n",
    "experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6) Supervised Euclidean for SIMPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 6\n",
    "store_path = 'experiments/6_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train/0'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/test'\n",
    "\n",
    "#model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 1))\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path, 'moving')\n",
    "\n",
    "accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val')\n",
    "accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test')\n",
    "\n",
    "set_2_image_2_accuracy = dict()\n",
    "set_2_image_2_accuracy['val'] = accuracy_val\n",
    "set_2_image_2_accuracy['test'] = accuracy_test\n",
    "\n",
    "experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.7) Supervised Euclidean for SIMPLED with mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 7\n",
    "store_path = 'experiments/6_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train/0'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/test'\n",
    "\n",
    "#model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 1))\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path, 'moving')\n",
    "\n",
    "accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val')\n",
    "accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test')\n",
    "\n",
    "set_2_image_2_accuracy = dict()\n",
    "set_2_image_2_accuracy['val'] = accuracy_val\n",
    "set_2_image_2_accuracy['test'] = accuracy_test\n",
    "\n",
    "experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.8) Supervised Euclidean for SIMPLED with fixed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiment = 8\n",
    "store_path = 'experiments/6_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train/0'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/test'\n",
    "\n",
    "#model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 2))\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path, 'fixed')\n",
    "\n",
    "#accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val')\n",
    "#accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test')\n",
    "\n",
    "#set_2_image_2_accuracy = dict()\n",
    "#set_2_image_2_accuracy['val'] = accuracy_val\n",
    "#set_2_image_2_accuracy['test'] = accuracy_test\n",
    "#experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy\n",
    "\n",
    "#spatial_distribution(store_path, path_fixed)\n",
    "spatial_display(store_path, path_validation, path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.9) Supervised Euclidean for SIMPLED with difference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 9\n",
    "store_path = 'experiments/6_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train/0'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/test'\n",
    "\n",
    "#model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 2))\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path, 'diff')\n",
    "\n",
    "accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val')\n",
    "accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test')\n",
    "\n",
    "set_2_image_2_accuracy = dict()\n",
    "set_2_image_2_accuracy['val'] = accuracy_val\n",
    "set_2_image_2_accuracy['test'] = accuracy_test\n",
    "\n",
    "experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.10) Supervised Euclidean for SIMPLED with difference image and gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 10\n",
    "store_path = 'experiments/6_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train/0'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/test'\n",
    "\n",
    "#model = UNet(filters=32, layers=4, activation='linear', classes=2, input_shape=(224, 224, 3))\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path, 'grad')\n",
    "\n",
    "accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val')\n",
    "accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test')\n",
    "\n",
    "set_2_image_2_accuracy = dict()\n",
    "set_2_image_2_accuracy['val'] = accuracy_val\n",
    "set_2_image_2_accuracy['test'] = accuracy_test\n",
    "\n",
    "experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.11) Supervised Euclidean for SIMPLED with L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 11\n",
    "store_path = 'experiments/6_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train/0'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/test'\n",
    "\n",
    "#kernel_regularizer=tf.keras.regularizers.l1(0.01)\n",
    "\n",
    "#model = UNet(filters=32,\n",
    "#             layers=4,\n",
    "#             activation='linear',\n",
    "#             classes=2,\n",
    "#             input_shape=(224, 224, 1),\n",
    "#             kernel_regularizer=kernel_regularizer)\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path, 'moving')\n",
    "\n",
    "accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val')\n",
    "accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test')\n",
    "\n",
    "set_2_image_2_accuracy = dict()\n",
    "set_2_image_2_accuracy['val'] = accuracy_val\n",
    "set_2_image_2_accuracy['test'] = accuracy_test\n",
    "\n",
    "experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.12) Supervised Euclidean for SIMPLED with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 12\n",
    "store_path = 'experiments/6_{}_euclidean'.format(experiment)\n",
    "\n",
    "path_fixed = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train/0'\n",
    "path_train = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/train'\n",
    "path_validation = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/validation'\n",
    "path_test = '/home/julian/Documents/Studium/MT-Masterarbeit/Data/SIMPLED/test'\n",
    "\n",
    "#kernel_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "\n",
    "#model = UNet(filters=32,\n",
    "#             layers=4,\n",
    "#             activation='linear',\n",
    "#             classes=2,\n",
    "#             input_shape=(224, 224, 1),\n",
    "#             kernel_regularizer=kernel_regularizer)\n",
    "\n",
    "#eval_pred(model, path_train, path_fixed, path_validation, path_test, store_path, 'moving')\n",
    "\n",
    "accuracy_val = utils.nearest_neighbor(store_path, path_fixed, 'val')\n",
    "accuracy_test = utils.nearest_neighbor(store_path, path_fixed, 'test')\n",
    "\n",
    "set_2_image_2_accuracy = dict()\n",
    "set_2_image_2_accuracy['val'] = accuracy_val\n",
    "set_2_image_2_accuracy['test'] = accuracy_test\n",
    "\n",
    "experiment_2_set_2_image_2_accuracy[experiment] = set_2_image_2_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_nearest_neighbor(experiment_2_set_2_image_2_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
